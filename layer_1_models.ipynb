{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Learners\n",
    "\n",
    "Julian Domingo - jad5348\n",
    "\n",
    "This file contains my process for training my base learners and meta learner to predict the probability values for the target value **Y**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Computation / Data Analysis stuff\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import skew, probplot, norm, uniform, randint\n",
    "from scipy.special import boxcox1p\n",
    "\n",
    "# Modeling stuff\n",
    "from mlens.metrics import make_scorer\n",
    "from mlens.model_selection import Evaluator\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import (GridSearchCV, \n",
    "                                     StratifiedKFold,\n",
    "                                     cross_val_score)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import (RandomForestClassifier, \n",
    "                              AdaBoostClassifier, \n",
    "                              GradientBoostingClassifier, \n",
    "                              ExtraTreesClassifier,\n",
    "                              BaggingClassifier)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_validation import train_test_split, KFold\n",
    "\n",
    "# Plotting stuff\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "from mlens.visualization import corrmat\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "\n",
    "# Plotting visuals stuff\n",
    "%matplotlib inline\n",
    "mpl.style.use('ggplot')\n",
    "sns.set_style('white')\n",
    "\n",
    "# ignore warnings (i.e. deprecation warnings)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_ids = pd.read_csv(\"./data/raw/test.csv\")[[\"id\"]]\n",
    "train_y_cp = pd.read_csv(\"./data/raw/train.csv\")[\"Y\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_preds(filename):\n",
    "    train = pd.read_csv(\"./meta_features/train/train_{}.csv\".format(filename), index_col=0).as_matrix().ravel()\n",
    "    test = pd.read_csv(\"./meta_features/test/test_{}.csv\".format(filename), index_col=0).as_matrix().ravel()\n",
    "    \n",
    "    return train, test\n",
    "\n",
    "\n",
    "def get_data(filename):\n",
    "    train = pd.read_csv(\"./data/refined/train/train_{}.csv\".format(filename))\n",
    "    test = pd.read_csv(\"./data/refined/test/test_{}.csv\".format(filename))\n",
    "    \n",
    "    x_train = train.drop([\"Y\"], axis = 1)\n",
    "    y_train = train[\"Y\"]\n",
    "    \n",
    "    return train, test, x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_raw, test_raw, x_train_raw, y_train_raw = get_data(\"raw\")\n",
    "train_base, test_base, x_train_base, y_train_base = get_data(\"base\")\n",
    "train_log, test_log, x_train_log, y_train_log = get_data(\"log\")\n",
    "train_poly, test_poly, x_train_poly, y_train_poly = get_data(\"poly\")\n",
    "train_scaled, test_scaled, x_train_scaled, y_train_scaled = get_data(\"scaled\")\n",
    "train_reduced, test_reduced, x_train_reduced, y_train_reduced = get_data(\"reduced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F10</th>\n",
       "      <th>F11</th>\n",
       "      <th>F15</th>\n",
       "      <th>F16</th>\n",
       "      <th>F17</th>\n",
       "      <th>F18</th>\n",
       "      <th>F19</th>\n",
       "      <th>F20</th>\n",
       "      <th>F21</th>\n",
       "      <th>F22</th>\n",
       "      <th>F23</th>\n",
       "      <th>F24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>61385</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>118751</td>\n",
       "      <td>1000</td>\n",
       "      <td>32020</td>\n",
       "      <td>1</td>\n",
       "      <td>127959</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>119757</td>\n",
       "      <td>119100</td>\n",
       "      <td>1</td>\n",
       "      <td>118830</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>126461</td>\n",
       "      <td>1</td>\n",
       "      <td>46871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51329</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>120800</td>\n",
       "      <td>1000</td>\n",
       "      <td>130630</td>\n",
       "      <td>1</td>\n",
       "      <td>128342</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>138110</td>\n",
       "      <td>121149</td>\n",
       "      <td>1</td>\n",
       "      <td>118832</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>130296</td>\n",
       "      <td>1</td>\n",
       "      <td>42386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5522</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>118779</td>\n",
       "      <td>1000</td>\n",
       "      <td>303218</td>\n",
       "      <td>2</td>\n",
       "      <td>128299</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>119777</td>\n",
       "      <td>119126</td>\n",
       "      <td>1</td>\n",
       "      <td>118832</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>127063</td>\n",
       "      <td>1</td>\n",
       "      <td>23968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6754</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>123163</td>\n",
       "      <td>2000</td>\n",
       "      <td>19024</td>\n",
       "      <td>1</td>\n",
       "      <td>127968</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>270637</td>\n",
       "      <td>123511</td>\n",
       "      <td>1</td>\n",
       "      <td>118832</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15274</td>\n",
       "      <td>1</td>\n",
       "      <td>27555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16991</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>119193</td>\n",
       "      <td>1000</td>\n",
       "      <td>303218</td>\n",
       "      <td>1</td>\n",
       "      <td>128299</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>119777</td>\n",
       "      <td>119542</td>\n",
       "      <td>1</td>\n",
       "      <td>118832</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>133491</td>\n",
       "      <td>1</td>\n",
       "      <td>50260</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      F2  F3  F4      F5    F6      F7  F8     F10  F11  F15     F16     F17  \\\n",
       "0  61385   0  38  118751  1000   32020   1  127959    1    1  119757  119100   \n",
       "1  51329   0  41  120800  1000  130630   1  128342    2    1  138110  121149   \n",
       "2   5522   0  50  118779  1000  303218   2  128299    1    1  119777  119126   \n",
       "3   6754   0  45  123163  2000   19024   1  127968    1    2  270637  123511   \n",
       "4  16991   0  41  119193  1000  303218   1  128299    1    1  119777  119542   \n",
       "\n",
       "   F18     F19  F20  F21     F22  F23    F24  \n",
       "0    1  118830    1    1  126461    1  46871  \n",
       "1    1  118832    1    1  130296    1  42386  \n",
       "2    1  118832    1    2  127063    1  23968  \n",
       "3    1  118832    1    1   15274    1  27555  \n",
       "4    1  118832    1    1  133491    1  50260  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_base.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_pearson_corr(mapping, dict_vals_are_models=True):\n",
    "    if dict_vals_are_models:\n",
    "        all_preds = pd.DataFrame(np.zeros((test_base.shape[0], len(mapping))), columns=list(mapping.keys()))\n",
    "    else:\n",
    "        all_preds = pd.DataFrame(np.zeros((train_base.shape[0], len(mapping))), columns=list(mapping.keys()))\n",
    "    \n",
    "    for name, val in mapping.items():\n",
    "        if dict_vals_are_models:\n",
    "            val.fit(x_train_base, y_train_base)\n",
    "            all_preds[name] = val.predict_proba(test_base)[:,1]   \n",
    "        else:\n",
    "            all_preds[name] = val\n",
    "        \n",
    "    all_preds = all_preds.reindex_axis(sorted(all_preds.columns.values), axis=1)\n",
    "\n",
    "    ax = corrmat(all_preds.corr())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cross_val_score(model, x_train, y_train, n_folds, run_parallel=True):\n",
    "    if run_parallel:\n",
    "        cv = cross_val_score(model, x_train, y_train, cv = n_folds, scoring = \"roc_auc\", n_jobs = -1)\n",
    "    else:\n",
    "        cv = cross_val_score(model, x_train, y_train, cv = n_folds, scoring = \"roc_auc\")\n",
    "        \n",
    "    print(\"Cross validation score: {} +/- {}\\nRaw scores: {}\".format(str(np.mean(cv)), str(np.std(cv)), str(cv)))\n",
    "    return cv\n",
    "\n",
    "\n",
    "def train_and_save_base_learner_preds(model, folds, x_train, y_train, test, pred_filename, timeit=True, mlens=False):\n",
    "    # Train model on the folds defined\n",
    "    if mlens:\n",
    "        train_ids = x_train.index\n",
    "        test_ids = test.index\n",
    "        x_train = np.array(x_train)\n",
    "        y_train = np.array(y_train)\n",
    "        test = np.array(test)\n",
    "        \n",
    "        train_preds = np.zeros(x_train.shape[0])\n",
    "        test_preds = np.zeros(test.shape[0])\n",
    "        test_preds_iter = np.zeros((test.shape[0], len(folds)))\n",
    "        \n",
    "        stacker = SuperLearner(random_state=seed, scorer=roc_auc_score)\n",
    "        stacker.add(model, proba=True)\n",
    "        \n",
    "        for i, (train_indices, test_indices) in enumerate(folds):\n",
    "            xtr = x_train[train_indices]\n",
    "            xhold = x_train[test_indices]\n",
    "            ytr = y_train[train_indices]\n",
    "            \n",
    "            # Deletes the previous fit when \"warm_start\" is disabled (intended behavior)\n",
    "            %time stacker.fit(x_train, y_train)\n",
    "            \n",
    "            train_preds[test_indices] = stacker.predict_proba(xhold)[:,1]\n",
    "            test_preds_iter[:,i] = stacker.predict_proba(test)[:,1]\n",
    "        \n",
    "        test_preds[:] = test_preds_iter.mean(1)\n",
    "        \n",
    "        submission = pd.DataFrame({\"id\": train_ids, \"Y\": train_preds})\n",
    "        submission.to_csv(\"./meta_features/mlens/train/train_{}.csv\".format(pred_filename), index=False, columns=[\"id\", \"Y\"])   \n",
    "        \n",
    "        submission = pd.DataFrame({\"id\": test_ids, \"Y\": test_preds})\n",
    "        submission.to_csv(\"./meta_features/mlens/test/test_{}.csv\".format(pred_filename), index=False, columns=[\"id\", \"Y\"])   \n",
    "        \n",
    "        return model  \n",
    "    \n",
    "    else:\n",
    "        result = generate_out_of_folds_preds(model, folds, x_train, y_train, test, timeit)\n",
    "\n",
    "        train_preds_csv = pd.DataFrame(columns=[\"Y\"], index=x_train.index, data=result[\"train_preds\"])\n",
    "        train_preds_csv.to_csv(\"./meta_features/train/train_{}.csv\".format(pred_filename), index=False, columns=[\"id\", \"Y\"])\n",
    "\n",
    "        test_preds_csv = pd.DataFrame(columns=[\"Y\"], index=test.index, data=result[\"test_preds\"])\n",
    "        test_preds_csv.to_csv(\"./meta_features/test/test_{}.csv\".format(pred_filename), index=False, columns=[\"id\", \"Y\"])\n",
    "\n",
    "        return result[\"model\"]\n",
    "                          \n",
    "\n",
    "def generate_out_of_folds_preds(model, folds, x, y, test, timeit=True):\n",
    "    \"\"\" \n",
    "    Trains the model through (stratified) CV, and generates predictions from\n",
    "    the weighted average of each holdout's predictions.\n",
    "    \n",
    "    'train_preds' is the combination of all predictions from each holdout.\n",
    "    'test_preds' is the final predictions computed through the mean of each test prediction.\n",
    "    \n",
    "    \"\"\"\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    test = np.array(test)\n",
    "        \n",
    "    train_preds = np.zeros(x.shape[0])\n",
    "    test_preds = np.zeros(test.shape[0])\n",
    "    test_preds_iter = np.zeros((test.shape[0], len(folds)))\n",
    "    \n",
    "    for i, (train_indices, test_indices) in enumerate(folds):\n",
    "        x_train = x[train_indices]\n",
    "        x_holdout = x[test_indices]\n",
    "        y_train = y[train_indices]\n",
    "        \n",
    "        if timeit:\n",
    "            %time model.fit(x_train, y_train)\n",
    "        else:\n",
    "            model.fit(x_train, y_train)\n",
    "        \n",
    "        train_preds[test_indices] = model.predict_proba(x_holdout)[:,1]\n",
    "        test_preds_iter[:,i] = model.predict_proba(test)[:,1]\n",
    "        \n",
    "    test_preds[:] = test_preds_iter.mean(1)\n",
    "        \n",
    "    return {'model': model, 'train_preds': train_preds ,'test_preds': test_preds}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtain fold indices for base learner training.\n",
    "n_splits = 5\n",
    "folds = list(StratifiedKFold(n_splits, random_state=seed).split(x_train_base, y_train_base))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we want to use the **same** fold indices every time in order for our stacking ensemble to perform optimally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Learners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min, sys: 386 ms, total: 1min\n",
      "Wall time: 9.53 s\n",
      "CPU times: user 1min 1s, sys: 350 ms, total: 1min 2s\n",
      "Wall time: 9.71 s\n",
      "CPU times: user 1min 1s, sys: 337 ms, total: 1min 2s\n",
      "Wall time: 9.67 s\n",
      "CPU times: user 1min 4s, sys: 339 ms, total: 1min 4s\n",
      "Wall time: 9.94 s\n",
      "CPU times: user 1min 4s, sys: 355 ms, total: 1min 4s\n",
      "Wall time: 10 s\n",
      "Cross validation score: 0.763972140277 +/- 0.0126201727415\n",
      "Raw scores: [ 0.76663797  0.77985633  0.74617437  0.75311065  0.77408139]\n"
     ]
    }
   ],
   "source": [
    "rfc_log = RandomForestClassifier(criterion='entropy', max_features=10, n_estimators=1000, n_jobs=-1)\n",
    "rfc_log = train_and_save_base_learner_preds(rfc_log, folds, x_train_log, y_train_log, test_log, \"random_forest_log\")\n",
    "rfc_log_cv = get_cross_val_score(rfc_log, x_train_log, y_train_log, n_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Using Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfc_raw = RandomForestClassifier(criterion='entropy', max_features=10, n_estimators=1000, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation score: 0.7695456125591551 +/- 0.012976891105761897\n",
      "Raw scores: [0.76927927 0.78441299 0.75467399 0.7555443  0.78381751]\n"
     ]
    }
   ],
   "source": [
    "# Using tuned parameters fitted on BASE data\n",
    "rfc_raw = train_and_save_base_learner_preds(rfc_raw, folds, x_train_raw, y_train_raw, test_raw, \"random_forest_raw\", timeit=False)\n",
    "rfc_raw_cv = get_cross_val_score(rfc_raw, x_train_raw, y_train_raw, n_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.97  0.675 0.93  ... 0.852 0.995 0.972]\n"
     ]
    }
   ],
   "source": [
    "# Finally, predict our probabilities.\n",
    "rfc_raw.fit(x_train_raw, y_train_raw)\n",
    "rfc_raw_probs = rfc_raw.predict_proba(test_raw)[:,1]\n",
    "print rfc_raw_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save a copy of the predictions\n",
    "submission = pd.DataFrame({\"id\": test_ids.id, \"Y\": rfc_raw_probs})\n",
    "submission.to_csv(\"./submissions/random_forest_raw_lone.csv\", index=False, columns=[\"id\", \"Y\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Using Polynomial Transformation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 32s, sys: 413 ms, total: 1min 32s\n",
      "Wall time: 16.1 s\n",
      "CPU times: user 1min 38s, sys: 398 ms, total: 1min 39s\n",
      "Wall time: 14.5 s\n",
      "CPU times: user 1min 36s, sys: 408 ms, total: 1min 37s\n",
      "Wall time: 15.3 s\n",
      "CPU times: user 1min 38s, sys: 646 ms, total: 1min 39s\n",
      "Wall time: 15.6 s\n",
      "CPU times: user 1min 40s, sys: 555 ms, total: 1min 41s\n",
      "Wall time: 15 s\n",
      "Cross validation score: 0.762157532882 +/- 0.0178247735886\n",
      "Raw scores: [ 0.74675429  0.78349288  0.74934748  0.74677624  0.78441678]\n"
     ]
    }
   ],
   "source": [
    "rfc_poly = RandomForestClassifier(criterion='entropy', max_features=10, n_estimators=1000, n_jobs=-1)\n",
    "rfc_poly = train_and_save_base_learner_preds(rfc_poly, folds, x_train_poly, y_train_poly, test_poly, \"random_forest_poly\")\n",
    "rfc_poly_cv = get_cross_val_score(rfc_poly, x_train_poly, y_train_poly, n_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Using Base Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=1000, n_jobs=-1, oob_score=False,\n",
       "            random_state=None, verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'max_features': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 'auto'], 'max_depth': [5, 6, 7, 8, 9, 10, 11, 12]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_param_grid = {\n",
    "    \"max_features\": [1, 3, 10]\n",
    "}\n",
    "\n",
    "rfc = RandomForestClassifier(criterion='entropy', max_depth=10, n_estimators=1000, n_jobs=-1)\n",
    "\n",
    "gs_rfc = GridSearchCV(estimator=rfc, param_grid=rfc_param_grid, cv=n_splits, scoring=\"roc_auc\")\n",
    "gs_rfc.fit(x_train_base, y_train_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_features': 6, 'max_depth': 12}\n"
     ]
    }
   ],
   "source": [
    "# So, we'll use 10 to be our max_features value.\n",
    "print gs_rfc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation score: 0.767653985688 +/- 0.0137592880393\n",
      "Raw scores: [ 0.76729217  0.78474473  0.74785336  0.7578412   0.78053847]\n"
     ]
    }
   ],
   "source": [
    "# Train with our optimized parameters.\n",
    "rfc = RandomForestClassifier(criterion='entropy', max_features=10, n_estimators=1000, n_jobs=-1)\n",
    "rfc = train_and_save_base_learner_preds(rfc, folds, x_train_base, y_train_base, test_base, \"random_forest_base\")\n",
    "rf_cv = get_cross_val_score(rfc, x_train_base, y_train_base, n_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Using Log Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 2s, sys: 511 ms, total: 1min 2s\n",
      "Wall time: 10.8 s\n",
      "CPU times: user 1min 4s, sys: 512 ms, total: 1min 4s\n",
      "Wall time: 11 s\n",
      "CPU times: user 1min 4s, sys: 498 ms, total: 1min 5s\n",
      "Wall time: 10.7 s\n",
      "CPU times: user 1min 4s, sys: 308 ms, total: 1min 5s\n",
      "Wall time: 10.1 s\n",
      "CPU times: user 1min 5s, sys: 413 ms, total: 1min 5s\n",
      "Wall time: 10.4 s\n",
      "Cross validation score: 0.766020138462 +/- 0.0113610765781\n",
      "Raw scores: [ 0.76509741  0.77783124  0.75289286  0.75429075  0.77998842]\n"
     ]
    }
   ],
   "source": [
    "rfc_log = RandomForestClassifier(criterion='entropy', max_features=10, n_estimators=1000, n_jobs=-1)\n",
    "rfc_log = train_and_save_base_learner_preds(rfc_log, folds, x_train_log, y_train_log, test_log, \"random_forest_log\")\n",
    "rfc_log_cv = get_cross_val_score(rfc_log, x_train_log, y_train_log, n_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oddly enough, the raw / no feature engineering data set has the highest public LB score when submitted to kaggle. However, this could potentially be overfitting with how much noise there is in the raw / no feature engineering data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what features RandomForestClassifier deemed most important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f55b94548d0>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsEAAAHfCAYAAACxhQUCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nH6ZfiLUyb/rbAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f55b9454f90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(index=x_train_raw.columns, data=rfc_raw.feature_importances_) \\\n",
    "    .drop([\"F1\", \"F9\", \"F12\", \"F13\", \"F14\"]) \\\n",
    "    .sort_values().plot(kind='barh', title='Variable Importances')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, we'll use the top 2 features, **F2** and **F24**, to use in our PolynomialFeature transformed data set. Generation of this data set can be found in **\"data_processing.ipynb\"** under the \"Transformations\" subsection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [0.01, 0.1, 1.0, 10, 100], 'tol': [1e-05, 0.0001, 0.001], 'solver': ['liblinear', 'sag']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_param_grid = {\n",
    "    \"tol\": [1e-5, 1e-4, 1e-3],\n",
    "    \"solver\": [\"liblinear\", \"sag\"], # For some reason, \"saga\" isn't allowed anymore.\n",
    "    \"C\": [0.01, 0.1, 1.0, 10, 100] # Inverse of regularization strength. Smaller values specify stronger regularization (must be pos float)\n",
    "}\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "gs_lr = GridSearchCV(estimator=lr, param_grid=lr_param_grid, cv=n_splits, scoring=\"roc_auc\")\n",
    "gs_lr.fit(x_train_log, y_train_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 100, 'tol': 1e-05, 'solver': 'liblinear'}\n",
      "0.545830385785\n"
     ]
    }
   ],
   "source": [
    "print gs_lr.best_params_\n",
    "print gs_lr.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation score: 0.545833322926 +/- 0.0230976755653\n",
      "Raw scores: [ 0.56433684  0.55349304  0.50612     0.53532381  0.56989291]\n"
     ]
    }
   ],
   "source": [
    "# Train with our optimized parameters.\n",
    "lr = LogisticRegression(C=100, tol=1e-05, solver=\"liblinear\")\n",
    "lr = train_and_save_base_learner_preds(lr, folds, x_train_log, y_train_log, test_log, \"logistic_regression_log\")\n",
    "lr_cv = get_cross_val_score(lr, x_train_log, y_train_log, n_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.91999531  0.93921733  0.91854823 ...,  0.92974219  0.92594105\n",
      "  0.94791889]\n"
     ]
    }
   ],
   "source": [
    "# Finally, predict our probabilities.\n",
    "lr.fit(x_train_log, y_train_log)\n",
    "lr_probs = lr.predict_proba(test_log)[:,1]\n",
    "print lr_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save a copy of the predictions\n",
    "submission = pd.DataFrame({\"id\": test_ids.id, \"Y\": lr_probs})\n",
    "submission.to_csv(\"./submissions/logistic_regression_lone.csv\", index=False, columns=[\"id\", \"Y\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logistic regressor scores are pretty bad, both in offline CV and when submitted to Kaggle. I'll choose to leave this base learner out of my ensemble."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Using Base Data\n",
    "###### Step 1: Optimize learning_rate & n_estimators\n",
    "1. max_depth = 5 : This should be between 3-10. Iâ€™ve started with 5.\n",
    "2. min_child_weight = 1 : A smaller value is chosen because it is a highly imbalanced class problem and leaf nodes can have smaller size groups.\n",
    "3. gamma = 0 : A smaller value like 0.1-0.2 can also be chosen for starting. This will anyways be tuned later.\n",
    "4. subsample & colsample_bytree = 0.8 : This is a commonly used start value. Typical values range between 0.5-0.9.\n",
    "5. scale_pos_weight = 1: Because of high class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initial xgb parameters\n",
    "xgb_base_params = {\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"n_estimators\": 311,\n",
    "    \"max_depth\": 8,\n",
    "    \"min_child_weight\": 2,\n",
    "    \"gamma\": 0.2,\n",
    "    \"subsample\": 0.6,\n",
    "    \"colsample_bytree\": 0.5,\n",
    "    \"objective\": 'binary:logistic', # Used for classifier XGB\n",
    "    \"seed\": seed\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.5, gamma=0.2, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=8, min_child_weight=2, missing=None,\n",
       "       n_estimators=311, n_jobs=1, nthread=None,\n",
       "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=42, silent=True,\n",
       "       subsample=0.6),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_estimators': [300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_base_n_est = {\n",
    "    \"n_estimators\": range(300, 350)\n",
    "}\n",
    "\n",
    "xgb_base = XGBClassifier(**xgb_base_params)\n",
    "\n",
    "gs_base_n_est = GridSearchCV(estimator=xgb_base, param_grid=xgb_base_n_est, cv=n_splits, scoring=\"roc_auc\")\n",
    "gs_base_n_est.fit(x_train_base, y_train_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 311}\n",
      "0.7507398286576572\n"
     ]
    }
   ],
   "source": [
    "print gs_base_n_est.best_params_\n",
    "print gs_base_n_est.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 311}\n",
      "0.7507398286576572\n"
     ]
    }
   ],
   "source": [
    "# After first iteration\n",
    "print gs_base_n_est.best_params_\n",
    "print gs_base_n_est.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Step 2: Optimize max_depth & min_child_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_base_params[\"n_estimators\"] = 345"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# refit model with optimized params\n",
    "xgb_base = XGBClassifier(**xgb_base_params)\n",
    "\n",
    "xgb_base_param_grid = {\n",
    "    \"max_depth\": range(3, 9, 1),\n",
    "    \"min_child_weight\": range(1, 6, 2)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=5, min_child_weight=1, missing=None, n_estimators=345,\n",
       "       n_jobs=1, nthread=4, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=42, silent=True,\n",
       "       subsample=0.8),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'max_depth': [3, 4, 5, 6, 7, 8], 'min_child_weight': [1, 3, 5]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_xgb_base = GridSearchCV(estimator=xgb_base, param_grid=xgb_base_param_grid, cv=n_splits, scoring=\"roc_auc\")\n",
    "gs_xgb_base.fit(x_train_base, y_train_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 6, 'min_child_weight': 1}\n",
      "0.7527988661\n"
     ]
    }
   ],
   "source": [
    "print gs_xgb_base.best_params_\n",
    "print gs_xgb_base.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_base_params[\"max_depth\"] = 6\n",
    "xgb_base_params[\"min_child_weight\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# refit model with optimized params\n",
    "xgb_base = XGBClassifier(**xgb_base_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now look for optimum values by searching 1 above and 1 below the initial best parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_base_param_grid_2 = {\n",
    "    \"max_depth\": [8, 9, 10],\n",
    "    \"min_child_weight\": [0, 1, 2, 3, 4]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=6, min_child_weight=1, missing=None, n_estimators=345,\n",
       "       n_jobs=1, nthread=4, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=42, silent=True,\n",
       "       subsample=0.8),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'max_depth': [8, 9, 10], 'min_child_weight': [0, 1, 2, 3, 4]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_xgb_base_2 = GridSearchCV(estimator=xgb_base, param_grid=xgb_base_param_grid_2, cv=n_splits, scoring=\"roc_auc\")\n",
    "gs_xgb_base_2.fit(x_train_base, y_train_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 8, 'min_child_weight': 2}\n",
      "0.75347678825\n"
     ]
    }
   ],
   "source": [
    "print gs_xgb_base_2.best_params_\n",
    "print gs_xgb_base_2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Looks like we got a better max_depth!\n",
    "xgb_base_params[\"max_depth\"] = 8\n",
    "xgb_base_params[\"min_child_weight\"] = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure **min_child_weight** isn't just a local optimum, we'll test values larger than our initial test range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_base_param_grid_2b = {\n",
    "    \"min_child_weight\": [1, 2, 6, 8, 10, 12]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# refit model with optimized params\n",
    "xgb_base = XGBClassifier(**xgb_base_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=8, min_child_weight=2, missing=None, n_estimators=345,\n",
       "       n_jobs=1, nthread=4, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=42, silent=True,\n",
       "       subsample=0.8),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'min_child_weight': [1, 2, 6, 8, 10, 12]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_xgb_base_2b = GridSearchCV(estimator=xgb_base, param_grid=xgb_base_param_grid_2b, cv=n_splits, scoring=\"roc_auc\")\n",
    "gs_xgb_base_2b.fit(x_train_base, y_train_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min_child_weight': 2}\n",
      "0.75347678825\n"
     ]
    }
   ],
   "source": [
    "# Looks like we were right!\n",
    "print gs_xgb_base_2b.best_params_\n",
    "print gs_xgb_base_2b.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Step 3: Tune Gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_base_param_grid_3 = {\n",
    "    \"gamma\": [(i / 10.0) for i in range(0,5)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=8, min_child_weight=2, missing=None, n_estimators=345,\n",
       "       n_jobs=1, nthread=4, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=42, silent=True,\n",
       "       subsample=0.8),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'gamma': [0.0, 0.1, 0.2, 0.3, 0.4]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_xgb_base_3 = GridSearchCV(estimator=xgb_base, param_grid=xgb_base_param_grid_3, cv=n_splits, scoring=\"roc_auc\")\n",
    "gs_xgb_base_3.fit(x_train_base, y_train_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gamma': 0.2}\n",
      "0.755026850826\n"
     ]
    }
   ],
   "source": [
    "print gs_xgb_base_3.best_params_\n",
    "print gs_xgb_base_3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_base_params[\"gamma\"] = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Step 4: Tune subsample & colsample_bytree\n",
    "\n",
    "Like **max_depth**, we'll use a 2-step process of searching across **0.1** increments, then a **0.5** change above and below our initial optimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# refit model with optimized params\n",
    "xgb_base = XGBClassifier(**xgb_base_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step one\n",
    "xgb_base_param_grid_4a = {\n",
    "    \"subsample\": [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "#     \"colsample_bytree\": [0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "    \"colsample_bytree\": [0.1, 0.2, 0.3, 0.4, 0.5, 0.6]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0.2, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=8, min_child_weight=2, missing=None,\n",
       "       n_estimators=345, n_jobs=1, nthread=4, objective='binary:logistic',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=42, silent=True, subsample=0.8),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'subsample': [0.6, 0.7, 0.8, 0.9, 1.0], 'colsample_bytree': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_xgb_base_4a = GridSearchCV(estimator=xgb_base, param_grid=xgb_base_param_grid_4a, cv=n_splits, scoring=\"roc_auc\")\n",
    "gs_xgb_base_4a.fit(x_train_base, y_train_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subsample': 0.6, 'colsample_bytree': 0.5}\n",
      "0.758964979608\n"
     ]
    }
   ],
   "source": [
    "print gs_xgb_base_4a.best_params_\n",
    "print gs_xgb_base_4a.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_base_params[\"colsample_bytree\"] = 0.5\n",
    "xgb_base_params[\"subsample\"] = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# refit model with optimized params\n",
    "xgb_base = XGBClassifier(**xgb_base_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step two\n",
    "xgb_base_param_grid_4b = {\n",
    "    \"subsample\": [0.55, 0.6, 0.65],\n",
    "    \"colsample_bytree\": [0.45, 0.5, 0.55]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.5, gamma=0.2, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=8, min_child_weight=2, missing=None,\n",
       "       n_estimators=198, n_jobs=1, nthread=4, objective='binary:logistic',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=42, silent=True, subsample=0.6),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'subsample': [0.55, 0.6, 0.65], 'colsample_bytree': [0.45, 0.5, 0.55]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_xgb_base_4b = GridSearchCV(estimator=xgb_base, param_grid=xgb_base_param_grid_4b, cv=n_splits, scoring=\"roc_auc\")\n",
    "gs_xgb_base_4b.fit(x_train_base, y_train_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subsample': 0.6, 'colsample_bytree': 0.5}\n",
      "0.760606208777\n"
     ]
    }
   ],
   "source": [
    "print gs_xgb_base_4b.best_params_\n",
    "print gs_xgb_base_4b.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like our initial optimum for these two features were the best values.\n",
    "\n",
    "I'm going to go ahead and stop tuning additional parameters, as I don't want to potentially \"overtune\" my model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Using Reduced Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_reduced_params = {\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"n_estimators\": 223,\n",
    "    \"max_depth\": 7,\n",
    "    \"min_child_weight\": 1,\n",
    "    \"gamma\": 0,\n",
    "    \"subsample\": 0.8,\n",
    "    \"colsample_bytree\": 0.75,\n",
    "    \"objective\": 'binary:logistic', # Used for classifier XGB\n",
    "    \"seed\": seed    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.75, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=7, min_child_weight=1, missing=None, n_estimators=223,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=42, silent=True,\n",
       "       subsample=0.8),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_estimators': [215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_reduced_n_est = {\n",
    "    \"n_estimators\": range(215, 230)\n",
    "}\n",
    "\n",
    "xgb_reduced = XGBClassifier(**xgb_reduced_params)\n",
    "\n",
    "gs_reduced_n_est = GridSearchCV(estimator=xgb_reduced, param_grid=xgb_reduced_n_est, cv=n_splits, scoring=\"roc_auc\")\n",
    "gs_reduced_n_est.fit(x_train_reduced, y_train_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 220}\n",
      "0.7593967046522269\n"
     ]
    }
   ],
   "source": [
    "print gs_reduced_n_est.best_params_\n",
    "print gs_reduced_n_est.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 223}\n",
      "0.7599316268348643\n"
     ]
    }
   ],
   "source": [
    "# After 1st iteration\n",
    "print gs_reduced_n_est.best_params_\n",
    "print gs_reduced_n_est.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.75, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=7, min_child_weight=1, missing=None, n_estimators=223,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=42, silent=True,\n",
       "       subsample=0.8),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'max_depth': [6, 7, 8], 'min_child_weight': [0, 1, 2]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_reduced = XGBClassifier(**xgb_reduced_params)\n",
    "\n",
    "gs_md_mcw = {\n",
    "    \"max_depth\": range(6, 9),\n",
    "    \"min_child_weight\": range(0, 3)\n",
    "}\n",
    "\n",
    "gs_md_mcw = GridSearchCV(estimator=xgb_reduced, param_grid=gs_md_mcw, cv=n_splits, scoring=\"roc_auc\", verbose=1)\n",
    "gs_md_mcw.fit(x_train_reduced, y_train_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 7, 'min_child_weight': 1}\n",
      "0.7580583641939536\n"
     ]
    }
   ],
   "source": [
    "print gs_md_mcw.best_params_\n",
    "print gs_md_mcw.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 7, 'min_child_weight': 1}\n",
      "0.7592573880980192\n"
     ]
    }
   ],
   "source": [
    "print gs_md_mcw.best_params_\n",
    "print gs_md_mcw.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 7, 'min_child_weight': 1}\n",
      "0.7599316268348643\n"
     ]
    }
   ],
   "source": [
    "# After first iteration\n",
    "print gs_md_mcw.best_params_\n",
    "print gs_md_mcw.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.75, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=7, min_child_weight=1, missing=None, n_estimators=223,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=42, silent=True,\n",
       "       subsample=0.8),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'gamma': [0.0, 0.1, 0.2, 0.3, 0.4]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_reduced = XGBClassifier(**xgb_reduced_params)\n",
    "\n",
    "gs_gamma = {\n",
    "    \"gamma\": [(i / 10.0) for i in range(0, 5)]\n",
    "}\n",
    "\n",
    "gs_gamma = GridSearchCV(estimator=xgb_reduced, param_grid=gs_gamma, cv=n_splits, scoring=\"roc_auc\")\n",
    "gs_gamma.fit(x_train_reduced, y_train_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gamma': 0.0}\n",
      "0.7592573880980192\n"
     ]
    }
   ],
   "source": [
    "print gs_gamma.best_params_\n",
    "print gs_gamma.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gamma': 0.0}\n",
      "0.7599316268348643\n"
     ]
    }
   ],
   "source": [
    "# After first iteration\n",
    "print gs_gamma.best_params_\n",
    "print gs_gamma.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 44 candidates, totalling 220 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 220 out of 220 | elapsed:  5.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.75, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=7, min_child_weight=1, missing=None, n_estimators=223,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=42, silent=True,\n",
       "       subsample=0.8),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'subsample': [0.75, 0.8, 0.85, 0.9], 'colsample_bytree': [0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_reduced = XGBClassifier(**xgb_reduced_params)\n",
    "\n",
    "gs_ss_cb = {\n",
    "    \"subsample\": [0.75, 0.8, 0.85, 0.9],\n",
    "    \"colsample_bytree\": [0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8]\n",
    "}\n",
    "\n",
    "gs_ss_cb = GridSearchCV(estimator=xgb_reduced, param_grid=gs_ss_cb, cv=n_splits, scoring=\"roc_auc\", verbose=1)\n",
    "gs_ss_cb.fit(x_train_reduced, y_train_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subsample': 0.8, 'colsample_bytree': 0.75}\n",
      "0.7592573880980192\n"
     ]
    }
   ],
   "source": [
    "print gs_ss_cb.best_params_\n",
    "print gs_ss_cb.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subsample': 0.8, 'colsample_bytree': 0.75}\n",
      "0.7599316268348643\n"
     ]
    }
   ],
   "source": [
    "# After first iteration\n",
    "print gs_ss_cb.best_params_\n",
    "print gs_ss_cb.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Using Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_raw_params = {\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"n_estimators\": 308,\n",
    "    \"max_depth\": 9,\n",
    "    \"min_child_weight\": 1,\n",
    "    \"gamma\": 0,\n",
    "    \"subsample\": 0.75,\n",
    "    \"colsample_bytree\": 0.35,\n",
    "    \"objective\": 'binary:logistic', # Used for classifier XGB\n",
    "    \"seed\": seed    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  2.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.35, gamma=0, learning_rate=0.05,\n",
       "       max_delta_step=0, max_depth=9, min_child_weight=1, missing=None,\n",
       "       n_estimators=308, n_jobs=1, nthread=None,\n",
       "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=42, silent=True,\n",
       "       subsample=0.75),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_estimators': [300, 301, 302, 303, 304, 305, 306, 307, 308, 309]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_raw_n_est = {\n",
    "    \"n_estimators\": range(300, 310)\n",
    "}\n",
    "\n",
    "xgb_raw = XGBClassifier(**xgb_raw_params)\n",
    "\n",
    "gs_raw_n_est = GridSearchCV(estimator=xgb_raw, param_grid=xgb_raw_n_est, cv=n_splits, scoring=\"roc_auc\", verbose=1)\n",
    "gs_raw_n_est.fit(x_train_raw, y_train_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 304}\n",
      "0.7504375241872834\n"
     ]
    }
   ],
   "source": [
    "print gs_raw_n_est.best_params_\n",
    "print gs_raw_n_est.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 308}\n",
      "0.7679402811335971\n"
     ]
    }
   ],
   "source": [
    "# After first iteration\n",
    "print gs_raw_n_est.best_params_\n",
    "print gs_raw_n_est.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:  2.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.35, gamma=0, learning_rate=0.05,\n",
       "       max_delta_step=0, max_depth=9, min_child_weight=1, missing=None,\n",
       "       n_estimators=308, n_jobs=1, nthread=None,\n",
       "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=42, silent=True,\n",
       "       subsample=0.75),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'max_depth': [8, 9, 10], 'min_child_weight': [0, 1, 2]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_raw = XGBClassifier(**xgb_raw_params)\n",
    "\n",
    "gs_md_mcw = {\n",
    "    \"max_depth\": range(8, 10 + 1),\n",
    "    \"min_child_weight\": range(0, 2 + 1)\n",
    "}\n",
    "\n",
    "gs_md_mcw = GridSearchCV(estimator=xgb_raw, param_grid=gs_md_mcw, cv=n_splits, scoring=\"roc_auc\", verbose=1)\n",
    "gs_md_mcw.fit(x_train_raw, y_train_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 7, 'min_child_weight': 5}\n",
      "0.7497058693786715\n"
     ]
    }
   ],
   "source": [
    "print gs_md_mcw.best_params_\n",
    "print gs_md_mcw.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 9, 'min_child_weight': 4}\n",
      "0.7520580379865669\n"
     ]
    }
   ],
   "source": [
    "print gs_md_mcw.best_params_\n",
    "print gs_md_mcw.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 9, 'min_child_weight': 1}\n",
      "0.7544897211045654\n"
     ]
    }
   ],
   "source": [
    "print gs_md_mcw.best_params_\n",
    "print gs_md_mcw.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:  2.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.75, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=9, min_child_weight=1, missing=None, n_estimators=304,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=42, silent=True,\n",
       "       subsample=0.8),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'gamma': [0.0, 0.1, 0.2, 0.3, 0.4]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_raw = XGBClassifier(**xgb_raw_params)\n",
    "\n",
    "gs_gamma = {\n",
    "    \"gamma\": [(i / 10.0) for i in range(0, 5)]\n",
    "}\n",
    "\n",
    "gs_gamma = GridSearchCV(estimator=xgb_raw, param_grid=gs_gamma, cv=n_splits, scoring=\"roc_auc\", verbose=1)\n",
    "gs_gamma.fit(x_train_raw, y_train_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gamma': 0.0}\n",
      "0.7544897211045654\n"
     ]
    }
   ],
   "source": [
    "print gs_gamma.best_params_\n",
    "print gs_gamma.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:  3.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.35, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=9, min_child_weight=1, missing=None, n_estimators=304,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=42, silent=True,\n",
       "       subsample=0.75),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'subsample': [0.725, 0.75, 0.775], 'colsample_bytree': [0.325, 0.35, 0.375, 0.4]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_raw = XGBClassifier(**xgb_raw_params)\n",
    "\n",
    "gs_ss_cb = {\n",
    "    \"subsample\": [0.725, 0.75, 0.775],\n",
    "    \"colsample_bytree\": [0.325, 0.35, 0.375, 0.4]\n",
    "}\n",
    "\n",
    "gs_ss_cb = GridSearchCV(estimator=xgb_raw, param_grid=gs_ss_cb, cv=n_splits, scoring=\"roc_auc\", verbose=1)\n",
    "gs_ss_cb.fit(x_train_raw, y_train_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subsample': 0.75, 'colsample_bytree': 0.35}\n",
      "0.7634658845502256\n"
     ]
    }
   ],
   "source": [
    "print gs_ss_cb.best_params_\n",
    "print gs_ss_cb.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subsample': 0.75, 'colsample_bytree': 0.35}\n",
      "0.7634658845502256\n"
     ]
    }
   ],
   "source": [
    "print gs_ss_cb.best_params_\n",
    "print gs_ss_cb.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  40 out of  40 | elapsed:  2.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.35, gamma=0, learning_rate=0.05,\n",
       "       max_delta_step=0, max_depth=9, min_child_weight=1, missing=None,\n",
       "       n_estimators=304, n_jobs=1, nthread=None,\n",
       "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=42, silent=True,\n",
       "       subsample=0.75),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'learning_rate': [0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_raw = XGBClassifier(**xgb_raw_params)\n",
    "\n",
    "gs_learning = {\n",
    "    \"learning_rate\": [0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09]\n",
    "}\n",
    "\n",
    "gs_learning = GridSearchCV(estimator=xgb_raw, param_grid=gs_learning, cv=n_splits, scoring=\"roc_auc\", verbose=1)\n",
    "gs_learning.fit(x_train_raw, y_train_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.05}\n",
      "0.7676482138163261\n"
     ]
    }
   ],
   "source": [
    "print gs_learning.best_params_\n",
    "print gs_learning.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.05}\n",
      "0.7676482138163261\n"
     ]
    }
   ],
   "source": [
    "print gs_learning.best_params_\n",
    "print gs_learning.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bagged Classifier Tuning (XGB Base Estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_tuned_xgb_copy(data):\n",
    "    \"\"\" \n",
    "    Returns a fresh copy of our parameter tuned XGBClassifier, in case someone\n",
    "    wants to re-run this notebook so the optimized parameters are saved.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"base\": XGBClassifier(learning_rate=0.1,\n",
    "                             n_estimators=345,\n",
    "                             max_depth=8,\n",
    "                             min_child_weight=2,\n",
    "                             gamma=0.2,\n",
    "                             subsample=0.6,\n",
    "                             colsample_bytree=0.5,\n",
    "                             objective=\"binary:logistic\",\n",
    "                             n_jobs=-1,\n",
    "                             random_state=seed),\n",
    "        \"reduced\": XGBClassifier(learning_rate=0.1,\n",
    "                                 n_estimators=223,\n",
    "                                 max_depth=7,\n",
    "                                 min_child_weight=1,\n",
    "                                 gamma=0,\n",
    "                                 subsample=0.8,\n",
    "                                 colsample_bytree=0.75,\n",
    "                                 objective=\"binary:logistic\",\n",
    "                                 n_jobs=-1,\n",
    "                                 random_state=seed),\n",
    "        \"raw\": XGBClassifier(learning_rate=0.05,\n",
    "                             n_estimators=308,\n",
    "                             max_depth=9,\n",
    "                             min_child_weight=1,\n",
    "                             gamma=0, \n",
    "                             subsample=0.75,\n",
    "                             colsample_bytree=0.35,\n",
    "                             objective=\"binary:logistic\",\n",
    "                             n_jobs=-1,\n",
    "                             random_state=seed)\n",
    "    }[data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_bag_params = {\n",
    "    \"n_estimators\": 40,\n",
    "    \"max_samples\": 0.8,\n",
    "    \"max_features\": 0.75\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bag_param_grid = {\n",
    "    \"max_samples\": [0.6, 0.7, 0.8,],\n",
    "    \"max_features\": [0.7, 0.75, 0.8],\n",
    "    \"n_estimators\": range(30, 70 + 1, 10)\n",
    "}\n",
    " \n",
    "xgb_bag = get_tuned_xgb_copy(\"base\")\n",
    "xgb_bagger = BaggingClassifier(base_estimator=xgb_bag, n_estimators=50, max_samples=0.7, max_features=0.75, \\\n",
    "                              bootstrap_features=True, n_jobs=-1)\n",
    "\n",
    "gs_xgb_bagger = GridSearchCV(estimator=xgb_bagger, param_grid=bag_param_grid, cv=n_splits, scoring=\"roc_auc\", verbose=2, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 45 candidates, totalling 225 fits\n",
      "[CV] max_features=0.7, max_samples=0.6, n_estimators=30 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.6, n_estimators=30, total= 1.3min\n",
      "[CV] max_features=0.7, max_samples=0.6, n_estimators=30 ..............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:  1.4min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_features=0.7, max_samples=0.6, n_estimators=30, total= 1.2min\n",
      "[CV] max_features=0.7, max_samples=0.6, n_estimators=30 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.6, n_estimators=30, total= 1.2min\n",
      "[CV] max_features=0.7, max_samples=0.6, n_estimators=30 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.6, n_estimators=30, total= 1.3min\n",
      "[CV] max_features=0.7, max_samples=0.6, n_estimators=30 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.6, n_estimators=30, total= 1.2min\n",
      "[CV] max_features=0.7, max_samples=0.6, n_estimators=40 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.6, n_estimators=40, total= 1.6min\n",
      "[CV] max_features=0.7, max_samples=0.6, n_estimators=40 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.6, n_estimators=40, total= 1.7min\n",
      "[CV] max_features=0.7, max_samples=0.6, n_estimators=40 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.6, n_estimators=40, total= 1.6min\n",
      "[CV] max_features=0.7, max_samples=0.6, n_estimators=40 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.6, n_estimators=40, total= 1.5min\n",
      "[CV] max_features=0.7, max_samples=0.6, n_estimators=40 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.6, n_estimators=40, total= 1.6min\n",
      "[CV] max_features=0.7, max_samples=0.6, n_estimators=50 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.6, n_estimators=50, total= 1.9min\n",
      "[CV] max_features=0.7, max_samples=0.6, n_estimators=50 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.6, n_estimators=50, total= 1.9min\n",
      "[CV] max_features=0.7, max_samples=0.6, n_estimators=50 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.6, n_estimators=50, total= 1.9min\n",
      "[CV] max_features=0.7, max_samples=0.6, n_estimators=50 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.6, n_estimators=50, total= 2.0min\n",
      "[CV] max_features=0.7, max_samples=0.6, n_estimators=50 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.6, n_estimators=50, total= 2.0min\n",
      "[CV] max_features=0.7, max_samples=0.6, n_estimators=60 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.6, n_estimators=60, total= 2.4min\n",
      "[CV] max_features=0.7, max_samples=0.6, n_estimators=60 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.6, n_estimators=60, total= 2.5min\n",
      "[CV] max_features=0.7, max_samples=0.6, n_estimators=60 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.6, n_estimators=60, total= 2.5min\n",
      "[CV] max_features=0.7, max_samples=0.6, n_estimators=60 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.6, n_estimators=60, total= 2.4min\n",
      "[CV] max_features=0.7, max_samples=0.6, n_estimators=60 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.6, n_estimators=60, total= 2.4min\n",
      "[CV] max_features=0.7, max_samples=0.6, n_estimators=70 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.6, n_estimators=70, total= 2.6min\n",
      "[CV] max_features=0.7, max_samples=0.6, n_estimators=70 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.6, n_estimators=70, total= 2.7min\n",
      "[CV] max_features=0.7, max_samples=0.6, n_estimators=70 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.6, n_estimators=70, total= 2.6min\n",
      "[CV] max_features=0.7, max_samples=0.6, n_estimators=70 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.6, n_estimators=70, total= 2.7min\n",
      "[CV] max_features=0.7, max_samples=0.6, n_estimators=70 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.6, n_estimators=70, total= 2.6min\n",
      "[CV] max_features=0.7, max_samples=0.7, n_estimators=30 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.7, n_estimators=30, total= 1.1min\n",
      "[CV] max_features=0.7, max_samples=0.7, n_estimators=30 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.7, n_estimators=30, total= 1.1min\n",
      "[CV] max_features=0.7, max_samples=0.7, n_estimators=30 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.7, n_estimators=30, total= 1.2min\n",
      "[CV] max_features=0.7, max_samples=0.7, n_estimators=30 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.7, n_estimators=30, total= 1.2min\n",
      "[CV] max_features=0.7, max_samples=0.7, n_estimators=30 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.7, n_estimators=30, total= 1.1min\n",
      "[CV] max_features=0.7, max_samples=0.7, n_estimators=40 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.7, n_estimators=40, total= 1.5min\n",
      "[CV] max_features=0.7, max_samples=0.7, n_estimators=40 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.7, n_estimators=40, total= 1.6min\n",
      "[CV] max_features=0.7, max_samples=0.7, n_estimators=40 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.7, n_estimators=40, total= 1.5min\n",
      "[CV] max_features=0.7, max_samples=0.7, n_estimators=40 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.7, n_estimators=40, total= 1.5min\n",
      "[CV] max_features=0.7, max_samples=0.7, n_estimators=40 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.7, n_estimators=40, total= 1.5min\n",
      "[CV] max_features=0.7, max_samples=0.7, n_estimators=50 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.7, n_estimators=50, total= 1.9min\n",
      "[CV] max_features=0.7, max_samples=0.7, n_estimators=50 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.7, n_estimators=50, total= 1.9min\n",
      "[CV] max_features=0.7, max_samples=0.7, n_estimators=50 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.7, n_estimators=50, total= 1.9min\n",
      "[CV] max_features=0.7, max_samples=0.7, n_estimators=50 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.7, n_estimators=50, total= 1.9min\n",
      "[CV] max_features=0.7, max_samples=0.7, n_estimators=50 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.7, n_estimators=50, total= 1.9min\n",
      "[CV] max_features=0.7, max_samples=0.7, n_estimators=60 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.7, n_estimators=60, total= 2.3min\n",
      "[CV] max_features=0.7, max_samples=0.7, n_estimators=60 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.7, n_estimators=60, total= 2.3min\n",
      "[CV] max_features=0.7, max_samples=0.7, n_estimators=60 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.7, n_estimators=60, total= 2.3min\n",
      "[CV] max_features=0.7, max_samples=0.7, n_estimators=60 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.7, n_estimators=60, total= 2.3min\n",
      "[CV] max_features=0.7, max_samples=0.7, n_estimators=60 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.7, n_estimators=60, total= 2.3min\n",
      "[CV] max_features=0.7, max_samples=0.7, n_estimators=70 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.7, n_estimators=70, total= 2.7min\n",
      "[CV] max_features=0.7, max_samples=0.7, n_estimators=70 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.7, n_estimators=70, total= 2.7min\n",
      "[CV] max_features=0.7, max_samples=0.7, n_estimators=70 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.7, n_estimators=70, total= 2.6min\n",
      "[CV] max_features=0.7, max_samples=0.7, n_estimators=70 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.7, n_estimators=70, total= 2.7min\n",
      "[CV] max_features=0.7, max_samples=0.7, n_estimators=70 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.7, n_estimators=70, total= 2.7min\n",
      "[CV] max_features=0.7, max_samples=0.8, n_estimators=30 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.8, n_estimators=30, total= 1.2min\n",
      "[CV] max_features=0.7, max_samples=0.8, n_estimators=30 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.8, n_estimators=30, total= 1.2min\n",
      "[CV] max_features=0.7, max_samples=0.8, n_estimators=30 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.8, n_estimators=30, total= 1.1min\n",
      "[CV] max_features=0.7, max_samples=0.8, n_estimators=30 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.8, n_estimators=30, total= 1.2min\n",
      "[CV] max_features=0.7, max_samples=0.8, n_estimators=30 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.8, n_estimators=30, total= 1.1min\n",
      "[CV] max_features=0.7, max_samples=0.8, n_estimators=40 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.8, n_estimators=40, total= 1.5min\n",
      "[CV] max_features=0.7, max_samples=0.8, n_estimators=40 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.8, n_estimators=40, total= 1.5min\n",
      "[CV] max_features=0.7, max_samples=0.8, n_estimators=40 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.8, n_estimators=40, total= 1.5min\n",
      "[CV] max_features=0.7, max_samples=0.8, n_estimators=40 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.8, n_estimators=40, total= 1.5min\n",
      "[CV] max_features=0.7, max_samples=0.8, n_estimators=40 ..............\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_features=0.7, max_samples=0.8, n_estimators=40, total= 1.5min\n",
      "[CV] max_features=0.7, max_samples=0.8, n_estimators=50 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.8, n_estimators=50, total= 1.9min\n",
      "[CV] max_features=0.7, max_samples=0.8, n_estimators=50 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.8, n_estimators=50, total= 1.9min\n",
      "[CV] max_features=0.7, max_samples=0.8, n_estimators=50 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.8, n_estimators=50, total= 1.9min\n",
      "[CV] max_features=0.7, max_samples=0.8, n_estimators=50 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.8, n_estimators=50, total= 1.9min\n",
      "[CV] max_features=0.7, max_samples=0.8, n_estimators=50 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.8, n_estimators=50, total= 1.9min\n",
      "[CV] max_features=0.7, max_samples=0.8, n_estimators=60 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.8, n_estimators=60, total= 2.3min\n",
      "[CV] max_features=0.7, max_samples=0.8, n_estimators=60 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.8, n_estimators=60, total= 2.3min\n",
      "[CV] max_features=0.7, max_samples=0.8, n_estimators=60 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.8, n_estimators=60, total= 2.3min\n",
      "[CV] max_features=0.7, max_samples=0.8, n_estimators=60 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.8, n_estimators=60, total= 2.3min\n",
      "[CV] max_features=0.7, max_samples=0.8, n_estimators=60 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.8, n_estimators=60, total= 2.3min\n",
      "[CV] max_features=0.7, max_samples=0.8, n_estimators=70 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.8, n_estimators=70, total= 2.7min\n",
      "[CV] max_features=0.7, max_samples=0.8, n_estimators=70 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.8, n_estimators=70, total= 2.7min\n",
      "[CV] max_features=0.7, max_samples=0.8, n_estimators=70 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.8, n_estimators=70, total= 2.7min\n",
      "[CV] max_features=0.7, max_samples=0.8, n_estimators=70 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.8, n_estimators=70, total= 2.7min\n",
      "[CV] max_features=0.7, max_samples=0.8, n_estimators=70 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.8, n_estimators=70, total= 2.7min\n",
      "[CV] max_features=0.75, max_samples=0.6, n_estimators=30 .............\n",
      "[CV]  max_features=0.75, max_samples=0.6, n_estimators=30, total= 1.3min\n",
      "[CV] max_features=0.75, max_samples=0.6, n_estimators=30 .............\n",
      "[CV]  max_features=0.75, max_samples=0.6, n_estimators=30, total= 1.2min\n",
      "[CV] max_features=0.75, max_samples=0.6, n_estimators=30 .............\n",
      "[CV]  max_features=0.75, max_samples=0.6, n_estimators=30, total= 1.3min\n",
      "[CV] max_features=0.75, max_samples=0.6, n_estimators=30 .............\n",
      "[CV]  max_features=0.75, max_samples=0.6, n_estimators=30, total= 1.3min\n",
      "[CV] max_features=0.75, max_samples=0.6, n_estimators=30 .............\n",
      "[CV]  max_features=0.75, max_samples=0.6, n_estimators=30, total= 1.3min\n",
      "[CV] max_features=0.75, max_samples=0.6, n_estimators=40 .............\n",
      "[CV]  max_features=0.75, max_samples=0.6, n_estimators=40, total= 1.7min\n",
      "[CV] max_features=0.75, max_samples=0.6, n_estimators=40 .............\n",
      "[CV]  max_features=0.75, max_samples=0.6, n_estimators=40, total= 1.7min\n",
      "[CV] max_features=0.75, max_samples=0.6, n_estimators=40 .............\n",
      "[CV]  max_features=0.75, max_samples=0.6, n_estimators=40, total= 1.7min\n",
      "[CV] max_features=0.75, max_samples=0.6, n_estimators=40 .............\n",
      "[CV]  max_features=0.75, max_samples=0.6, n_estimators=40, total= 1.7min\n",
      "[CV] max_features=0.75, max_samples=0.6, n_estimators=40 .............\n",
      "[CV]  max_features=0.75, max_samples=0.6, n_estimators=40, total= 1.7min\n",
      "[CV] max_features=0.75, max_samples=0.6, n_estimators=50 .............\n",
      "[CV]  max_features=0.75, max_samples=0.6, n_estimators=50, total= 2.1min\n",
      "[CV] max_features=0.75, max_samples=0.6, n_estimators=50 .............\n",
      "[CV]  max_features=0.75, max_samples=0.6, n_estimators=50, total= 2.1min\n",
      "[CV] max_features=0.75, max_samples=0.6, n_estimators=50 .............\n",
      "[CV]  max_features=0.75, max_samples=0.6, n_estimators=50, total= 2.1min\n",
      "[CV] max_features=0.75, max_samples=0.6, n_estimators=50 .............\n",
      "[CV]  max_features=0.75, max_samples=0.6, n_estimators=50, total= 2.1min\n",
      "[CV] max_features=0.75, max_samples=0.6, n_estimators=50 .............\n",
      "[CV]  max_features=0.75, max_samples=0.6, n_estimators=50, total= 2.1min\n",
      "[CV] max_features=0.75, max_samples=0.6, n_estimators=60 .............\n",
      "[CV]  max_features=0.75, max_samples=0.6, n_estimators=60, total= 2.5min\n",
      "[CV] max_features=0.75, max_samples=0.6, n_estimators=60 .............\n",
      "[CV]  max_features=0.75, max_samples=0.6, n_estimators=60, total= 2.5min\n",
      "[CV] max_features=0.75, max_samples=0.6, n_estimators=60 .............\n",
      "[CV]  max_features=0.75, max_samples=0.6, n_estimators=60, total= 2.5min\n",
      "[CV] max_features=0.75, max_samples=0.6, n_estimators=60 .............\n",
      "[CV]  max_features=0.75, max_samples=0.6, n_estimators=60, total= 2.5min\n",
      "[CV] max_features=0.75, max_samples=0.6, n_estimators=60 .............\n",
      "[CV]  max_features=0.75, max_samples=0.6, n_estimators=60, total= 2.5min\n",
      "[CV] max_features=0.75, max_samples=0.6, n_estimators=70 .............\n",
      "[CV]  max_features=0.75, max_samples=0.6, n_estimators=70, total= 2.9min\n",
      "[CV] max_features=0.75, max_samples=0.6, n_estimators=70 .............\n",
      "[CV]  max_features=0.75, max_samples=0.6, n_estimators=70, total= 2.9min\n",
      "[CV] max_features=0.75, max_samples=0.6, n_estimators=70 .............\n",
      "[CV]  max_features=0.75, max_samples=0.6, n_estimators=70, total= 2.9min\n",
      "[CV] max_features=0.75, max_samples=0.6, n_estimators=70 .............\n",
      "[CV]  max_features=0.75, max_samples=0.6, n_estimators=70, total= 2.9min\n",
      "[CV] max_features=0.75, max_samples=0.6, n_estimators=70 .............\n",
      "[CV]  max_features=0.75, max_samples=0.6, n_estimators=70, total= 2.9min\n",
      "[CV] max_features=0.75, max_samples=0.7, n_estimators=30 .............\n",
      "[CV]  max_features=0.75, max_samples=0.7, n_estimators=30, total= 1.3min\n",
      "[CV] max_features=0.75, max_samples=0.7, n_estimators=30 .............\n",
      "[CV]  max_features=0.75, max_samples=0.7, n_estimators=30, total= 1.2min\n",
      "[CV] max_features=0.75, max_samples=0.7, n_estimators=30 .............\n",
      "[CV]  max_features=0.75, max_samples=0.7, n_estimators=30, total= 1.2min\n",
      "[CV] max_features=0.75, max_samples=0.7, n_estimators=30 .............\n",
      "[CV]  max_features=0.75, max_samples=0.7, n_estimators=30, total= 1.3min\n",
      "[CV] max_features=0.75, max_samples=0.7, n_estimators=30 .............\n",
      "[CV]  max_features=0.75, max_samples=0.7, n_estimators=30, total= 1.2min\n",
      "[CV] max_features=0.75, max_samples=0.7, n_estimators=40 .............\n",
      "[CV]  max_features=0.75, max_samples=0.7, n_estimators=40, total= 1.7min\n",
      "[CV] max_features=0.75, max_samples=0.7, n_estimators=40 .............\n",
      "[CV]  max_features=0.75, max_samples=0.7, n_estimators=40, total= 1.7min\n",
      "[CV] max_features=0.75, max_samples=0.7, n_estimators=40 .............\n",
      "[CV]  max_features=0.75, max_samples=0.7, n_estimators=40, total= 1.7min\n",
      "[CV] max_features=0.75, max_samples=0.7, n_estimators=40 .............\n",
      "[CV]  max_features=0.75, max_samples=0.7, n_estimators=40, total= 1.7min\n",
      "[CV] max_features=0.75, max_samples=0.7, n_estimators=40 .............\n",
      "[CV]  max_features=0.75, max_samples=0.7, n_estimators=40, total= 1.7min\n",
      "[CV] max_features=0.75, max_samples=0.7, n_estimators=50 .............\n",
      "[CV]  max_features=0.75, max_samples=0.7, n_estimators=50, total= 2.1min\n",
      "[CV] max_features=0.75, max_samples=0.7, n_estimators=50 .............\n",
      "[CV]  max_features=0.75, max_samples=0.7, n_estimators=50, total= 2.1min\n",
      "[CV] max_features=0.75, max_samples=0.7, n_estimators=50 .............\n",
      "[CV]  max_features=0.75, max_samples=0.7, n_estimators=50, total= 2.1min\n",
      "[CV] max_features=0.75, max_samples=0.7, n_estimators=50 .............\n",
      "[CV]  max_features=0.75, max_samples=0.7, n_estimators=50, total= 2.1min\n",
      "[CV] max_features=0.75, max_samples=0.7, n_estimators=50 .............\n",
      "[CV]  max_features=0.75, max_samples=0.7, n_estimators=50, total= 2.1min\n",
      "[CV] max_features=0.75, max_samples=0.7, n_estimators=60 .............\n",
      "[CV]  max_features=0.75, max_samples=0.7, n_estimators=60, total= 2.5min\n",
      "[CV] max_features=0.75, max_samples=0.7, n_estimators=60 .............\n",
      "[CV]  max_features=0.75, max_samples=0.7, n_estimators=60, total= 2.5min\n",
      "[CV] max_features=0.75, max_samples=0.7, n_estimators=60 .............\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_features=0.75, max_samples=0.7, n_estimators=60, total= 2.5min\n",
      "[CV] max_features=0.75, max_samples=0.7, n_estimators=60 .............\n",
      "[CV]  max_features=0.75, max_samples=0.7, n_estimators=60, total= 2.5min\n",
      "[CV] max_features=0.75, max_samples=0.7, n_estimators=60 .............\n",
      "[CV]  max_features=0.75, max_samples=0.7, n_estimators=60, total= 2.5min\n",
      "[CV] max_features=0.75, max_samples=0.7, n_estimators=70 .............\n",
      "[CV]  max_features=0.75, max_samples=0.7, n_estimators=70, total= 2.9min\n",
      "[CV] max_features=0.75, max_samples=0.7, n_estimators=70 .............\n",
      "[CV]  max_features=0.75, max_samples=0.7, n_estimators=70, total= 2.9min\n",
      "[CV] max_features=0.75, max_samples=0.7, n_estimators=70 .............\n",
      "[CV]  max_features=0.75, max_samples=0.7, n_estimators=70, total= 2.9min\n",
      "[CV] max_features=0.75, max_samples=0.7, n_estimators=70 .............\n",
      "[CV]  max_features=0.75, max_samples=0.7, n_estimators=70, total= 2.9min\n",
      "[CV] max_features=0.75, max_samples=0.7, n_estimators=70 .............\n",
      "[CV]  max_features=0.75, max_samples=0.7, n_estimators=70, total= 2.9min\n",
      "[CV] max_features=0.75, max_samples=0.8, n_estimators=30 .............\n",
      "[CV]  max_features=0.75, max_samples=0.8, n_estimators=30, total= 1.3min\n",
      "[CV] max_features=0.75, max_samples=0.8, n_estimators=30 .............\n",
      "[CV]  max_features=0.75, max_samples=0.8, n_estimators=30, total= 1.3min\n",
      "[CV] max_features=0.75, max_samples=0.8, n_estimators=30 .............\n",
      "[CV]  max_features=0.75, max_samples=0.8, n_estimators=30, total= 1.3min\n",
      "[CV] max_features=0.75, max_samples=0.8, n_estimators=30 .............\n",
      "[CV]  max_features=0.75, max_samples=0.8, n_estimators=30, total= 1.3min\n",
      "[CV] max_features=0.75, max_samples=0.8, n_estimators=30 .............\n",
      "[CV]  max_features=0.75, max_samples=0.8, n_estimators=30, total= 1.3min\n",
      "[CV] max_features=0.75, max_samples=0.8, n_estimators=40 .............\n",
      "[CV]  max_features=0.75, max_samples=0.8, n_estimators=40, total= 1.7min\n",
      "[CV] max_features=0.75, max_samples=0.8, n_estimators=40 .............\n",
      "[CV]  max_features=0.75, max_samples=0.8, n_estimators=40, total= 1.7min\n",
      "[CV] max_features=0.75, max_samples=0.8, n_estimators=40 .............\n",
      "[CV]  max_features=0.75, max_samples=0.8, n_estimators=40, total= 1.7min\n",
      "[CV] max_features=0.75, max_samples=0.8, n_estimators=40 .............\n",
      "[CV]  max_features=0.75, max_samples=0.8, n_estimators=40, total= 1.7min\n",
      "[CV] max_features=0.75, max_samples=0.8, n_estimators=40 .............\n",
      "[CV]  max_features=0.75, max_samples=0.8, n_estimators=40, total= 1.7min\n",
      "[CV] max_features=0.75, max_samples=0.8, n_estimators=50 .............\n",
      "[CV]  max_features=0.75, max_samples=0.8, n_estimators=50, total= 2.1min\n",
      "[CV] max_features=0.75, max_samples=0.8, n_estimators=50 .............\n",
      "[CV]  max_features=0.75, max_samples=0.8, n_estimators=50, total= 2.1min\n",
      "[CV] max_features=0.75, max_samples=0.8, n_estimators=50 .............\n",
      "[CV]  max_features=0.75, max_samples=0.8, n_estimators=50, total= 2.1min\n",
      "[CV] max_features=0.75, max_samples=0.8, n_estimators=50 .............\n",
      "[CV]  max_features=0.75, max_samples=0.8, n_estimators=50, total= 2.1min\n",
      "[CV] max_features=0.75, max_samples=0.8, n_estimators=50 .............\n",
      "[CV]  max_features=0.75, max_samples=0.8, n_estimators=50, total= 2.1min\n",
      "[CV] max_features=0.75, max_samples=0.8, n_estimators=60 .............\n",
      "[CV]  max_features=0.75, max_samples=0.8, n_estimators=60, total= 2.5min\n",
      "[CV] max_features=0.75, max_samples=0.8, n_estimators=60 .............\n",
      "[CV]  max_features=0.75, max_samples=0.8, n_estimators=60, total= 2.5min\n",
      "[CV] max_features=0.75, max_samples=0.8, n_estimators=60 .............\n",
      "[CV]  max_features=0.75, max_samples=0.8, n_estimators=60, total= 2.5min\n",
      "[CV] max_features=0.75, max_samples=0.8, n_estimators=60 .............\n",
      "[CV]  max_features=0.75, max_samples=0.8, n_estimators=60, total= 2.5min\n",
      "[CV] max_features=0.75, max_samples=0.8, n_estimators=60 .............\n",
      "[CV]  max_features=0.75, max_samples=0.8, n_estimators=60, total= 2.6min\n",
      "[CV] max_features=0.75, max_samples=0.8, n_estimators=70 .............\n",
      "[CV]  max_features=0.75, max_samples=0.8, n_estimators=70, total= 3.0min\n",
      "[CV] max_features=0.75, max_samples=0.8, n_estimators=70 .............\n",
      "[CV]  max_features=0.75, max_samples=0.8, n_estimators=70, total= 2.9min\n",
      "[CV] max_features=0.75, max_samples=0.8, n_estimators=70 .............\n",
      "[CV]  max_features=0.75, max_samples=0.8, n_estimators=70, total= 2.9min\n",
      "[CV] max_features=0.75, max_samples=0.8, n_estimators=70 .............\n",
      "[CV]  max_features=0.75, max_samples=0.8, n_estimators=70, total= 2.9min\n",
      "[CV] max_features=0.75, max_samples=0.8, n_estimators=70 .............\n",
      "[CV]  max_features=0.75, max_samples=0.8, n_estimators=70, total= 3.0min\n",
      "[CV] max_features=0.8, max_samples=0.6, n_estimators=30 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.6, n_estimators=30, total= 1.3min\n",
      "[CV] max_features=0.8, max_samples=0.6, n_estimators=30 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.6, n_estimators=30, total= 1.2min\n",
      "[CV] max_features=0.8, max_samples=0.6, n_estimators=30 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.6, n_estimators=30, total= 1.3min\n",
      "[CV] max_features=0.8, max_samples=0.6, n_estimators=30 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.6, n_estimators=30, total= 1.3min\n",
      "[CV] max_features=0.8, max_samples=0.6, n_estimators=30 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.6, n_estimators=30, total= 1.3min\n",
      "[CV] max_features=0.8, max_samples=0.6, n_estimators=40 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.6, n_estimators=40, total= 1.7min\n",
      "[CV] max_features=0.8, max_samples=0.6, n_estimators=40 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.6, n_estimators=40, total= 1.7min\n",
      "[CV] max_features=0.8, max_samples=0.6, n_estimators=40 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.6, n_estimators=40, total= 1.7min\n",
      "[CV] max_features=0.8, max_samples=0.6, n_estimators=40 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.6, n_estimators=40, total= 1.7min\n",
      "[CV] max_features=0.8, max_samples=0.6, n_estimators=40 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.6, n_estimators=40, total= 1.7min\n",
      "[CV] max_features=0.8, max_samples=0.6, n_estimators=50 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.6, n_estimators=50, total= 2.1min\n",
      "[CV] max_features=0.8, max_samples=0.6, n_estimators=50 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.6, n_estimators=50, total= 2.1min\n",
      "[CV] max_features=0.8, max_samples=0.6, n_estimators=50 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.6, n_estimators=50, total= 2.1min\n",
      "[CV] max_features=0.8, max_samples=0.6, n_estimators=50 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.6, n_estimators=50, total= 2.1min\n",
      "[CV] max_features=0.8, max_samples=0.6, n_estimators=50 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.6, n_estimators=50, total= 2.1min\n",
      "[CV] max_features=0.8, max_samples=0.6, n_estimators=60 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.6, n_estimators=60, total= 2.5min\n",
      "[CV] max_features=0.8, max_samples=0.6, n_estimators=60 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.6, n_estimators=60, total= 2.5min\n",
      "[CV] max_features=0.8, max_samples=0.6, n_estimators=60 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.6, n_estimators=60, total= 2.5min\n",
      "[CV] max_features=0.8, max_samples=0.6, n_estimators=60 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.6, n_estimators=60, total= 2.5min\n",
      "[CV] max_features=0.8, max_samples=0.6, n_estimators=60 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.6, n_estimators=60, total= 2.5min\n",
      "[CV] max_features=0.8, max_samples=0.6, n_estimators=70 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.6, n_estimators=70, total= 3.0min\n",
      "[CV] max_features=0.8, max_samples=0.6, n_estimators=70 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.6, n_estimators=70, total= 2.9min\n",
      "[CV] max_features=0.8, max_samples=0.6, n_estimators=70 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.6, n_estimators=70, total= 2.9min\n",
      "[CV] max_features=0.8, max_samples=0.6, n_estimators=70 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.6, n_estimators=70, total= 2.9min\n",
      "[CV] max_features=0.8, max_samples=0.6, n_estimators=70 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.6, n_estimators=70, total= 2.9min\n",
      "[CV] max_features=0.8, max_samples=0.7, n_estimators=30 ..............\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_features=0.8, max_samples=0.7, n_estimators=30, total= 1.3min\n",
      "[CV] max_features=0.8, max_samples=0.7, n_estimators=30 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.7, n_estimators=30, total= 1.3min\n",
      "[CV] max_features=0.8, max_samples=0.7, n_estimators=30 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.7, n_estimators=30, total= 1.3min\n",
      "[CV] max_features=0.8, max_samples=0.7, n_estimators=30 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.7, n_estimators=30, total= 1.3min\n",
      "[CV] max_features=0.8, max_samples=0.7, n_estimators=30 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.7, n_estimators=30, total= 1.3min\n",
      "[CV] max_features=0.8, max_samples=0.7, n_estimators=40 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.7, n_estimators=40, total= 1.7min\n",
      "[CV] max_features=0.8, max_samples=0.7, n_estimators=40 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.7, n_estimators=40, total= 1.7min\n",
      "[CV] max_features=0.8, max_samples=0.7, n_estimators=40 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.7, n_estimators=40, total= 1.7min\n",
      "[CV] max_features=0.8, max_samples=0.7, n_estimators=40 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.7, n_estimators=40, total= 1.7min\n",
      "[CV] max_features=0.8, max_samples=0.7, n_estimators=40 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.7, n_estimators=40, total= 1.7min\n",
      "[CV] max_features=0.8, max_samples=0.7, n_estimators=50 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.7, n_estimators=50, total= 2.1min\n",
      "[CV] max_features=0.8, max_samples=0.7, n_estimators=50 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.7, n_estimators=50, total= 2.1min\n",
      "[CV] max_features=0.8, max_samples=0.7, n_estimators=50 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.7, n_estimators=50, total= 2.1min\n",
      "[CV] max_features=0.8, max_samples=0.7, n_estimators=50 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.7, n_estimators=50, total= 2.1min\n",
      "[CV] max_features=0.8, max_samples=0.7, n_estimators=50 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.7, n_estimators=50, total= 2.1min\n",
      "[CV] max_features=0.8, max_samples=0.7, n_estimators=60 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.7, n_estimators=60, total= 2.5min\n",
      "[CV] max_features=0.8, max_samples=0.7, n_estimators=60 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.7, n_estimators=60, total= 2.5min\n",
      "[CV] max_features=0.8, max_samples=0.7, n_estimators=60 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.7, n_estimators=60, total= 2.5min\n",
      "[CV] max_features=0.8, max_samples=0.7, n_estimators=60 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.7, n_estimators=60, total= 2.5min\n",
      "[CV] max_features=0.8, max_samples=0.7, n_estimators=60 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.7, n_estimators=60, total= 2.5min\n",
      "[CV] max_features=0.8, max_samples=0.7, n_estimators=70 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.7, n_estimators=70, total= 2.9min\n",
      "[CV] max_features=0.8, max_samples=0.7, n_estimators=70 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.7, n_estimators=70, total= 2.9min\n",
      "[CV] max_features=0.8, max_samples=0.7, n_estimators=70 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.7, n_estimators=70, total= 2.9min\n",
      "[CV] max_features=0.8, max_samples=0.7, n_estimators=70 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.7, n_estimators=70, total= 3.0min\n",
      "[CV] max_features=0.8, max_samples=0.7, n_estimators=70 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.7, n_estimators=70, total= 2.9min\n",
      "[CV] max_features=0.8, max_samples=0.8, n_estimators=30 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.8, n_estimators=30, total= 1.3min\n",
      "[CV] max_features=0.8, max_samples=0.8, n_estimators=30 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.8, n_estimators=30, total= 1.3min\n",
      "[CV] max_features=0.8, max_samples=0.8, n_estimators=30 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.8, n_estimators=30, total= 1.3min\n",
      "[CV] max_features=0.8, max_samples=0.8, n_estimators=30 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.8, n_estimators=30, total= 1.3min\n",
      "[CV] max_features=0.8, max_samples=0.8, n_estimators=30 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.8, n_estimators=30, total= 1.3min\n",
      "[CV] max_features=0.8, max_samples=0.8, n_estimators=40 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.8, n_estimators=40, total= 1.7min\n",
      "[CV] max_features=0.8, max_samples=0.8, n_estimators=40 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.8, n_estimators=40, total= 1.7min\n",
      "[CV] max_features=0.8, max_samples=0.8, n_estimators=40 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.8, n_estimators=40, total= 1.7min\n",
      "[CV] max_features=0.8, max_samples=0.8, n_estimators=40 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.8, n_estimators=40, total= 1.7min\n",
      "[CV] max_features=0.8, max_samples=0.8, n_estimators=40 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.8, n_estimators=40, total= 1.7min\n",
      "[CV] max_features=0.8, max_samples=0.8, n_estimators=50 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.8, n_estimators=50, total= 2.1min\n",
      "[CV] max_features=0.8, max_samples=0.8, n_estimators=50 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.8, n_estimators=50, total= 2.1min\n",
      "[CV] max_features=0.8, max_samples=0.8, n_estimators=50 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.8, n_estimators=50, total= 2.1min\n",
      "[CV] max_features=0.8, max_samples=0.8, n_estimators=50 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.8, n_estimators=50, total= 2.1min\n",
      "[CV] max_features=0.8, max_samples=0.8, n_estimators=50 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.8, n_estimators=50, total= 2.1min\n",
      "[CV] max_features=0.8, max_samples=0.8, n_estimators=60 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.8, n_estimators=60, total= 2.5min\n",
      "[CV] max_features=0.8, max_samples=0.8, n_estimators=60 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.8, n_estimators=60, total= 2.5min\n",
      "[CV] max_features=0.8, max_samples=0.8, n_estimators=60 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.8, n_estimators=60, total= 2.5min\n",
      "[CV] max_features=0.8, max_samples=0.8, n_estimators=60 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.8, n_estimators=60, total= 2.5min\n",
      "[CV] max_features=0.8, max_samples=0.8, n_estimators=60 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.8, n_estimators=60, total= 2.5min\n",
      "[CV] max_features=0.8, max_samples=0.8, n_estimators=70 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.8, n_estimators=70, total= 2.9min\n",
      "[CV] max_features=0.8, max_samples=0.8, n_estimators=70 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.8, n_estimators=70, total= 2.9min\n",
      "[CV] max_features=0.8, max_samples=0.8, n_estimators=70 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.8, n_estimators=70, total= 3.0min\n",
      "[CV] max_features=0.8, max_samples=0.8, n_estimators=70 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.8, n_estimators=70, total= 2.9min\n",
      "[CV] max_features=0.8, max_samples=0.8, n_estimators=70 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.8, n_estimators=70, total= 2.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 225 out of 225 | elapsed: 509.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=BaggingClassifier(base_estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.5, gamma=0.2, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=8, min_child_weight=2, missing=None,\n",
       "       n_estimators=345, n_jobs=-1, nthread=None,\n",
       "       ..._estimators=50, n_jobs=-1, oob_score=False,\n",
       "         random_state=None, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'max_features': [0.7, 0.75, 0.8], 'max_samples': [0.6, 0.7, 0.8], 'n_estimators': [30, 40, 50, 60, 70]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=2)"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_xgb_bagger.fit(x_train_base, y_train_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_features': 0.75, 'max_samples': 0.8, 'n_estimators': 40}\n",
      "0.772503097893139\n"
     ]
    }
   ],
   "source": [
    "print gs_xgb_bagger.best_params_\n",
    "print gs_xgb_bagger.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB Modeling\n",
    "\n",
    "With our tuned parameters, we'll now actually create, fit, train, and store predictions for the 3 XGBClassifier model variations described above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.68 s, sys: 3.77 ms, total: 2.68 s\n",
      "Wall time: 3.21 s\n",
      "CPU times: user 2.68 s, sys: 7.58 ms, total: 2.69 s\n",
      "Wall time: 3.22 s\n",
      "CPU times: user 2.72 s, sys: 11.7 ms, total: 2.73 s\n",
      "Wall time: 2.88 s\n",
      "CPU times: user 2.99 s, sys: 11.8 ms, total: 3 s\n",
      "Wall time: 3.16 s\n",
      "CPU times: user 2.92 s, sys: 7.83 ms, total: 2.93 s\n",
      "Wall time: 3.06 s\n"
     ]
    }
   ],
   "source": [
    "xgb_raw = get_tuned_xgb_copy(\"raw\")\n",
    "xgb_raw = train_and_save_base_learner_preds(xgb_raw, folds, x_train_raw, y_train_raw, test_raw, \"xgboost_raw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation score: 0.7679407487061665 +/- 0.0036097387764845133\n",
      "Raw scores: [0.76847903 0.76623869 0.76193105 0.7712841  0.77177087]\n"
     ]
    }
   ],
   "source": [
    "# There seems to be a parallelization issue w/ XGBClassifier when trying to obtain a CV score, thus we use only 1 core\n",
    "xgb_raw_cv = get_cross_val_score(xgb_raw, x_train_raw, y_train_raw, n_splits, run_parallel=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.27 s, sys: 1.46 s, total: 7.73 s\n",
      "Wall time: 1.94 s\n",
      "CPU times: user 5.98 s, sys: 1.41 s, total: 7.39 s\n",
      "Wall time: 1.87 s\n",
      "CPU times: user 6.12 s, sys: 1.51 s, total: 7.63 s\n",
      "Wall time: 1.98 s\n",
      "CPU times: user 6.13 s, sys: 1.55 s, total: 7.69 s\n",
      "Wall time: 2.05 s\n",
      "CPU times: user 6.08 s, sys: 1.49 s, total: 7.57 s\n",
      "Wall time: 1.94 s\n"
     ]
    }
   ],
   "source": [
    "xgb_base = get_tuned_xgb_copy(\"base\")\n",
    "xgb_base = train_and_save_base_learner_preds(xgb_base, folds, x_train_base, y_train_base, test_base, \"xgboost_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation score: 0.758965265001 +/- 0.0044137786577\n",
      "Raw scores: [ 0.76202306  0.75019668  0.76073913  0.76056439  0.76130306]\n"
     ]
    }
   ],
   "source": [
    "xgb_base_cv = get_cross_val_score(xgb_base, x_train_base, y_train_base, n_splits, run_parallel=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.09 s, sys: 1.56 s, total: 9.65 s\n",
      "Wall time: 2.27 s\n",
      "CPU times: user 7.81 s, sys: 1.47 s, total: 9.28 s\n",
      "Wall time: 2.2 s\n",
      "CPU times: user 8.01 s, sys: 1.47 s, total: 9.47 s\n",
      "Wall time: 2.16 s\n",
      "CPU times: user 8.02 s, sys: 1.48 s, total: 9.5 s\n",
      "Wall time: 2.18 s\n",
      "CPU times: user 8.09 s, sys: 1.51 s, total: 9.59 s\n",
      "Wall time: 2.19 s\n"
     ]
    }
   ],
   "source": [
    "xgb_poly = get_tuned_xgb_copy(\"poly\")\n",
    "xgb_poly = train_and_save_base_learner_preds(xgb_poly, folds, x_train_poly, y_train_poly, test_poly, \"xgboost_poly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation score: 0.745601533629 +/- 0.00395136757867\n",
      "Raw scores: [ 0.74112726  0.7418853   0.74615411  0.74670364  0.75213736]\n"
     ]
    }
   ],
   "source": [
    "xgb_poly_cv = get_cross_val_score(xgb_poly, x_train_poly, y_train_poly, n_splits, run_parallel=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Bagged (Using Base Fitted XGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 40s, sys: 237 ms, total: 1min 40s\n",
      "Wall time: 1min 44s\n",
      "CPU times: user 1min 38s, sys: 170 ms, total: 1min 38s\n",
      "Wall time: 1min 41s\n",
      "CPU times: user 1min 35s, sys: 236 ms, total: 1min 35s\n",
      "Wall time: 1min 38s\n",
      "CPU times: user 1min 36s, sys: 260 ms, total: 1min 36s\n",
      "Wall time: 1min 39s\n",
      "CPU times: user 1min 35s, sys: 229 ms, total: 1min 36s\n",
      "Wall time: 1min 40s\n"
     ]
    }
   ],
   "source": [
    "# Bagged classifier\n",
    "xgb_bag = BaggingClassifier(base_estimator=get_tuned_xgb_copy(\"base\"), **xgb_bag_params)\n",
    "xgb_bag = train_and_save_base_learner_preds(xgb_bag, folds, x_train_base, y_train_base, test_base, \"xgboost_bag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation score: 0.7680347140060597 +/- 0.006487042101997774\n",
      "Raw scores: [0.7719898  0.76970894 0.75715998 0.76518267 0.77613217]\n"
     ]
    }
   ],
   "source": [
    "xgb_bag_cv = get_cross_val_score(xgb_bag, x_train_base, y_train_base, n_splits, run_parallel=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.65 s, sys: 3.81 ms, total: 1.65 s\n",
      "Wall time: 1.91 s\n",
      "CPU times: user 1.61 s, sys: 3.86 ms, total: 1.61 s\n",
      "Wall time: 1.71 s\n",
      "CPU times: user 1.63 s, sys: 0 ns, total: 1.63 s\n",
      "Wall time: 1.89 s\n",
      "CPU times: user 1.63 s, sys: 15.6 ms, total: 1.64 s\n",
      "Wall time: 1.9 s\n",
      "CPU times: user 1.6 s, sys: 3.93 ms, total: 1.61 s\n",
      "Wall time: 1.7 s\n"
     ]
    }
   ],
   "source": [
    "xgb_reduced = get_tuned_xgb_copy(\"reduced\")\n",
    "xgb_reduced = train_and_save_base_learner_preds(xgb_reduced, folds, x_train_reduced, y_train_reduced, test_reduced, \"xgboost_reduced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation score: 0.7592580101765478 +/- 0.00403111282038657\n",
      "Raw scores: [0.75909812 0.76317025 0.75419874 0.75546917 0.76435377]\n"
     ]
    }
   ],
   "source": [
    "xgb_reduced_cv = get_cross_val_score(xgb_reduced, x_train_reduced, y_train_reduced, n_splits, run_parallel=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='entropy',\n",
       "           max_depth=6, max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=150, n_jobs=-1, oob_score=False, random_state=None,\n",
       "           verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'n_estimators': [150, 200, 250, 300, 350], 'max_depth': [6, 8, 10, 12]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "et_param_grid = {\n",
    "    \"max_depth\": range(6, 12 + 1, 2),\n",
    "    \"n_estimators\": range(150, 350 + 1, 50)\n",
    "}\n",
    "\n",
    "et = ExtraTreesClassifier(max_depth=6, n_estimators=150, n_jobs=-1, criterion=\"entropy\")\n",
    "gs_et = GridSearchCV(estimator=et, param_grid=et_param_grid, cv=n_splits, scoring=\"roc_auc\")\n",
    "gs_et.fit(x_train_base, y_train_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 250, 'max_depth': 12}\n",
      "0.657812396697\n"
     ]
    }
   ],
   "source": [
    "print gs_et.best_params_\n",
    "print gs_et.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='entropy',\n",
       "           max_depth=12, max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=250, n_jobs=-1, oob_score=False, random_state=None,\n",
       "           verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'max_depth': [12, 14, 16, 18, 20]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step two\n",
    "et_param_grid_2 = {\n",
    "    \"max_depth\": range(12, 20 + 1, 2)\n",
    "}\n",
    "\n",
    "et_2 = ExtraTreesClassifier(max_depth=12, n_estimators=250, n_jobs=-1, criterion=\"entropy\")\n",
    "gs_et_2 = GridSearchCV(estimator=et_2, param_grid=et_param_grid_2, cv=n_splits, scoring=\"roc_auc\")\n",
    "gs_et_2.fit(x_train_base, y_train_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 250, 'max_depth': 12}\n",
      "0.657812396697\n"
     ]
    }
   ],
   "source": [
    "print gs_et.best_params_\n",
    "print gs_et.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation score: 0.658994376998 +/- 0.0162024899885\n",
      "Raw scores: [ 0.66693004  0.65553248  0.67156773  0.62885771  0.67208392]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.66693004,  0.65553248,  0.67156773,  0.62885771,  0.67208392])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_cross_val_score(ExtraTreesClassifier(max_depth=12, n_estimators=250, n_jobs=-1, criterion=\"entropy\"), x_train_base, y_train_base, n_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.03 s, sys: 132 ms, total: 2.16 s\n",
      "Wall time: 925 ms\n",
      "CPU times: user 2.13 s, sys: 127 ms, total: 2.26 s\n",
      "Wall time: 948 ms\n",
      "CPU times: user 2.33 s, sys: 120 ms, total: 2.45 s\n",
      "Wall time: 1.08 s\n",
      "CPU times: user 2.18 s, sys: 121 ms, total: 2.31 s\n",
      "Wall time: 970 ms\n",
      "CPU times: user 2.1 s, sys: 110 ms, total: 2.21 s\n",
      "Wall time: 935 ms\n"
     ]
    }
   ],
   "source": [
    "et_base = ExtraTreesClassifier(max_depth=12, n_estimators=250, n_jobs=-1, criterion=\"entropy\")\n",
    "et_base = train_and_save_base_learner_preds(et_base, folds, x_train_base, y_train_base, test_base, \"extra_trees_base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaboostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ada_params = {\n",
    "    \"n_estimators\": 410,\n",
    "    \"learning_rate\": 1.7,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:  1.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=1.7, n_estimators=410, random_state=None),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_estimators': [409], 'learning_rate': [1.675, 1.7, 1.725]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_param_grid = {\n",
    "    \"learning_rate\": [1.675, 1.7, 1.725],\n",
    "    \"n_estimators\": range(409, 410, 411)\n",
    "}\n",
    "\n",
    "ada = AdaBoostClassifier(**ada_params)\n",
    "gs_ada = GridSearchCV(estimator=ada, param_grid=ada_param_grid, cv=n_splits, scoring=\"roc_auc\", verbose=1)\n",
    "gs_ada.fit(x_train_base, y_train_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 400, 'learning_rate': 1.6}\n",
      "0.7048120649813508\n"
     ]
    }
   ],
   "source": [
    "print gs_ada.best_params_\n",
    "print gs_ada.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 413, 'learning_rate': 1.65}\n",
      "0.7064952811706677\n"
     ]
    }
   ],
   "source": [
    "print gs_ada.best_params_\n",
    "print gs_ada.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 410, 'learning_rate': 1.7}\n",
      "0.7101570612471971\n"
     ]
    }
   ],
   "source": [
    "print gs_ada.best_params_\n",
    "print gs_ada.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.5 s, sys: 16 ms, total: 3.51 s\n",
      "Wall time: 4.21 s\n",
      "CPU times: user 3.47 s, sys: 36 Âµs, total: 3.47 s\n",
      "Wall time: 4 s\n",
      "CPU times: user 3.51 s, sys: 4.02 ms, total: 3.52 s\n",
      "Wall time: 3.6 s\n",
      "CPU times: user 3.47 s, sys: 68 Âµs, total: 3.47 s\n",
      "Wall time: 3.51 s\n",
      "CPU times: user 3.49 s, sys: 15 Âµs, total: 3.49 s\n",
      "Wall time: 3.83 s\n"
     ]
    }
   ],
   "source": [
    "ada_tuned = AdaBoostClassifier(**ada_params)\n",
    "ada_tuned = train_and_save_base_learner_preds(ada_tuned, folds, x_train_base, y_train_base, test_base, \"adaboost_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation score: 0.70863909472035 +/- 0.009432939045787084\n",
      "Raw scores: [0.72384353 0.70028701 0.69732999 0.70911501 0.71261994]\n"
     ]
    }
   ],
   "source": [
    "ada_tuned_cv = get_cross_val_score(ada_tuned, x_train_base, y_train_base, n_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNeighborsClassifier\n",
    "\n",
    "We'll train instances of KNeighbors with **n_neighbors** set to $2^n$ for **n = [1, 10]**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'n_neighbors'=2:  Cross validation score: 0.573434775043 +/- 0.0215055478114\n",
      "Raw scores: [ 0.56259454  0.59927742  0.59888489  0.54767778  0.55873925]\n",
      "'n_neighbors'=4:  Cross validation score: 0.590499136721 +/- 0.0217076333611\n",
      "Raw scores: [ 0.61750827  0.59411804  0.60925007  0.56118483  0.57043447]\n",
      "'n_neighbors'=8:  Cross validation score: 0.610623922154 +/- 0.0283743924322\n",
      "Raw scores: [ 0.65312922  0.60882293  0.62842129  0.5716876   0.59105856]\n",
      "'n_neighbors'=16:  Cross validation score: 0.624549248213 +/- 0.0129561138453\n",
      "Raw scores: [ 0.62794604  0.6354268   0.63109468  0.59914151  0.62913721]\n",
      "'n_neighbors'=32:  Cross validation score: 0.635463475798 +/- 0.0167329190449\n",
      "Raw scores: [ 0.64259775  0.63234569  0.64453252  0.60471873  0.65312269]\n",
      "'n_neighbors'=64:  Cross validation score: 0.626697022758 +/- 0.0260453337146\n",
      "Raw scores: [ 0.64346299  0.59740765  0.64831594  0.59261885  0.65167967]\n",
      "'n_neighbors'=128:  Cross validation score: 0.627894229991 +/- 0.0251870821371\n",
      "Raw scores: [ 0.64371286  0.59585022  0.63367943  0.60305662  0.66317202]\n",
      "'n_neighbors'=256:  Cross validation score: 0.62450318956 +/- 0.0214519569907\n",
      "Raw scores: [ 0.64017423  0.6006044   0.62072528  0.60406875  0.65694328]\n",
      "'n_neighbors'=512:  Cross validation score: 0.61037238551 +/- 0.0276870271816\n",
      "Raw scores: [ 0.63900088  0.5820131   0.61331291  0.57563732  0.64189772]\n",
      "'n_neighbors'=1024:  Cross validation score: 0.601517820762 +/- 0.0222069878259\n",
      "Raw scores: [ 0.62095236  0.57190201  0.61168963  0.57799078  0.62505433]\n"
     ]
    }
   ],
   "source": [
    "knn_models = dict()\n",
    "\n",
    "for n in range(1, 10 + 1):\n",
    "    knn_i = KNeighborsClassifier(n_neighbors=2**n, n_jobs=-1)\n",
    "    knn_i = train_and_save_base_learner_preds(knn_i, \n",
    "                                              folds, \n",
    "                                              x_train_base, \n",
    "                                              y_train_base, \n",
    "                                              test_base, \n",
    "                                              \"knn_{}\".format(2**n), \n",
    "                                              timeit=False)\n",
    "    knn_models[\"knn_{}\".format(2**n)] = knn_i\n",
    "    print (\"'n_neighbors'={}: \".format(2**n)),\n",
    "    get_cross_val_score(knn_i, x_train_base, y_train_base, n_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svc_base_params = {\n",
    "    \"C\": 5,\n",
    "    \"gamma\": 0.001,\n",
    "    \"random_state\": seed,\n",
    "    \"probability\": True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed: 15.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=42, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'C': [5, 10, 15, 20], 'gamma': [0, 0.001, 0.005]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_param_grid = {\n",
    "    \"C\": [5, 10, 15, 20],\n",
    "    \"gamma\": [0, 0.001, 0.005]\n",
    "}\n",
    "\n",
    "svc = SVC(**svc_base_params)\n",
    "\n",
    "gs_svc = GridSearchCV(estimator=svc, param_grid=svc_param_grid, cv=n_splits, scoring=\"roc_auc\", verbose=1, n_jobs=-1)\n",
    "gs_svc.fit(x_train_base, y_train_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'gamma': 0.001}\n",
      "0.5134521837313666\n"
     ]
    }
   ],
   "source": [
    "print gs_svc.best_params_\n",
    "print gs_svc.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 5, 'gamma': 0.001}\n",
      "0.5134521837313666\n"
     ]
    }
   ],
   "source": [
    "print gs_svc.best_params_\n",
    "print gs_svc.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 27s, sys: 3.51 ms, total: 1min 27s\n",
      "Wall time: 1min 47s\n",
      "CPU times: user 1min 21s, sys: 470 Âµs, total: 1min 21s\n",
      "Wall time: 1min 27s\n",
      "CPU times: user 1min 21s, sys: 18.9 ms, total: 1min 21s\n",
      "Wall time: 1min 32s\n",
      "CPU times: user 1min 20s, sys: 196 Âµs, total: 1min 20s\n",
      "Wall time: 1min 23s\n",
      "CPU times: user 1min 21s, sys: 7.98 ms, total: 1min 21s\n",
      "Wall time: 1min 25s\n"
     ]
    }
   ],
   "source": [
    "svc_base = SVC(**svc_base_params)\n",
    "svc_base = train_and_save_base_learner_preds(svc_base, folds, x_train_base, y_train_base, test_base, \"svc_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation score: 0.5134516567807748 +/- 0.002230529369057635\n",
      "Raw scores: [0.51432334 0.51557857 0.51432503 0.5138962  0.50913514]\n"
     ]
    }
   ],
   "source": [
    "svc_base_cv = get_cross_val_score(svc_base, x_train_base, y_train_base, n_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Choosing optimal base learners\n",
    "\n",
    "We'll first see how each base learner performs by itself, then display the pearson correlation matrix against each base learner's predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Process for parameters used for each base learner is documented in \"layer_1_models.ipynb\".\n",
    "rfc = RandomForestClassifier(criterion='entropy', max_depth=10, n_estimators=1000, n_jobs=-1)\n",
    "lr = LogisticRegression(C=100, tol=1e-05, solver=\"liblinear\")\n",
    "et = ExtraTreesClassifier(max_depth=12, n_estimators=250, n_jobs=-1, criterion=\"entropy\")\n",
    "ada_base = AdaBoostClassifier(n_estimators=410, learning_rate=1.7)\n",
    "svc_base = SVC(**svc_base_params)\n",
    "xgb_raw = get_tuned_xgb_copy(\"raw\")\n",
    "xgb_base = get_tuned_xgb_copy(\"base\")\n",
    "xgb_reduced = get_tuned_xgb_copy(\"reduced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_learners = {\n",
    "    \"svc_base\": svc_base,\n",
    "    \"rfc\": rfc,\n",
    "    \"lr\": lr,\n",
    "    \"et\": et,\n",
    "    \"ada\": ada_base,\n",
    "    \"xgb_raw\": xgb_raw,\n",
    "    \"xgb_base\": xgb_base,\n",
    "    \"xgb_reduced\": xgb_reduced\n",
    "}\n",
    "\n",
    "# base_learners.update(knn_models)\n",
    "\n",
    "all_preds = pd.DataFrame(np.zeros((test_base.shape[0], len(base_learners))), columns=list(base_learners.keys()))\n",
    "\n",
    "for name, model in base_learners.items():\n",
    "    model.fit(x_train_base, y_train_base)\n",
    "    all_preds[name] = model.predict_proba(test_base)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAokAAAIXCAYAAADwu8QSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncBpeiuzILqYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f55b65ee8d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_preds = all_preds.reindex_axis(sorted(all_preds.columns.values), axis=1)\n",
    "\n",
    "ax = corrmat(all_preds.corr())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excluding the correlation values of different XGB instances, we can see that a majority of the base learners aren't highly correlated, so an ensemble including **all** of these base learners will likely outperform any of the base learner's lone predictions, through combining each base learner's respective predictive \n",
    "strengths."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on my most recent Kaggle submissions, it seems ML-Ensemble produces better performing predictions. Because of this, I'll generate another set of meta features with the same tuned parameters, but predicting using mlens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mlens.ensemble import SuperLearner\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 56s, sys: 8.85 ms, total: 1min 56s\n",
      "Wall time: 1min 58s\n",
      "CPU times: user 1min 55s, sys: 679 Âµs, total: 1min 55s\n",
      "Wall time: 1min 57s\n",
      "CPU times: user 1min 55s, sys: 4.71 ms, total: 1min 55s\n",
      "Wall time: 1min 57s\n",
      "CPU times: user 1min 54s, sys: 8.45 ms, total: 1min 54s\n",
      "Wall time: 1min 55s\n",
      "CPU times: user 1min 55s, sys: 468 Âµs, total: 1min 55s\n",
      "Wall time: 1min 56s\n",
      "Cross validation score: 0.771108710694092 +/- 0.011731124909709916\n",
      "Raw scores: [0.76757834 0.78622451 0.75820418 0.75994142 0.78359511]\n",
      "CPU times: user 1min 33s, sys: 11.9 ms, total: 1min 33s\n",
      "Wall time: 1min 36s\n",
      "CPU times: user 1min 28s, sys: 26.1 ms, total: 1min 28s\n",
      "Wall time: 1min 39s\n",
      "CPU times: user 1min 29s, sys: 0 ns, total: 1min 29s\n",
      "Wall time: 1min 42s\n",
      "CPU times: user 1min 27s, sys: 18.2 ms, total: 1min 27s\n",
      "Wall time: 1min 36s\n",
      "CPU times: user 1min 28s, sys: 11.1 ms, total: 1min 28s\n",
      "Wall time: 1min 33s\n",
      "Cross validation score: 0.7670154592380092 +/- 0.013308737233868325\n",
      "Raw scores: [0.76937382 0.782539   0.74785842 0.75600689 0.77929917]\n",
      "CPU times: user 2min 13s, sys: 203 ms, total: 2min 13s\n",
      "Wall time: 2min 30s\n",
      "CPU times: user 2min 13s, sys: 242 ms, total: 2min 14s\n",
      "Wall time: 2min 33s\n",
      "CPU times: user 2min 14s, sys: 60.7 ms, total: 2min 14s\n",
      "Wall time: 2min 31s\n",
      "CPU times: user 2min 20s, sys: 117 ms, total: 2min 21s\n",
      "Wall time: 2min 28s\n",
      "CPU times: user 2min 14s, sys: 151 ms, total: 2min 14s\n",
      "Wall time: 2min 33s\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'y_train_poy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-a1c9bfed8f6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m                                                        \u001b[0mtimeit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                                                        mlens=True)\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mrf_poly_mlens_cv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_cross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrf_poly_mlens_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train_poly\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_poy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_splits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'y_train_poy' is not defined"
     ]
    }
   ],
   "source": [
    "rf_mlens = RandomForestClassifier(criterion='entropy', max_features=10, n_estimators=1000, n_jobs=-1)\n",
    "\n",
    "# Raw\n",
    "rf_raw_mlens = train_and_save_base_learner_preds(rf_mlens, \n",
    "                                                       folds, \n",
    "                                                       x_train_raw, y_train_raw, test_raw, \n",
    "                                                       \"random_forest_raw\",\n",
    "                                                       timeit=False, \n",
    "                                                       mlens=True)\n",
    "rf_raw_mlens_cv = get_cross_val_score(rf_raw_mlens, x_train_raw, y_train_raw, n_splits)\n",
    "\n",
    "# Log\n",
    "rf_log_mlens = train_and_save_base_learner_preds(rf_mlens, \n",
    "                                                       folds, \n",
    "                                                       x_train_log, y_train_log, test_log, \n",
    "                                                       \"random_forest_log\",\n",
    "                                                       timeit=False, \n",
    "                                                       mlens=True)\n",
    "rf_log_mlens_cv = get_cross_val_score(rf_log_mlens, x_train_log, y_train_log, n_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 16s, sys: 156 ms, total: 2min 16s\n",
      "Wall time: 2min 38s\n",
      "CPU times: user 2min 15s, sys: 40.2 ms, total: 2min 15s\n",
      "Wall time: 2min 31s\n",
      "CPU times: user 2min 13s, sys: 1.49 ms, total: 2min 13s\n",
      "Wall time: 2min 15s\n",
      "CPU times: user 2min 13s, sys: 1.39 ms, total: 2min 13s\n",
      "Wall time: 2min 15s\n",
      "CPU times: user 2min 13s, sys: 8.66 ms, total: 2min 13s\n",
      "Wall time: 2min 16s\n",
      "Cross validation score: 0.7630587133668844 +/- 0.016673517355080603\n",
      "Raw scores: [0.75718615 0.78210342 0.74633306 0.74603677 0.78363416]\n"
     ]
    }
   ],
   "source": [
    "# Typo lmao, just running the poly transformation in this block separately since it takes a while\n",
    "# Poly\n",
    "rf_poly_mlens = train_and_save_base_learner_preds(rf_mlens, \n",
    "                                                       folds, \n",
    "                                                       x_train_poly, y_train_poly, test_poly, \n",
    "                                                       \"random_forest_poly\",\n",
    "                                                       timeit=False, \n",
    "                                                       mlens=True)\n",
    "rf_poly_mlens_cv = get_cross_val_score(rf_poly_mlens, x_train_poly, y_train_poly, n_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 346 ms, sys: 7 Âµs, total: 346 ms\n",
      "Wall time: 384 ms\n",
      "CPU times: user 356 ms, sys: 0 ns, total: 356 ms\n",
      "Wall time: 399 ms\n",
      "CPU times: user 336 ms, sys: 0 ns, total: 336 ms\n",
      "Wall time: 362 ms\n",
      "CPU times: user 339 ms, sys: 0 ns, total: 339 ms\n",
      "Wall time: 365 ms\n",
      "CPU times: user 343 ms, sys: 0 ns, total: 343 ms\n",
      "Wall time: 368 ms\n",
      "Cross validation score: 0.5457534068030371 +/- 0.023000862577507126\n",
      "Raw scores: [0.5643436  0.55359772 0.50611494 0.53533056 0.56938022]\n"
     ]
    }
   ],
   "source": [
    "lr_mlens = LogisticRegression(C=100, tol=1e-05, solver=\"liblinear\", random_state=seed)\n",
    "\n",
    "# Log\n",
    "lr_log_mlens = train_and_save_base_learner_preds(lr_mlens,\n",
    "                                                       folds,\n",
    "                                                       x_train_log, y_train_log, test_log,\n",
    "                                                       \"logistic_regression_log\",\n",
    "                                                       mlens=True)\n",
    "lr_log_mlens_cv = get_cross_val_score(lr_log_mlens, x_train_log, y_train_log, n_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.92 s, sys: 27.5 ms, total: 9.95 s\n",
      "Wall time: 10.5 s\n",
      "CPU times: user 10.5 s, sys: 35.4 ms, total: 10.5 s\n",
      "Wall time: 10.7 s\n",
      "CPU times: user 10.4 s, sys: 31.5 ms, total: 10.5 s\n",
      "Wall time: 10.9 s\n",
      "CPU times: user 10.4 s, sys: 39.4 ms, total: 10.4 s\n",
      "Wall time: 10.6 s\n",
      "CPU times: user 10.4 s, sys: 35.4 ms, total: 10.4 s\n",
      "Wall time: 10.5 s\n",
      "Cross validation score: 0.7529464731081388 +/- 0.0049081599371427545\n",
      "Raw scores: [0.75409323 0.75685271 0.74511919 0.75873599 0.74993124]\n",
      "CPU times: user 8.39 s, sys: 27.6 ms, total: 8.42 s\n",
      "Wall time: 8.54 s\n",
      "CPU times: user 8.26 s, sys: 39.3 ms, total: 8.3 s\n",
      "Wall time: 8.39 s\n",
      "CPU times: user 8.22 s, sys: 35.4 ms, total: 8.25 s\n",
      "Wall time: 8.34 s\n",
      "CPU times: user 8.18 s, sys: 4 ms, total: 8.18 s\n",
      "Wall time: 8.28 s\n",
      "CPU times: user 8.22 s, sys: 19.7 ms, total: 8.24 s\n",
      "Wall time: 8.33 s\n",
      "Cross validation score: 0.7589652650008001 +/- 0.00441377865770259\n",
      "Raw scores: [0.76202306 0.75019668 0.76073913 0.76056439 0.76130306]\n",
      "CPU times: user 10.7 s, sys: 23.7 ms, total: 10.7 s\n",
      "Wall time: 11.1 s\n",
      "CPU times: user 12 s, sys: 59 ms, total: 12 s\n",
      "Wall time: 12.2 s\n",
      "CPU times: user 11 s, sys: 23.6 ms, total: 11 s\n",
      "Wall time: 11.3 s\n",
      "CPU times: user 10.9 s, sys: 27.5 ms, total: 10.9 s\n",
      "Wall time: 11.7 s\n",
      "CPU times: user 10.7 s, sys: 19.8 ms, total: 10.8 s\n",
      "Wall time: 10.9 s\n",
      "Cross validation score: 0.7456015336292732 +/- 0.003951367578665627\n",
      "Raw scores: [0.74112726 0.7418853  0.74615411 0.74670364 0.75213736]\n",
      "CPU times: user 5min 36s, sys: 1.11 s, total: 5min 37s\n",
      "Wall time: 5min 41s\n",
      "CPU times: user 5min 38s, sys: 1.34 s, total: 5min 39s\n",
      "Wall time: 5min 45s\n",
      "CPU times: user 5min 38s, sys: 1.15 s, total: 5min 39s\n",
      "Wall time: 5min 44s\n",
      "CPU times: user 5min 47s, sys: 1.08 s, total: 5min 48s\n",
      "Wall time: 6min\n",
      "CPU times: user 5min 29s, sys: 1.04 s, total: 5min 30s\n",
      "Wall time: 5min 40s\n",
      "Cross validation score: 0.7667638893323365 +/- 0.008399416315940707\n",
      "Raw scores: [0.76508644 0.77300615 0.75443848 0.7626148  0.77867358]\n"
     ]
    }
   ],
   "source": [
    "xgb_mlens = get_tuned_xgb_copy()\n",
    "\n",
    "# Raw\n",
    "xgb_raw_mlens = train_and_save_base_learner_preds(xgb_mlens,\n",
    "                                                  folds,\n",
    "                                                  x_train_raw, y_train_raw, test_raw,\n",
    "                                                   \"xgboost_raw\",\n",
    "                                                  mlens=True)\n",
    "xgb_raw_mlens_cv = get_cross_val_score(xgb_raw_mlens, x_train_raw, y_train_raw, n_splits, run_parallel=False)\n",
    "\n",
    "# Base\n",
    "xgb_base_mlens = train_and_save_base_learner_preds(xgb_mlens,\n",
    "                                                   folds,\n",
    "                                                   x_train_base, y_train_base, test_base,\n",
    "                                                   \"xgboost_base\",\n",
    "                                                   mlens=True)\n",
    "xgb_base_mlens_cv = get_cross_val_score(xgb_base_mlens, x_train_base, y_train_base, n_splits, run_parallel=False)\n",
    "\n",
    "# Poly\n",
    "xgb_poly_mlens = train_and_save_base_learner_preds(xgb_mlens,\n",
    "                                                   folds,\n",
    "                                                   x_train_poly, y_train_poly, test_poly,\n",
    "                                                   \"xgboost_poly\",\n",
    "                                                   mlens=True)\n",
    "xgb_poly_mlens_cv = get_cross_val_score(xgb_poly_mlens, x_train_poly, y_train_poly, n_splits, run_parallel=False)\n",
    "\n",
    "# Bag\n",
    "xgb_bag = BaggingClassifier(base_estimator=xgb_mlens, n_estimators=50, max_samples=0.7, max_features=0.75, \\\n",
    "                              bootstrap_features=True)\n",
    "\n",
    "xgb_bag_mlens = train_and_save_base_learner_preds(xgb_bag,\n",
    "                                                  folds,\n",
    "                                                  x_train_base, y_train_base, test_base,\n",
    "                                                  \"xgboost_bag\",\n",
    "                                                  mlens=True)\n",
    "xgb_bag_mlens_cv = get_cross_val_score(xgb_bag_mlens, x_train_base, y_train_base, n_splits, run_parallel=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.4 s, sys: 4.07 ms, total: 10.4 s\n",
      "Wall time: 10.5 s\n",
      "CPU times: user 9.92 s, sys: 176 Âµs, total: 9.92 s\n",
      "Wall time: 10 s\n",
      "CPU times: user 9.71 s, sys: 128 Âµs, total: 9.71 s\n",
      "Wall time: 9.79 s\n",
      "CPU times: user 9.65 s, sys: 187 Âµs, total: 9.65 s\n",
      "Wall time: 9.72 s\n",
      "CPU times: user 9.91 s, sys: 4.04 ms, total: 9.92 s\n",
      "Wall time: 10.3 s\n",
      "Cross validation score: 0.7041421557601281 +/- 0.011600286950032486\n",
      "Raw scores: [0.71407938 0.69589411 0.70874949 0.68574588 0.71624191]\n"
     ]
    }
   ],
   "source": [
    "ada_mlens = AdaBoostClassifier(n_estimators=395, learning_rate=1.55)\n",
    "\n",
    "# Base\n",
    "ada_base_mlens = train_and_save_base_learner_preds(ada_mlens, \n",
    "                                                   folds, \n",
    "                                                   x_train_base, y_train_base, test_base, \n",
    "                                                   \"adaboost_base\",\n",
    "                                                   mlens=True)\n",
    "ada_base_mlens_cv = get_cross_val_score(ada_base_mlens, x_train_base, y_train_base, n_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.32 s, sys: 47 Âµs, total: 3.32 s\n",
      "Wall time: 3.36 s\n",
      "CPU times: user 3.41 s, sys: 51 Âµs, total: 3.41 s\n",
      "Wall time: 3.45 s\n",
      "CPU times: user 3.35 s, sys: 53 Âµs, total: 3.35 s\n",
      "Wall time: 3.37 s\n",
      "CPU times: user 3.36 s, sys: 3.99 ms, total: 3.36 s\n",
      "Wall time: 3.39 s\n",
      "CPU times: user 3.45 s, sys: 63 Âµs, total: 3.45 s\n",
      "Wall time: 3.48 s\n",
      "Cross validation score: 0.6552834053985692 +/- 0.01665215010591389\n",
      "Raw scores: [0.66506618 0.64908158 0.67635906 0.62707827 0.65883194]\n"
     ]
    }
   ],
   "source": [
    "et_mlens = ExtraTreesClassifier(max_depth=12, n_estimators=250, n_jobs=-1, random_state=seed, criterion=\"entropy\")\n",
    "et_base_mlens = train_and_save_base_learner_preds(et_mlens, \n",
    "                                                  folds, \n",
    "                                                  x_train_base, y_train_base, test_base, \n",
    "                                                  \"extra_trees_base\",\n",
    "                                                  mlens=True)\n",
    "et_base_mlens_cv = get_cross_val_score(et_base_mlens, x_train_base, y_train_base, n_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
