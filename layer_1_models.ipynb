{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Learners\n",
    "\n",
    "Julian Domingo - jad5348\n",
    "\n",
    "This file contains my process for training my base learners and meta learner to predict the probability values for the target value **Y**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Computation / Data Analysis stuff\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import skew, probplot, norm, uniform, randint\n",
    "from scipy.special import boxcox1p\n",
    "\n",
    "# Modeling stuff\n",
    "from mlens.metrics import make_scorer\n",
    "from mlens.model_selection import Evaluator\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import (GridSearchCV, \n",
    "                                     StratifiedKFold,\n",
    "                                     cross_val_score)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import (RandomForestClassifier, \n",
    "                              AdaBoostClassifier, \n",
    "                              GradientBoostingClassifier, \n",
    "                              ExtraTreesClassifier,\n",
    "                              BaggingClassifier)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_validation import train_test_split, KFold\n",
    "\n",
    "# Plotting stuff\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "from mlens.visualization import corrmat\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "\n",
    "# Plotting visuals stuff\n",
    "%matplotlib inline\n",
    "mpl.style.use('ggplot')\n",
    "sns.set_style('white')\n",
    "\n",
    "# ignore warnings (i.e. deprecation warnings)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_ids = pd.read_csv(\"./data/raw/test.csv\")[[\"id\"]]\n",
    "train_y_cp = pd.read_csv(\"./data/raw/train.csv\")[\"Y\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_preds(filename):\n",
    "    train = pd.read_csv(\"./meta_features/train/train_{}.csv\".format(filename), index_col=0).as_matrix().ravel()\n",
    "    test = pd.read_csv(\"./meta_features/test/test_{}.csv\".format(filename), index_col=0).as_matrix().ravel()\n",
    "    \n",
    "    return train, test\n",
    "\n",
    "\n",
    "def get_data(filename):\n",
    "    train = pd.read_csv(\"./data/refined/train/train_{}.csv\".format(filename))\n",
    "    test = pd.read_csv(\"./data/refined/test/test_{}.csv\".format(filename))\n",
    "    \n",
    "    x_train = train.drop([\"Y\"], axis = 1)\n",
    "    y_train = train[\"Y\"]\n",
    "    \n",
    "    return train, test, x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_raw, test_raw, x_train_raw, y_train_raw = get_data(\"raw\")\n",
    "train_base, test_base, x_train_base, y_train_base = get_data(\"base\")\n",
    "train_log, test_log, x_train_log, y_train_log = get_data(\"log\")\n",
    "train_poly, test_poly, x_train_poly, y_train_poly = get_data(\"poly\")\n",
    "train_scaled, test_scaled, x_train_scaled, y_train_scaled = get_data(\"scaled\")\n",
    "train_reduced, test_reduced, x_train_reduced, y_train_reduced = get_data(\"reduced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F10</th>\n",
       "      <th>F11</th>\n",
       "      <th>F15</th>\n",
       "      <th>F16</th>\n",
       "      <th>F17</th>\n",
       "      <th>F18</th>\n",
       "      <th>F19</th>\n",
       "      <th>F20</th>\n",
       "      <th>F21</th>\n",
       "      <th>F22</th>\n",
       "      <th>F23</th>\n",
       "      <th>F24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>61385</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>118751</td>\n",
       "      <td>1000</td>\n",
       "      <td>32020</td>\n",
       "      <td>1</td>\n",
       "      <td>127959</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>119757</td>\n",
       "      <td>119100</td>\n",
       "      <td>1</td>\n",
       "      <td>118830</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>126461</td>\n",
       "      <td>1</td>\n",
       "      <td>46871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51329</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>120800</td>\n",
       "      <td>1000</td>\n",
       "      <td>130630</td>\n",
       "      <td>1</td>\n",
       "      <td>128342</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>138110</td>\n",
       "      <td>121149</td>\n",
       "      <td>1</td>\n",
       "      <td>118832</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>130296</td>\n",
       "      <td>1</td>\n",
       "      <td>42386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5522</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>118779</td>\n",
       "      <td>1000</td>\n",
       "      <td>303218</td>\n",
       "      <td>2</td>\n",
       "      <td>128299</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>119777</td>\n",
       "      <td>119126</td>\n",
       "      <td>1</td>\n",
       "      <td>118832</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>127063</td>\n",
       "      <td>1</td>\n",
       "      <td>23968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6754</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>123163</td>\n",
       "      <td>2000</td>\n",
       "      <td>19024</td>\n",
       "      <td>1</td>\n",
       "      <td>127968</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>270637</td>\n",
       "      <td>123511</td>\n",
       "      <td>1</td>\n",
       "      <td>118832</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15274</td>\n",
       "      <td>1</td>\n",
       "      <td>27555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16991</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>119193</td>\n",
       "      <td>1000</td>\n",
       "      <td>303218</td>\n",
       "      <td>1</td>\n",
       "      <td>128299</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>119777</td>\n",
       "      <td>119542</td>\n",
       "      <td>1</td>\n",
       "      <td>118832</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>133491</td>\n",
       "      <td>1</td>\n",
       "      <td>50260</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      F2  F3  F4      F5    F6      F7  F8     F10  F11  F15     F16     F17  \\\n",
       "0  61385   0  38  118751  1000   32020   1  127959    1    1  119757  119100   \n",
       "1  51329   0  41  120800  1000  130630   1  128342    2    1  138110  121149   \n",
       "2   5522   0  50  118779  1000  303218   2  128299    1    1  119777  119126   \n",
       "3   6754   0  45  123163  2000   19024   1  127968    1    2  270637  123511   \n",
       "4  16991   0  41  119193  1000  303218   1  128299    1    1  119777  119542   \n",
       "\n",
       "   F18     F19  F20  F21     F22  F23    F24  \n",
       "0    1  118830    1    1  126461    1  46871  \n",
       "1    1  118832    1    1  130296    1  42386  \n",
       "2    1  118832    1    2  127063    1  23968  \n",
       "3    1  118832    1    1   15274    1  27555  \n",
       "4    1  118832    1    1  133491    1  50260  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_base.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def show_pearson_corr(mapping, dict_vals_are_models=True):\n",
    "    if dict_vals_are_models:\n",
    "        all_preds = pd.DataFrame(np.zeros((test_base.shape[0], len(mapping))), columns=list(mapping.keys()))\n",
    "    else:\n",
    "        all_preds = pd.DataFrame(np.zeros((train_base.shape[0], len(mapping))), columns=list(mapping.keys()))\n",
    "    \n",
    "    for name, val in mapping.items():\n",
    "        if dict_vals_are_models:\n",
    "            val.fit(x_train_base, y_train_base)\n",
    "            all_preds[name] = val.predict_proba(test_base)[:,1]   \n",
    "        else:\n",
    "            all_preds[name] = val\n",
    "        \n",
    "    all_preds = all_preds.reindex_axis(sorted(all_preds.columns.values), axis=1)\n",
    "\n",
    "    ax = corrmat(all_preds.corr())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cross_val_score(model, x_train, y_train, n_folds, run_parallel=True):\n",
    "    if run_parallel:\n",
    "        cv = cross_val_score(model, x_train, y_train, cv = n_folds, scoring = \"roc_auc\", n_jobs = -1)\n",
    "    else:\n",
    "        cv = cross_val_score(model, x_train, y_train, cv = n_folds, scoring = \"roc_auc\")\n",
    "        \n",
    "    print(\"Cross validation score: {} +/- {}\\nRaw scores: {}\".format(str(np.mean(cv)), str(np.std(cv)), str(cv)))\n",
    "    return cv\n",
    "\n",
    "\n",
    "def train_and_save_base_learner_preds(model, folds, x_train, y_train, test, pred_filename, timeit=True, mlens=False):\n",
    "    # Train model on the folds defined\n",
    "    if mlens:\n",
    "        train_ids = x_train.index\n",
    "        test_ids = test.index\n",
    "        x_train = np.array(x_train)\n",
    "        y_train = np.array(y_train)\n",
    "        test = np.array(test)\n",
    "        \n",
    "        train_preds = np.zeros(x_train.shape[0])\n",
    "        test_preds = np.zeros(test.shape[0])\n",
    "        test_preds_iter = np.zeros((test.shape[0], len(folds)))\n",
    "        \n",
    "        stacker = SuperLearner(random_state=seed, scorer=roc_auc_score)\n",
    "        stacker.add(model, proba=True)\n",
    "        \n",
    "        for i, (train_indices, test_indices) in enumerate(folds):\n",
    "            xtr = x_train[train_indices]\n",
    "            xhold = x_train[test_indices]\n",
    "            ytr = y_train[train_indices]\n",
    "            \n",
    "            # Deletes the previous fit when \"warm_start\" is disabled (intended behavior)\n",
    "            %time stacker.fit(x_train, y_train)\n",
    "            \n",
    "            train_preds[test_indices] = stacker.predict_proba(xhold)[:,1]\n",
    "            test_preds_iter[:,i] = stacker.predict_proba(test)[:,1]\n",
    "        \n",
    "        test_preds[:] = test_preds_iter.mean(1)\n",
    "        \n",
    "        submission = pd.DataFrame({\"id\": train_ids, \"Y\": train_preds})\n",
    "        submission.to_csv(\"./meta_features/mlens/train/train_{}.csv\".format(pred_filename), index=False, columns=[\"id\", \"Y\"])   \n",
    "        \n",
    "        submission = pd.DataFrame({\"id\": test_ids, \"Y\": test_preds})\n",
    "        submission.to_csv(\"./meta_features/mlens/test/test_{}.csv\".format(pred_filename), index=False, columns=[\"id\", \"Y\"])   \n",
    "        \n",
    "        return model  \n",
    "    \n",
    "    else:\n",
    "        result = generate_out_of_folds_preds(model, folds, x_train, y_train, test, timeit)\n",
    "\n",
    "        train_preds_csv = pd.DataFrame(columns=[\"Y\"], index=x_train.index, data=result[\"train_preds\"])\n",
    "        train_preds_csv.to_csv(\"./meta_features/train/train_{}.csv\".format(pred_filename), index=False, columns=[\"id\", \"Y\"])\n",
    "\n",
    "        test_preds_csv = pd.DataFrame(columns=[\"Y\"], index=test.index, data=result[\"test_preds\"])\n",
    "        test_preds_csv.to_csv(\"./meta_features/test/test_{}.csv\".format(pred_filename), index=False, columns=[\"id\", \"Y\"])\n",
    "\n",
    "        return result[\"model\"]\n",
    "                          \n",
    "\n",
    "def generate_out_of_folds_preds(model, folds, x, y, test, timeit=True):\n",
    "    \"\"\" \n",
    "    Trains the model through (stratified) CV, and generates predictions from\n",
    "    the weighted average of each holdout's predictions.\n",
    "    \n",
    "    'train_preds' is the combination of all predictions from each holdout.\n",
    "    'test_preds' is the final predictions computed through the mean of each test prediction.\n",
    "    \n",
    "    \"\"\"\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    test = np.array(test)\n",
    "        \n",
    "    train_preds = np.zeros(x.shape[0])\n",
    "    test_preds = np.zeros(test.shape[0])\n",
    "    test_preds_iter = np.zeros((test.shape[0], len(folds)))\n",
    "    \n",
    "    for i, (train_indices, test_indices) in enumerate(folds):\n",
    "        x_train = x[train_indices]\n",
    "        x_holdout = x[test_indices]\n",
    "        y_train = y[train_indices]\n",
    "        \n",
    "        if timeit:\n",
    "            %time model.fit(x_train, y_train)\n",
    "        else:\n",
    "            model.fit(x_train, y_train)\n",
    "        \n",
    "        train_preds[test_indices] = model.predict_proba(x_holdout)[:,1]\n",
    "        test_preds_iter[:,i] = model.predict_proba(test)[:,1]\n",
    "        \n",
    "    test_preds[:] = test_preds_iter.mean(1)\n",
    "        \n",
    "    return {'model': model, 'train_preds': train_preds ,'test_preds': test_preds}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtain fold indices for base learner training.\n",
    "n_splits = 5\n",
    "folds = list(StratifiedKFold(n_splits, random_state=seed).split(x_train_base, y_train_base))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we want to use the **same** fold indices every time in order for our stacking ensemble to perform optimally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Learners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min, sys: 386 ms, total: 1min\n",
      "Wall time: 9.53 s\n",
      "CPU times: user 1min 1s, sys: 350 ms, total: 1min 2s\n",
      "Wall time: 9.71 s\n",
      "CPU times: user 1min 1s, sys: 337 ms, total: 1min 2s\n",
      "Wall time: 9.67 s\n",
      "CPU times: user 1min 4s, sys: 339 ms, total: 1min 4s\n",
      "Wall time: 9.94 s\n",
      "CPU times: user 1min 4s, sys: 355 ms, total: 1min 4s\n",
      "Wall time: 10 s\n",
      "Cross validation score: 0.763972140277 +/- 0.0126201727415\n",
      "Raw scores: [ 0.76663797  0.77985633  0.74617437  0.75311065  0.77408139]\n"
     ]
    }
   ],
   "source": [
    "rfc_log = RandomForestClassifier(criterion='entropy', max_features=10, n_estimators=1000, n_jobs=-1)\n",
    "rfc_log = train_and_save_base_learner_preds(rfc_log, folds, x_train_log, y_train_log, test_log, \"random_forest_log\")\n",
    "rfc_log_cv = get_cross_val_score(rfc_log, x_train_log, y_train_log, n_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Using Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=-1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'max_features': [9, 10, 11, 12], 'n_estimators': [1000, 1050, 1100], 'max_depth': [9, 10, 11]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_raw_grid = {\n",
    "    \"max_features\": range(9, 12 + 1),\n",
    "    \"n_estimators\": range(1000, 1100 + 1, 50),\n",
    "    \"max_depth\": range(9, 11 + 1)\n",
    "}\n",
    "\n",
    "rfc_raw = RandomForestClassifier(criterion='entropy', max_depth=10, n_estimators=1000, n_jobs=-1)\n",
    "\n",
    "gs_raw = GridSearchCV(estimator=rfc_raw, param_grid=rfc_raw_grid, cv=n_splits, scoring=\"roc_auc\", n_jobs=-1, verbose=1)\n",
    "gs_raw.fit(x_train_raw, y_train_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_features': 11, 'n_estimators': 1050, 'max_depth': 11}\n",
      "0.7561616541276784\n"
     ]
    }
   ],
   "source": [
    "print gs_raw.best_params_\n",
    "print gs_raw.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfc_raw = RandomForestClassifier(criterion='entropy', max_features=10, n_estimators=1000, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation score: 0.7695456125591551 +/- 0.012976891105761897\n",
      "Raw scores: [0.76927927 0.78441299 0.75467399 0.7555443  0.78381751]\n"
     ]
    }
   ],
   "source": [
    "# Using tuned parameters fitted on BASE data\n",
    "rfc_raw = train_and_save_base_learner_preds(rfc_raw, folds, x_train_raw, y_train_raw, test_raw, \"random_forest_raw\", timeit=False)\n",
    "rfc_raw_cv = get_cross_val_score(rfc_raw, x_train_raw, y_train_raw, n_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Using Polynomial Transformation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 32s, sys: 413 ms, total: 1min 32s\n",
      "Wall time: 16.1 s\n",
      "CPU times: user 1min 38s, sys: 398 ms, total: 1min 39s\n",
      "Wall time: 14.5 s\n",
      "CPU times: user 1min 36s, sys: 408 ms, total: 1min 37s\n",
      "Wall time: 15.3 s\n",
      "CPU times: user 1min 38s, sys: 646 ms, total: 1min 39s\n",
      "Wall time: 15.6 s\n",
      "CPU times: user 1min 40s, sys: 555 ms, total: 1min 41s\n",
      "Wall time: 15 s\n",
      "Cross validation score: 0.762157532882 +/- 0.0178247735886\n",
      "Raw scores: [ 0.74675429  0.78349288  0.74934748  0.74677624  0.78441678]\n"
     ]
    }
   ],
   "source": [
    "rfc_poly = RandomForestClassifier(criterion='entropy', max_features=10, n_estimators=1000, n_jobs=-1)\n",
    "rfc_poly = train_and_save_base_learner_preds(rfc_poly, folds, x_train_poly, y_train_poly, test_poly, \"random_forest_poly\")\n",
    "rfc_poly_cv = get_cross_val_score(rfc_poly, x_train_poly, y_train_poly, n_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Using Base Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=1000, n_jobs=-1, oob_score=False,\n",
       "            random_state=None, verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'max_features': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 'auto'], 'max_depth': [5, 6, 7, 8, 9, 10, 11, 12]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_param_grid = {\n",
    "    \"max_features\": [1, 3, 10]\n",
    "}\n",
    "\n",
    "rfc = RandomForestClassifier(criterion='entropy', max_depth=10, n_estimators=1000, n_jobs=-1)\n",
    "\n",
    "gs_rfc = GridSearchCV(estimator=rfc, param_grid=rfc_param_grid, cv=n_splits, scoring=\"roc_auc\")\n",
    "gs_rfc.fit(x_train_base, y_train_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_features': 6, 'max_depth': 12}\n"
     ]
    }
   ],
   "source": [
    "# So, we'll use 10 to be our max_features value.\n",
    "print gs_rfc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation score: 0.767653985688 +/- 0.0137592880393\n",
      "Raw scores: [ 0.76729217  0.78474473  0.74785336  0.7578412   0.78053847]\n"
     ]
    }
   ],
   "source": [
    "# Train with our optimized parameters.\n",
    "rfc = RandomForestClassifier(criterion='entropy', max_features=10, n_estimators=1000, n_jobs=-1)\n",
    "rfc = train_and_save_base_learner_preds(rfc, folds, x_train_base, y_train_base, test_base, \"random_forest_base\")\n",
    "rf_cv = get_cross_val_score(rfc, x_train_base, y_train_base, n_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Using Log Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 2s, sys: 511 ms, total: 1min 2s\n",
      "Wall time: 10.8 s\n",
      "CPU times: user 1min 4s, sys: 512 ms, total: 1min 4s\n",
      "Wall time: 11 s\n",
      "CPU times: user 1min 4s, sys: 498 ms, total: 1min 5s\n",
      "Wall time: 10.7 s\n",
      "CPU times: user 1min 4s, sys: 308 ms, total: 1min 5s\n",
      "Wall time: 10.1 s\n",
      "CPU times: user 1min 5s, sys: 413 ms, total: 1min 5s\n",
      "Wall time: 10.4 s\n",
      "Cross validation score: 0.766020138462 +/- 0.0113610765781\n",
      "Raw scores: [ 0.76509741  0.77783124  0.75289286  0.75429075  0.77998842]\n"
     ]
    }
   ],
   "source": [
    "rfc_log = RandomForestClassifier(criterion='entropy', max_features=10, n_estimators=1000, n_jobs=-1)\n",
    "rfc_log = train_and_save_base_learner_preds(rfc_log, folds, x_train_log, y_train_log, test_log, \"random_forest_log\")\n",
    "rfc_log_cv = get_cross_val_score(rfc_log, x_train_log, y_train_log, n_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oddly enough, the raw / no feature engineering data set has the highest public LB score when submitted to kaggle. However, this could potentially be overfitting with how much noise there is in the raw / no feature engineering data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what features RandomForestClassifier deemed most important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f55b94548d0>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsEAAAHfCAYAAACxhQUCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nH6ZfiLUyb/rbAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f55b9454f90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(index=x_train_raw.columns, data=rfc_raw.feature_importances_) \\\n",
    "    .drop([\"F1\", \"F9\", \"F12\", \"F13\", \"F14\"]) \\\n",
    "    .sort_values().plot(kind='barh', title='Variable Importances')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, we'll use the top 2 features, **F2** and **F24**, to use in our PolynomialFeature transformed data set. Generation of this data set can be found in **\"data_processing.ipynb\"** under the \"Transformations\" subsection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [0.01, 0.1, 1.0, 10, 100], 'tol': [1e-05, 0.0001, 0.001], 'solver': ['liblinear', 'sag']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_param_grid = {\n",
    "    \"tol\": [1e-5, 1e-4, 1e-3],\n",
    "    \"solver\": [\"liblinear\", \"sag\"], # For some reason, \"saga\" isn't allowed anymore.\n",
    "    \"C\": [0.01, 0.1, 1.0, 10, 100] # Inverse of regularization strength. Smaller values specify stronger regularization (must be pos float)\n",
    "}\n",
    "\n",
    "lr = LogisticRegression()\n",
    "\n",
    "gs_lr = GridSearchCV(estimator=lr, param_grid=lr_param_grid, cv=n_splits, scoring=\"roc_auc\")\n",
    "gs_lr.fit(x_train_log, y_train_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 100, 'tol': 1e-05, 'solver': 'liblinear'}\n",
      "0.545830385785\n"
     ]
    }
   ],
   "source": [
    "print gs_lr.best_params_\n",
    "print gs_lr.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation score: 0.545833322926 +/- 0.0230976755653\n",
      "Raw scores: [ 0.56433684  0.55349304  0.50612     0.53532381  0.56989291]\n"
     ]
    }
   ],
   "source": [
    "# Train with our optimized parameters.\n",
    "lr = LogisticRegression(C=100, tol=1e-05, solver=\"liblinear\")\n",
    "lr = train_and_save_base_learner_preds(lr, folds, x_train_log, y_train_log, test_log, \"logistic_regression_log\")\n",
    "lr_cv = get_cross_val_score(lr, x_train_log, y_train_log, n_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.91999531  0.93921733  0.91854823 ...,  0.92974219  0.92594105\n",
      "  0.94791889]\n"
     ]
    }
   ],
   "source": [
    "# Finally, predict our probabilities.\n",
    "lr.fit(x_train_log, y_train_log)\n",
    "lr_probs = lr.predict_proba(test_log)[:,1]\n",
    "print lr_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save a copy of the predictions\n",
    "submission = pd.DataFrame({\"id\": test_ids.id, \"Y\": lr_probs})\n",
    "submission.to_csv(\"./submissions/logistic_regression_lone.csv\", index=False, columns=[\"id\", \"Y\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logistic regressor scores are pretty bad, both in offline CV and when submitted to Kaggle. I'll choose to leave this base learner out of my ensemble."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Using Base Data\n",
    "###### Step 1: Optimize learning_rate & n_estimators\n",
    "1. max_depth = 5 : This should be between 3-10. Ive started with 5.\n",
    "2. min_child_weight = 1 : A smaller value is chosen because it is a highly imbalanced class problem and leaf nodes can have smaller size groups.\n",
    "3. gamma = 0 : A smaller value like 0.1-0.2 can also be chosen for starting. This will anyways be tuned later.\n",
    "4. subsample & colsample_bytree = 0.8 : This is a commonly used start value. Typical values range between 0.5-0.9.\n",
    "5. scale_pos_weight = 1: Because of high class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initial xgb parameters\n",
    "xgb_base_params = {\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"n_estimators\": 311,\n",
    "    \"max_depth\": 8,\n",
    "    \"min_child_weight\": 2,\n",
    "    \"gamma\": 0.2,\n",
    "    \"subsample\": 0.6,\n",
    "    \"colsample_bytree\": 0.5,\n",
    "    \"objective\": 'binary:logistic', # Used for classifier XGB\n",
    "    \"seed\": seed\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.5, gamma=0.2, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=8, min_child_weight=2, missing=None,\n",
       "       n_estimators=311, n_jobs=1, nthread=None,\n",
       "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=42, silent=True,\n",
       "       subsample=0.6),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_estimators': [300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_base_n_est = {\n",
    "    \"n_estimators\": range(300, 350)\n",
    "}\n",
    "\n",
    "xgb_base = XGBClassifier(**xgb_base_params)\n",
    "\n",
    "gs_base_n_est = GridSearchCV(estimator=xgb_base, param_grid=xgb_base_n_est, cv=n_splits, scoring=\"roc_auc\")\n",
    "gs_base_n_est.fit(x_train_base, y_train_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 311}\n",
      "0.7507398286576572\n"
     ]
    }
   ],
   "source": [
    "print gs_base_n_est.best_params_\n",
    "print gs_base_n_est.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 311}\n",
      "0.7507398286576572\n"
     ]
    }
   ],
   "source": [
    "# After first iteration\n",
    "print gs_base_n_est.best_params_\n",
    "print gs_base_n_est.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Step 2: Optimize max_depth & min_child_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_base_params[\"n_estimators\"] = 345"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# refit model with optimized params\n",
    "xgb_base = XGBClassifier(**xgb_base_params)\n",
    "\n",
    "xgb_base_param_grid = {\n",
    "    \"max_depth\": range(3, 9, 1),\n",
    "    \"min_child_weight\": range(1, 6, 2)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=5, min_child_weight=1, missing=None, n_estimators=345,\n",
       "       n_jobs=1, nthread=4, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=42, silent=True,\n",
       "       subsample=0.8),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'max_depth': [3, 4, 5, 6, 7, 8], 'min_child_weight': [1, 3, 5]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_xgb_base = GridSearchCV(estimator=xgb_base, param_grid=xgb_base_param_grid, cv=n_splits, scoring=\"roc_auc\")\n",
    "gs_xgb_base.fit(x_train_base, y_train_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 6, 'min_child_weight': 1}\n",
      "0.7527988661\n"
     ]
    }
   ],
   "source": [
    "print gs_xgb_base.best_params_\n",
    "print gs_xgb_base.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_base_params[\"max_depth\"] = 6\n",
    "xgb_base_params[\"min_child_weight\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# refit model with optimized params\n",
    "xgb_base = XGBClassifier(**xgb_base_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now look for optimum values by searching 1 above and 1 below the initial best parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_base_param_grid_2 = {\n",
    "    \"max_depth\": [8, 9, 10],\n",
    "    \"min_child_weight\": [0, 1, 2, 3, 4]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=6, min_child_weight=1, missing=None, n_estimators=345,\n",
       "       n_jobs=1, nthread=4, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=42, silent=True,\n",
       "       subsample=0.8),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'max_depth': [8, 9, 10], 'min_child_weight': [0, 1, 2, 3, 4]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_xgb_base_2 = GridSearchCV(estimator=xgb_base, param_grid=xgb_base_param_grid_2, cv=n_splits, scoring=\"roc_auc\")\n",
    "gs_xgb_base_2.fit(x_train_base, y_train_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 8, 'min_child_weight': 2}\n",
      "0.75347678825\n"
     ]
    }
   ],
   "source": [
    "print gs_xgb_base_2.best_params_\n",
    "print gs_xgb_base_2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Looks like we got a better max_depth!\n",
    "xgb_base_params[\"max_depth\"] = 8\n",
    "xgb_base_params[\"min_child_weight\"] = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure **min_child_weight** isn't just a local optimum, we'll test values larger than our initial test range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_base_param_grid_2b = {\n",
    "    \"min_child_weight\": [1, 2, 6, 8, 10, 12]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# refit model with optimized params\n",
    "xgb_base = XGBClassifier(**xgb_base_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=8, min_child_weight=2, missing=None, n_estimators=345,\n",
       "       n_jobs=1, nthread=4, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=42, silent=True,\n",
       "       subsample=0.8),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'min_child_weight': [1, 2, 6, 8, 10, 12]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_xgb_base_2b = GridSearchCV(estimator=xgb_base, param_grid=xgb_base_param_grid_2b, cv=n_splits, scoring=\"roc_auc\")\n",
    "gs_xgb_base_2b.fit(x_train_base, y_train_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min_child_weight': 2}\n",
      "0.75347678825\n"
     ]
    }
   ],
   "source": [
    "# Looks like we were right!\n",
    "print gs_xgb_base_2b.best_params_\n",
    "print gs_xgb_base_2b.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Step 3: Tune Gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_base_param_grid_3 = {\n",
    "    \"gamma\": [(i / 10.0) for i in range(0,5)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=8, min_child_weight=2, missing=None, n_estimators=345,\n",
       "       n_jobs=1, nthread=4, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=42, silent=True,\n",
       "       subsample=0.8),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'gamma': [0.0, 0.1, 0.2, 0.3, 0.4]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_xgb_base_3 = GridSearchCV(estimator=xgb_base, param_grid=xgb_base_param_grid_3, cv=n_splits, scoring=\"roc_auc\")\n",
    "gs_xgb_base_3.fit(x_train_base, y_train_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gamma': 0.2}\n",
      "0.755026850826\n"
     ]
    }
   ],
   "source": [
    "print gs_xgb_base_3.best_params_\n",
    "print gs_xgb_base_3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_base_params[\"gamma\"] = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Step 4: Tune subsample & colsample_bytree\n",
    "\n",
    "Like **max_depth**, we'll use a 2-step process of searching across **0.1** increments, then a **0.5** change above and below our initial optimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# refit model with optimized params\n",
    "xgb_base = XGBClassifier(**xgb_base_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step one\n",
    "xgb_base_param_grid_4a = {\n",
    "    \"subsample\": [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "#     \"colsample_bytree\": [0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "    \"colsample_bytree\": [0.1, 0.2, 0.3, 0.4, 0.5, 0.6]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0.2, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=8, min_child_weight=2, missing=None,\n",
       "       n_estimators=345, n_jobs=1, nthread=4, objective='binary:logistic',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=42, silent=True, subsample=0.8),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'subsample': [0.6, 0.7, 0.8, 0.9, 1.0], 'colsample_bytree': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_xgb_base_4a = GridSearchCV(estimator=xgb_base, param_grid=xgb_base_param_grid_4a, cv=n_splits, scoring=\"roc_auc\")\n",
    "gs_xgb_base_4a.fit(x_train_base, y_train_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subsample': 0.6, 'colsample_bytree': 0.5}\n",
      "0.758964979608\n"
     ]
    }
   ],
   "source": [
    "print gs_xgb_base_4a.best_params_\n",
    "print gs_xgb_base_4a.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_base_params[\"colsample_bytree\"] = 0.5\n",
    "xgb_base_params[\"subsample\"] = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# refit model with optimized params\n",
    "xgb_base = XGBClassifier(**xgb_base_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step two\n",
    "xgb_base_param_grid_4b = {\n",
    "    \"subsample\": [0.55, 0.6, 0.65],\n",
    "    \"colsample_bytree\": [0.45, 0.5, 0.55]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.5, gamma=0.2, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=8, min_child_weight=2, missing=None,\n",
       "       n_estimators=198, n_jobs=1, nthread=4, objective='binary:logistic',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=42, silent=True, subsample=0.6),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'subsample': [0.55, 0.6, 0.65], 'colsample_bytree': [0.45, 0.5, 0.55]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_xgb_base_4b = GridSearchCV(estimator=xgb_base, param_grid=xgb_base_param_grid_4b, cv=n_splits, scoring=\"roc_auc\")\n",
    "gs_xgb_base_4b.fit(x_train_base, y_train_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subsample': 0.6, 'colsample_bytree': 0.5}\n",
      "0.760606208777\n"
     ]
    }
   ],
   "source": [
    "print gs_xgb_base_4b.best_params_\n",
    "print gs_xgb_base_4b.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like our initial optimum for these two features were the best values.\n",
    "\n",
    "I'm going to go ahead and stop tuning additional parameters, as I don't want to potentially \"overtune\" my model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Using Reduced Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_reduced_params = {\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"n_estimators\": 223,\n",
    "    \"max_depth\": 7,\n",
    "    \"min_child_weight\": 1,\n",
    "    \"gamma\": 0,\n",
    "    \"subsample\": 0.8,\n",
    "    \"colsample_bytree\": 0.75,\n",
    "    \"objective\": 'binary:logistic', # Used for classifier XGB\n",
    "    \"seed\": seed    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.75, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=7, min_child_weight=1, missing=None, n_estimators=223,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=42, silent=True,\n",
       "       subsample=0.8),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_estimators': [215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_reduced_n_est = {\n",
    "    \"n_estimators\": range(215, 230)\n",
    "}\n",
    "\n",
    "xgb_reduced = XGBClassifier(**xgb_reduced_params)\n",
    "\n",
    "gs_reduced_n_est = GridSearchCV(estimator=xgb_reduced, param_grid=xgb_reduced_n_est, cv=n_splits, scoring=\"roc_auc\")\n",
    "gs_reduced_n_est.fit(x_train_reduced, y_train_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 220}\n",
      "0.7593967046522269\n"
     ]
    }
   ],
   "source": [
    "print gs_reduced_n_est.best_params_\n",
    "print gs_reduced_n_est.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 223}\n",
      "0.7599316268348643\n"
     ]
    }
   ],
   "source": [
    "# After 1st iteration\n",
    "print gs_reduced_n_est.best_params_\n",
    "print gs_reduced_n_est.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.75, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=7, min_child_weight=1, missing=None, n_estimators=223,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=42, silent=True,\n",
       "       subsample=0.8),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'max_depth': [6, 7, 8], 'min_child_weight': [0, 1, 2]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_reduced = XGBClassifier(**xgb_reduced_params)\n",
    "\n",
    "gs_md_mcw = {\n",
    "    \"max_depth\": range(6, 9),\n",
    "    \"min_child_weight\": range(0, 3)\n",
    "}\n",
    "\n",
    "gs_md_mcw = GridSearchCV(estimator=xgb_reduced, param_grid=gs_md_mcw, cv=n_splits, scoring=\"roc_auc\", verbose=1)\n",
    "gs_md_mcw.fit(x_train_reduced, y_train_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 7, 'min_child_weight': 1}\n",
      "0.7580583641939536\n"
     ]
    }
   ],
   "source": [
    "print gs_md_mcw.best_params_\n",
    "print gs_md_mcw.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 7, 'min_child_weight': 1}\n",
      "0.7592573880980192\n"
     ]
    }
   ],
   "source": [
    "print gs_md_mcw.best_params_\n",
    "print gs_md_mcw.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 7, 'min_child_weight': 1}\n",
      "0.7599316268348643\n"
     ]
    }
   ],
   "source": [
    "# After first iteration\n",
    "print gs_md_mcw.best_params_\n",
    "print gs_md_mcw.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.75, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=7, min_child_weight=1, missing=None, n_estimators=223,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=42, silent=True,\n",
       "       subsample=0.8),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'gamma': [0.0, 0.1, 0.2, 0.3, 0.4]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_reduced = XGBClassifier(**xgb_reduced_params)\n",
    "\n",
    "gs_gamma = {\n",
    "    \"gamma\": [(i / 10.0) for i in range(0, 5)]\n",
    "}\n",
    "\n",
    "gs_gamma = GridSearchCV(estimator=xgb_reduced, param_grid=gs_gamma, cv=n_splits, scoring=\"roc_auc\")\n",
    "gs_gamma.fit(x_train_reduced, y_train_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gamma': 0.0}\n",
      "0.7592573880980192\n"
     ]
    }
   ],
   "source": [
    "print gs_gamma.best_params_\n",
    "print gs_gamma.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gamma': 0.0}\n",
      "0.7599316268348643\n"
     ]
    }
   ],
   "source": [
    "# After first iteration\n",
    "print gs_gamma.best_params_\n",
    "print gs_gamma.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 44 candidates, totalling 220 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 220 out of 220 | elapsed:  5.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.75, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=7, min_child_weight=1, missing=None, n_estimators=223,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=42, silent=True,\n",
       "       subsample=0.8),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'subsample': [0.75, 0.8, 0.85, 0.9], 'colsample_bytree': [0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_reduced = XGBClassifier(**xgb_reduced_params)\n",
    "\n",
    "gs_ss_cb = {\n",
    "    \"subsample\": [0.75, 0.8, 0.85, 0.9],\n",
    "    \"colsample_bytree\": [0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8]\n",
    "}\n",
    "\n",
    "gs_ss_cb = GridSearchCV(estimator=xgb_reduced, param_grid=gs_ss_cb, cv=n_splits, scoring=\"roc_auc\", verbose=1)\n",
    "gs_ss_cb.fit(x_train_reduced, y_train_reduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subsample': 0.8, 'colsample_bytree': 0.75}\n",
      "0.7592573880980192\n"
     ]
    }
   ],
   "source": [
    "print gs_ss_cb.best_params_\n",
    "print gs_ss_cb.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subsample': 0.8, 'colsample_bytree': 0.75}\n",
      "0.7599316268348643\n"
     ]
    }
   ],
   "source": [
    "# After first iteration\n",
    "print gs_ss_cb.best_params_\n",
    "print gs_ss_cb.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Polynomial Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_poly_params = {\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"n_estimators\": 343,\n",
    "    \"max_depth\": 17,\n",
    "    \"min_child_weight\": 3,\n",
    "    \"gamma\": 0.2,\n",
    "    \"subsample\": 0.75,\n",
    "    \"colsample_bytree\": 0.35,\n",
    "    \"objective\": 'binary:logistic', # Used for classifier XGB\n",
    "    \"seed\": seed    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  5.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.35, gamma=0.2, learning_rate=0.05,\n",
       "       max_delta_step=0, max_depth=17, min_child_weight=3, missing=None,\n",
       "       n_estimators=339, n_jobs=1, nthread=None,\n",
       "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=42, silent=True,\n",
       "       subsample=0.75),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_estimators': [335, 336, 337, 338, 339, 340, 341, 342, 343, 344]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_poly_n_est = {\n",
    "    \"n_estimators\": range(335, 345)\n",
    "}\n",
    "\n",
    "xgb_poly = XGBClassifier(**xgb_poly_params)\n",
    "\n",
    "gs_poly_n_est = GridSearchCV(estimator=xgb_poly, param_grid=xgb_poly_n_est, cv=n_splits, scoring=\"roc_auc\", verbose=1)\n",
    "gs_poly_n_est.fit(x_train_poly, y_train_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 340}\n",
      "0.7511335078388837\n"
     ]
    }
   ],
   "source": [
    "print gs_poly_n_est.best_params_\n",
    "print gs_poly_n_est.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 339}\n",
      "0.7511949102193791\n"
     ]
    }
   ],
   "source": [
    "print gs_poly_n_est.best_params_\n",
    "print gs_poly_n_est.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 343}\n",
      "0.7541242814466971\n"
     ]
    }
   ],
   "source": [
    "# After first iteration\n",
    "print gs_poly_n_est.best_params_\n",
    "print gs_poly_n_est.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  5.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.35, gamma=0, learning_rate=0.05,\n",
       "       max_delta_step=0, max_depth=17, min_child_weight=3, missing=None,\n",
       "       n_estimators=339, n_jobs=1, nthread=None,\n",
       "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=42, silent=True,\n",
       "       subsample=0.75),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'max_depth': [16, 17, 18], 'min_child_weight': [3, 4]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_poly = XGBClassifier(**xgb_poly_params)\n",
    "\n",
    "gs_md_mcw = {\n",
    "    \"max_depth\": range(16, 18 + 1),\n",
    "    \"min_child_weight\": range(3, 5)\n",
    "}\n",
    "\n",
    "gs_md_mcw = GridSearchCV(estimator=xgb_poly, param_grid=gs_md_mcw, cv=n_splits, scoring=\"roc_auc\", verbose=1)\n",
    "gs_md_mcw.fit(x_train_poly, y_train_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 10, 'min_child_weight': 3}\n",
      "0.7491771519086454\n"
     ]
    }
   ],
   "source": [
    "print gs_md_mcw.best_params_\n",
    "print gs_md_mcw.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 13}\n",
      "0.7560657449943476\n"
     ]
    }
   ],
   "source": [
    "print gs_md_mcw.best_params_\n",
    "print gs_md_mcw.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 16}\n",
      "0.7591748820996025\n"
     ]
    }
   ],
   "source": [
    "print gs_md_mcw.best_params_\n",
    "print gs_md_mcw.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:  1.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.35, gamma=0, learning_rate=0.05,\n",
       "       max_delta_step=0, max_depth=17, min_child_weight=3, missing=None,\n",
       "       n_estimators=339, n_jobs=1, nthread=None,\n",
       "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=42, silent=True,\n",
       "       subsample=0.75),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'gamma': [0.15, 0.2, 0.25]}, pre_dispatch='2*n_jobs',\n",
       "       refit=True, return_train_score='warn', scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_poly = XGBClassifier(**xgb_poly_params)\n",
    "\n",
    "gs_gamma = {\n",
    "    \"gamma\": [0.15, 0.2, 0.25]\n",
    "}\n",
    "\n",
    "gs_gamma = GridSearchCV(estimator=xgb_poly, param_grid=gs_gamma, cv=n_splits, scoring=\"roc_auc\", verbose=1)\n",
    "gs_gamma.fit(x_train_poly, y_train_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gamma': 0.2}\n",
      "0.7540321882174835\n"
     ]
    }
   ],
   "source": [
    "print gs_gamma.best_params_\n",
    "print gs_gamma.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:  4.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.35, gamma=0.2, learning_rate=0.05,\n",
       "       max_delta_step=0, max_depth=16, min_child_weight=3, missing=None,\n",
       "       n_estimators=339, n_jobs=1, nthread=None,\n",
       "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=42, silent=True,\n",
       "       subsample=0.75),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'subsample': [0.7, 0.75, 0.8], 'colsample_bytree': [0.35, 0.4, 0.45]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_poly = XGBClassifier(**xgb_poly_params)\n",
    "\n",
    "gs_ss_cb = {\n",
    "    \"subsample\": [0.7, 0.75, 0.8],\n",
    "    \"colsample_bytree\": [0.35, 0.4, 0.45]\n",
    "}\n",
    "\n",
    "gs_ss_cb = GridSearchCV(estimator=xgb_poly, param_grid=gs_ss_cb, cv=n_splits, scoring=\"roc_auc\", verbose=1)\n",
    "gs_ss_cb.fit(x_train_poly, y_train_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subsample': 0.75, 'colsample_bytree': 0.45}\n",
      "0.7545884251782282\n"
     ]
    }
   ],
   "source": [
    "print gs_ss_cb.best_params_\n",
    "print gs_ss_cb.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:  4.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.35, gamma=0.2, learning_rate=0.05,\n",
       "       max_delta_step=0, max_depth=17, min_child_weight=3, missing=None,\n",
       "       n_estimators=339, n_jobs=1, nthread=None,\n",
       "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=42, silent=True,\n",
       "       subsample=0.75),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'learning_rate': [0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_poly = XGBClassifier(**xgb_poly_params)\n",
    "\n",
    "gs_learning = {\n",
    "    \"learning_rate\": [0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1]\n",
    "}\n",
    "\n",
    "gs_learning = GridSearchCV(estimator=xgb_poly, param_grid=gs_learning, cv=n_splits, scoring=\"roc_auc\", verbose=1)\n",
    "gs_learning.fit(x_train_poly, y_train_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.05}\n",
      "0.7540321882174835\n"
     ]
    }
   ],
   "source": [
    "print gs_learning.best_params_\n",
    "print gs_learning.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Using Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_raw_params = {\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"n_estimators\": 308,\n",
    "    \"max_depth\": 9,\n",
    "    \"min_child_weight\": 1,\n",
    "    \"gamma\": 0,\n",
    "    \"subsample\": 0.75,\n",
    "    \"colsample_bytree\": 0.35,\n",
    "    \"objective\": 'binary:logistic', # Used for classifier XGB\n",
    "    \"seed\": seed    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:  2.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.35, gamma=0, learning_rate=0.05,\n",
       "       max_delta_step=0, max_depth=9, min_child_weight=1, missing=None,\n",
       "       n_estimators=308, n_jobs=1, nthread=None,\n",
       "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=42, silent=True,\n",
       "       subsample=0.75),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_estimators': [300, 301, 302, 303, 304, 305, 306, 307, 308, 309]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_raw_n_est = {\n",
    "    \"n_estimators\": range(300, 310)\n",
    "}\n",
    "\n",
    "xgb_raw = XGBClassifier(**xgb_raw_params)\n",
    "\n",
    "gs_raw_n_est = GridSearchCV(estimator=xgb_raw, param_grid=xgb_raw_n_est, cv=n_splits, scoring=\"roc_auc\", verbose=1)\n",
    "gs_raw_n_est.fit(x_train_raw, y_train_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 304}\n",
      "0.7504375241872834\n"
     ]
    }
   ],
   "source": [
    "print gs_raw_n_est.best_params_\n",
    "print gs_raw_n_est.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 308}\n",
      "0.7679402811335971\n"
     ]
    }
   ],
   "source": [
    "# After first iteration\n",
    "print gs_raw_n_est.best_params_\n",
    "print gs_raw_n_est.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:  2.5min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.35, gamma=0, learning_rate=0.05,\n",
       "       max_delta_step=0, max_depth=9, min_child_weight=1, missing=None,\n",
       "       n_estimators=308, n_jobs=1, nthread=None,\n",
       "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=42, silent=True,\n",
       "       subsample=0.75),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'max_depth': [8, 9, 10], 'min_child_weight': [0, 1, 2]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_raw = XGBClassifier(**xgb_raw_params)\n",
    "\n",
    "gs_md_mcw = {\n",
    "    \"max_depth\": range(8, 10 + 1),\n",
    "    \"min_child_weight\": range(0, 2 + 1)\n",
    "}\n",
    "\n",
    "gs_md_mcw = GridSearchCV(estimator=xgb_raw, param_grid=gs_md_mcw, cv=n_splits, scoring=\"roc_auc\", verbose=1)\n",
    "gs_md_mcw.fit(x_train_raw, y_train_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 7, 'min_child_weight': 5}\n",
      "0.7497058693786715\n"
     ]
    }
   ],
   "source": [
    "print gs_md_mcw.best_params_\n",
    "print gs_md_mcw.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 9, 'min_child_weight': 4}\n",
      "0.7520580379865669\n"
     ]
    }
   ],
   "source": [
    "print gs_md_mcw.best_params_\n",
    "print gs_md_mcw.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 9, 'min_child_weight': 1}\n",
      "0.7544897211045654\n"
     ]
    }
   ],
   "source": [
    "print gs_md_mcw.best_params_\n",
    "print gs_md_mcw.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:  2.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.75, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=9, min_child_weight=1, missing=None, n_estimators=304,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=42, silent=True,\n",
       "       subsample=0.8),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'gamma': [0.0, 0.1, 0.2, 0.3, 0.4]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_raw = XGBClassifier(**xgb_raw_params)\n",
    "\n",
    "gs_gamma = {\n",
    "    \"gamma\": [(i / 10.0) for i in range(0, 5)]\n",
    "}\n",
    "\n",
    "gs_gamma = GridSearchCV(estimator=xgb_raw, param_grid=gs_gamma, cv=n_splits, scoring=\"roc_auc\", verbose=1)\n",
    "gs_gamma.fit(x_train_raw, y_train_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gamma': 0.0}\n",
      "0.7544897211045654\n"
     ]
    }
   ],
   "source": [
    "print gs_gamma.best_params_\n",
    "print gs_gamma.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:  3.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.35, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=9, min_child_weight=1, missing=None, n_estimators=304,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=42, silent=True,\n",
       "       subsample=0.75),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'subsample': [0.725, 0.75, 0.775], 'colsample_bytree': [0.325, 0.35, 0.375, 0.4]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_raw = XGBClassifier(**xgb_raw_params)\n",
    "\n",
    "gs_ss_cb = {\n",
    "    \"subsample\": [0.725, 0.75, 0.775],\n",
    "    \"colsample_bytree\": [0.325, 0.35, 0.375, 0.4]\n",
    "}\n",
    "\n",
    "gs_ss_cb = GridSearchCV(estimator=xgb_raw, param_grid=gs_ss_cb, cv=n_splits, scoring=\"roc_auc\", verbose=1)\n",
    "gs_ss_cb.fit(x_train_raw, y_train_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subsample': 0.75, 'colsample_bytree': 0.35}\n",
      "0.7634658845502256\n"
     ]
    }
   ],
   "source": [
    "print gs_ss_cb.best_params_\n",
    "print gs_ss_cb.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subsample': 0.75, 'colsample_bytree': 0.35}\n",
      "0.7634658845502256\n"
     ]
    }
   ],
   "source": [
    "print gs_ss_cb.best_params_\n",
    "print gs_ss_cb.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  40 out of  40 | elapsed:  2.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.35, gamma=0, learning_rate=0.05,\n",
       "       max_delta_step=0, max_depth=9, min_child_weight=1, missing=None,\n",
       "       n_estimators=304, n_jobs=1, nthread=None,\n",
       "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=42, silent=True,\n",
       "       subsample=0.75),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'learning_rate': [0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_raw = XGBClassifier(**xgb_raw_params)\n",
    "\n",
    "gs_learning = {\n",
    "    \"learning_rate\": [0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09]\n",
    "}\n",
    "\n",
    "gs_learning = GridSearchCV(estimator=xgb_raw, param_grid=gs_learning, cv=n_splits, scoring=\"roc_auc\", verbose=1)\n",
    "gs_learning.fit(x_train_raw, y_train_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.05}\n",
      "0.7676482138163261\n"
     ]
    }
   ],
   "source": [
    "print gs_learning.best_params_\n",
    "print gs_learning.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.05}\n",
      "0.7676482138163261\n"
     ]
    }
   ],
   "source": [
    "print gs_learning.best_params_\n",
    "print gs_learning.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Bagged Classifier Tuning (XGB Base Estimator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_tuned_xgb_copy(data):\n",
    "    \"\"\" \n",
    "    Returns a fresh copy of our parameter tuned XGBClassifier, in case someone\n",
    "    wants to re-run this notebook so the optimized parameters are saved.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        \"base\": XGBClassifier(learning_rate=0.1,\n",
    "                             n_estimators=345,\n",
    "                             max_depth=8,\n",
    "                             min_child_weight=2,\n",
    "                             gamma=0.2,\n",
    "                             subsample=0.6,\n",
    "                             colsample_bytree=0.5,\n",
    "                             objective=\"binary:logistic\",\n",
    "                             n_jobs=-1,\n",
    "                             random_state=seed),\n",
    "        \"reduced\": XGBClassifier(learning_rate=0.1,\n",
    "                                 n_estimators=223,\n",
    "                                 max_depth=7,\n",
    "                                 min_child_weight=1,\n",
    "                                 gamma=0,\n",
    "                                 subsample=0.8,\n",
    "                                 colsample_bytree=0.75,\n",
    "                                 objective=\"binary:logistic\",\n",
    "                                 n_jobs=-1,\n",
    "                                 random_state=seed),\n",
    "        \"raw\": XGBClassifier(learning_rate=0.05,\n",
    "                             n_estimators=308,\n",
    "                             max_depth=9,\n",
    "                             min_child_weight=1,\n",
    "                             gamma=0, \n",
    "                             subsample=0.75,\n",
    "                             colsample_bytree=0.35,\n",
    "                             objective=\"binary:logistic\",\n",
    "                             n_jobs=-1,\n",
    "                             random_state=seed)\n",
    "    }[data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_bag_params = {\n",
    "    \"n_estimators\": 40,\n",
    "    \"max_samples\": 0.8,\n",
    "    \"max_features\": 0.75\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bag_param_grid = {\n",
    "    \"max_samples\": [0.6, 0.7, 0.8,],\n",
    "    \"max_features\": [0.7, 0.75, 0.8],\n",
    "    \"n_estimators\": range(30, 70 + 1, 10)\n",
    "}\n",
    " \n",
    "xgb_bag = get_tuned_xgb_copy(\"base\")\n",
    "xgb_bagger = BaggingClassifier(base_estimator=xgb_bag, n_estimators=50, max_samples=0.7, max_features=0.75, \\\n",
    "                              bootstrap_features=True, n_jobs=-1)\n",
    "\n",
    "gs_xgb_bagger = GridSearchCV(estimator=xgb_bagger, param_grid=bag_param_grid, cv=n_splits, scoring=\"roc_auc\", verbose=2, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 45 candidates, totalling 225 fits\n",
      "[CV] max_features=0.7, max_samples=0.6, n_estimators=30 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.6, n_estimators=30, total= 1.3min\n",
      "[CV] max_features=0.7, max_samples=0.6, n_estimators=30 ..............\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:  1.4min remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_features=0.7, max_samples=0.6, n_estimators=30, total= 1.2min\n",
      "[CV] max_features=0.7, max_samples=0.6, n_estimators=30 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.6, n_estimators=30, total= 1.2min\n",
      "[CV] max_features=0.7, max_samples=0.6, n_estimators=30 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.6, n_estimators=30, total= 1.3min\n",
      "[CV] max_features=0.7, max_samples=0.6, n_estimators=30 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.6, n_estimators=30, total= 1.2min\n",
      "[CV] max_features=0.7, max_samples=0.6, n_estimators=40 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.6, n_estimators=40, total= 1.6min\n",
      "[CV] max_features=0.7, max_samples=0.6, n_estimators=40 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.6, n_estimators=40, total= 1.7min\n",
      "[CV] max_features=0.7, max_samples=0.6, n_estimators=40 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.6, n_estimators=40, total= 1.6min\n",
      "[CV] max_features=0.7, max_samples=0.6, n_estimators=40 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.6, n_estimators=40, total= 1.5min\n",
      "[CV] max_features=0.7, max_samples=0.6, n_estimators=40 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.6, n_estimators=40, total= 1.6min\n",
      "[CV] max_features=0.7, max_samples=0.6, n_estimators=50 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.6, n_estimators=50, total= 1.9min\n",
      "[CV] max_features=0.7, max_samples=0.6, n_estimators=50 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.6, n_estimators=50, total= 1.9min\n",
      "[CV] max_features=0.7, max_samples=0.6, n_estimators=50 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.6, n_estimators=50, total= 1.9min\n",
      "[CV] max_features=0.7, max_samples=0.6, n_estimators=50 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.6, n_estimators=50, total= 2.0min\n",
      "[CV] max_features=0.7, max_samples=0.6, n_estimators=50 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.6, n_estimators=50, total= 2.0min\n",
      "[CV] max_features=0.7, max_samples=0.6, n_estimators=60 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.6, n_estimators=60, total= 2.4min\n",
      "[CV] max_features=0.7, max_samples=0.6, n_estimators=60 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.6, n_estimators=60, total= 2.5min\n",
      "[CV] max_features=0.7, max_samples=0.6, n_estimators=60 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.6, n_estimators=60, total= 2.5min\n",
      "[CV] max_features=0.7, max_samples=0.6, n_estimators=60 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.6, n_estimators=60, total= 2.4min\n",
      "[CV] max_features=0.7, max_samples=0.6, n_estimators=60 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.6, n_estimators=60, total= 2.4min\n",
      "[CV] max_features=0.7, max_samples=0.6, n_estimators=70 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.6, n_estimators=70, total= 2.6min\n",
      "[CV] max_features=0.7, max_samples=0.6, n_estimators=70 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.6, n_estimators=70, total= 2.7min\n",
      "[CV] max_features=0.7, max_samples=0.6, n_estimators=70 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.6, n_estimators=70, total= 2.6min\n",
      "[CV] max_features=0.7, max_samples=0.6, n_estimators=70 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.6, n_estimators=70, total= 2.7min\n",
      "[CV] max_features=0.7, max_samples=0.6, n_estimators=70 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.6, n_estimators=70, total= 2.6min\n",
      "[CV] max_features=0.7, max_samples=0.7, n_estimators=30 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.7, n_estimators=30, total= 1.1min\n",
      "[CV] max_features=0.7, max_samples=0.7, n_estimators=30 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.7, n_estimators=30, total= 1.1min\n",
      "[CV] max_features=0.7, max_samples=0.7, n_estimators=30 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.7, n_estimators=30, total= 1.2min\n",
      "[CV] max_features=0.7, max_samples=0.7, n_estimators=30 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.7, n_estimators=30, total= 1.2min\n",
      "[CV] max_features=0.7, max_samples=0.7, n_estimators=30 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.7, n_estimators=30, total= 1.1min\n",
      "[CV] max_features=0.7, max_samples=0.7, n_estimators=40 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.7, n_estimators=40, total= 1.5min\n",
      "[CV] max_features=0.7, max_samples=0.7, n_estimators=40 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.7, n_estimators=40, total= 1.6min\n",
      "[CV] max_features=0.7, max_samples=0.7, n_estimators=40 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.7, n_estimators=40, total= 1.5min\n",
      "[CV] max_features=0.7, max_samples=0.7, n_estimators=40 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.7, n_estimators=40, total= 1.5min\n",
      "[CV] max_features=0.7, max_samples=0.7, n_estimators=40 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.7, n_estimators=40, total= 1.5min\n",
      "[CV] max_features=0.7, max_samples=0.7, n_estimators=50 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.7, n_estimators=50, total= 1.9min\n",
      "[CV] max_features=0.7, max_samples=0.7, n_estimators=50 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.7, n_estimators=50, total= 1.9min\n",
      "[CV] max_features=0.7, max_samples=0.7, n_estimators=50 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.7, n_estimators=50, total= 1.9min\n",
      "[CV] max_features=0.7, max_samples=0.7, n_estimators=50 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.7, n_estimators=50, total= 1.9min\n",
      "[CV] max_features=0.7, max_samples=0.7, n_estimators=50 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.7, n_estimators=50, total= 1.9min\n",
      "[CV] max_features=0.7, max_samples=0.7, n_estimators=60 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.7, n_estimators=60, total= 2.3min\n",
      "[CV] max_features=0.7, max_samples=0.7, n_estimators=60 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.7, n_estimators=60, total= 2.3min\n",
      "[CV] max_features=0.7, max_samples=0.7, n_estimators=60 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.7, n_estimators=60, total= 2.3min\n",
      "[CV] max_features=0.7, max_samples=0.7, n_estimators=60 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.7, n_estimators=60, total= 2.3min\n",
      "[CV] max_features=0.7, max_samples=0.7, n_estimators=60 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.7, n_estimators=60, total= 2.3min\n",
      "[CV] max_features=0.7, max_samples=0.7, n_estimators=70 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.7, n_estimators=70, total= 2.7min\n",
      "[CV] max_features=0.7, max_samples=0.7, n_estimators=70 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.7, n_estimators=70, total= 2.7min\n",
      "[CV] max_features=0.7, max_samples=0.7, n_estimators=70 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.7, n_estimators=70, total= 2.6min\n",
      "[CV] max_features=0.7, max_samples=0.7, n_estimators=70 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.7, n_estimators=70, total= 2.7min\n",
      "[CV] max_features=0.7, max_samples=0.7, n_estimators=70 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.7, n_estimators=70, total= 2.7min\n",
      "[CV] max_features=0.7, max_samples=0.8, n_estimators=30 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.8, n_estimators=30, total= 1.2min\n",
      "[CV] max_features=0.7, max_samples=0.8, n_estimators=30 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.8, n_estimators=30, total= 1.2min\n",
      "[CV] max_features=0.7, max_samples=0.8, n_estimators=30 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.8, n_estimators=30, total= 1.1min\n",
      "[CV] max_features=0.7, max_samples=0.8, n_estimators=30 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.8, n_estimators=30, total= 1.2min\n",
      "[CV] max_features=0.7, max_samples=0.8, n_estimators=30 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.8, n_estimators=30, total= 1.1min\n",
      "[CV] max_features=0.7, max_samples=0.8, n_estimators=40 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.8, n_estimators=40, total= 1.5min\n",
      "[CV] max_features=0.7, max_samples=0.8, n_estimators=40 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.8, n_estimators=40, total= 1.5min\n",
      "[CV] max_features=0.7, max_samples=0.8, n_estimators=40 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.8, n_estimators=40, total= 1.5min\n",
      "[CV] max_features=0.7, max_samples=0.8, n_estimators=40 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.8, n_estimators=40, total= 1.5min\n",
      "[CV] max_features=0.7, max_samples=0.8, n_estimators=40 ..............\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_features=0.7, max_samples=0.8, n_estimators=40, total= 1.5min\n",
      "[CV] max_features=0.7, max_samples=0.8, n_estimators=50 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.8, n_estimators=50, total= 1.9min\n",
      "[CV] max_features=0.7, max_samples=0.8, n_estimators=50 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.8, n_estimators=50, total= 1.9min\n",
      "[CV] max_features=0.7, max_samples=0.8, n_estimators=50 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.8, n_estimators=50, total= 1.9min\n",
      "[CV] max_features=0.7, max_samples=0.8, n_estimators=50 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.8, n_estimators=50, total= 1.9min\n",
      "[CV] max_features=0.7, max_samples=0.8, n_estimators=50 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.8, n_estimators=50, total= 1.9min\n",
      "[CV] max_features=0.7, max_samples=0.8, n_estimators=60 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.8, n_estimators=60, total= 2.3min\n",
      "[CV] max_features=0.7, max_samples=0.8, n_estimators=60 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.8, n_estimators=60, total= 2.3min\n",
      "[CV] max_features=0.7, max_samples=0.8, n_estimators=60 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.8, n_estimators=60, total= 2.3min\n",
      "[CV] max_features=0.7, max_samples=0.8, n_estimators=60 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.8, n_estimators=60, total= 2.3min\n",
      "[CV] max_features=0.7, max_samples=0.8, n_estimators=60 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.8, n_estimators=60, total= 2.3min\n",
      "[CV] max_features=0.7, max_samples=0.8, n_estimators=70 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.8, n_estimators=70, total= 2.7min\n",
      "[CV] max_features=0.7, max_samples=0.8, n_estimators=70 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.8, n_estimators=70, total= 2.7min\n",
      "[CV] max_features=0.7, max_samples=0.8, n_estimators=70 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.8, n_estimators=70, total= 2.7min\n",
      "[CV] max_features=0.7, max_samples=0.8, n_estimators=70 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.8, n_estimators=70, total= 2.7min\n",
      "[CV] max_features=0.7, max_samples=0.8, n_estimators=70 ..............\n",
      "[CV]  max_features=0.7, max_samples=0.8, n_estimators=70, total= 2.7min\n",
      "[CV] max_features=0.75, max_samples=0.6, n_estimators=30 .............\n",
      "[CV]  max_features=0.75, max_samples=0.6, n_estimators=30, total= 1.3min\n",
      "[CV] max_features=0.75, max_samples=0.6, n_estimators=30 .............\n",
      "[CV]  max_features=0.75, max_samples=0.6, n_estimators=30, total= 1.2min\n",
      "[CV] max_features=0.75, max_samples=0.6, n_estimators=30 .............\n",
      "[CV]  max_features=0.75, max_samples=0.6, n_estimators=30, total= 1.3min\n",
      "[CV] max_features=0.75, max_samples=0.6, n_estimators=30 .............\n",
      "[CV]  max_features=0.75, max_samples=0.6, n_estimators=30, total= 1.3min\n",
      "[CV] max_features=0.75, max_samples=0.6, n_estimators=30 .............\n",
      "[CV]  max_features=0.75, max_samples=0.6, n_estimators=30, total= 1.3min\n",
      "[CV] max_features=0.75, max_samples=0.6, n_estimators=40 .............\n",
      "[CV]  max_features=0.75, max_samples=0.6, n_estimators=40, total= 1.7min\n",
      "[CV] max_features=0.75, max_samples=0.6, n_estimators=40 .............\n",
      "[CV]  max_features=0.75, max_samples=0.6, n_estimators=40, total= 1.7min\n",
      "[CV] max_features=0.75, max_samples=0.6, n_estimators=40 .............\n",
      "[CV]  max_features=0.75, max_samples=0.6, n_estimators=40, total= 1.7min\n",
      "[CV] max_features=0.75, max_samples=0.6, n_estimators=40 .............\n",
      "[CV]  max_features=0.75, max_samples=0.6, n_estimators=40, total= 1.7min\n",
      "[CV] max_features=0.75, max_samples=0.6, n_estimators=40 .............\n",
      "[CV]  max_features=0.75, max_samples=0.6, n_estimators=40, total= 1.7min\n",
      "[CV] max_features=0.75, max_samples=0.6, n_estimators=50 .............\n",
      "[CV]  max_features=0.75, max_samples=0.6, n_estimators=50, total= 2.1min\n",
      "[CV] max_features=0.75, max_samples=0.6, n_estimators=50 .............\n",
      "[CV]  max_features=0.75, max_samples=0.6, n_estimators=50, total= 2.1min\n",
      "[CV] max_features=0.75, max_samples=0.6, n_estimators=50 .............\n",
      "[CV]  max_features=0.75, max_samples=0.6, n_estimators=50, total= 2.1min\n",
      "[CV] max_features=0.75, max_samples=0.6, n_estimators=50 .............\n",
      "[CV]  max_features=0.75, max_samples=0.6, n_estimators=50, total= 2.1min\n",
      "[CV] max_features=0.75, max_samples=0.6, n_estimators=50 .............\n",
      "[CV]  max_features=0.75, max_samples=0.6, n_estimators=50, total= 2.1min\n",
      "[CV] max_features=0.75, max_samples=0.6, n_estimators=60 .............\n",
      "[CV]  max_features=0.75, max_samples=0.6, n_estimators=60, total= 2.5min\n",
      "[CV] max_features=0.75, max_samples=0.6, n_estimators=60 .............\n",
      "[CV]  max_features=0.75, max_samples=0.6, n_estimators=60, total= 2.5min\n",
      "[CV] max_features=0.75, max_samples=0.6, n_estimators=60 .............\n",
      "[CV]  max_features=0.75, max_samples=0.6, n_estimators=60, total= 2.5min\n",
      "[CV] max_features=0.75, max_samples=0.6, n_estimators=60 .............\n",
      "[CV]  max_features=0.75, max_samples=0.6, n_estimators=60, total= 2.5min\n",
      "[CV] max_features=0.75, max_samples=0.6, n_estimators=60 .............\n",
      "[CV]  max_features=0.75, max_samples=0.6, n_estimators=60, total= 2.5min\n",
      "[CV] max_features=0.75, max_samples=0.6, n_estimators=70 .............\n",
      "[CV]  max_features=0.75, max_samples=0.6, n_estimators=70, total= 2.9min\n",
      "[CV] max_features=0.75, max_samples=0.6, n_estimators=70 .............\n",
      "[CV]  max_features=0.75, max_samples=0.6, n_estimators=70, total= 2.9min\n",
      "[CV] max_features=0.75, max_samples=0.6, n_estimators=70 .............\n",
      "[CV]  max_features=0.75, max_samples=0.6, n_estimators=70, total= 2.9min\n",
      "[CV] max_features=0.75, max_samples=0.6, n_estimators=70 .............\n",
      "[CV]  max_features=0.75, max_samples=0.6, n_estimators=70, total= 2.9min\n",
      "[CV] max_features=0.75, max_samples=0.6, n_estimators=70 .............\n",
      "[CV]  max_features=0.75, max_samples=0.6, n_estimators=70, total= 2.9min\n",
      "[CV] max_features=0.75, max_samples=0.7, n_estimators=30 .............\n",
      "[CV]  max_features=0.75, max_samples=0.7, n_estimators=30, total= 1.3min\n",
      "[CV] max_features=0.75, max_samples=0.7, n_estimators=30 .............\n",
      "[CV]  max_features=0.75, max_samples=0.7, n_estimators=30, total= 1.2min\n",
      "[CV] max_features=0.75, max_samples=0.7, n_estimators=30 .............\n",
      "[CV]  max_features=0.75, max_samples=0.7, n_estimators=30, total= 1.2min\n",
      "[CV] max_features=0.75, max_samples=0.7, n_estimators=30 .............\n",
      "[CV]  max_features=0.75, max_samples=0.7, n_estimators=30, total= 1.3min\n",
      "[CV] max_features=0.75, max_samples=0.7, n_estimators=30 .............\n",
      "[CV]  max_features=0.75, max_samples=0.7, n_estimators=30, total= 1.2min\n",
      "[CV] max_features=0.75, max_samples=0.7, n_estimators=40 .............\n",
      "[CV]  max_features=0.75, max_samples=0.7, n_estimators=40, total= 1.7min\n",
      "[CV] max_features=0.75, max_samples=0.7, n_estimators=40 .............\n",
      "[CV]  max_features=0.75, max_samples=0.7, n_estimators=40, total= 1.7min\n",
      "[CV] max_features=0.75, max_samples=0.7, n_estimators=40 .............\n",
      "[CV]  max_features=0.75, max_samples=0.7, n_estimators=40, total= 1.7min\n",
      "[CV] max_features=0.75, max_samples=0.7, n_estimators=40 .............\n",
      "[CV]  max_features=0.75, max_samples=0.7, n_estimators=40, total= 1.7min\n",
      "[CV] max_features=0.75, max_samples=0.7, n_estimators=40 .............\n",
      "[CV]  max_features=0.75, max_samples=0.7, n_estimators=40, total= 1.7min\n",
      "[CV] max_features=0.75, max_samples=0.7, n_estimators=50 .............\n",
      "[CV]  max_features=0.75, max_samples=0.7, n_estimators=50, total= 2.1min\n",
      "[CV] max_features=0.75, max_samples=0.7, n_estimators=50 .............\n",
      "[CV]  max_features=0.75, max_samples=0.7, n_estimators=50, total= 2.1min\n",
      "[CV] max_features=0.75, max_samples=0.7, n_estimators=50 .............\n",
      "[CV]  max_features=0.75, max_samples=0.7, n_estimators=50, total= 2.1min\n",
      "[CV] max_features=0.75, max_samples=0.7, n_estimators=50 .............\n",
      "[CV]  max_features=0.75, max_samples=0.7, n_estimators=50, total= 2.1min\n",
      "[CV] max_features=0.75, max_samples=0.7, n_estimators=50 .............\n",
      "[CV]  max_features=0.75, max_samples=0.7, n_estimators=50, total= 2.1min\n",
      "[CV] max_features=0.75, max_samples=0.7, n_estimators=60 .............\n",
      "[CV]  max_features=0.75, max_samples=0.7, n_estimators=60, total= 2.5min\n",
      "[CV] max_features=0.75, max_samples=0.7, n_estimators=60 .............\n",
      "[CV]  max_features=0.75, max_samples=0.7, n_estimators=60, total= 2.5min\n",
      "[CV] max_features=0.75, max_samples=0.7, n_estimators=60 .............\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_features=0.75, max_samples=0.7, n_estimators=60, total= 2.5min\n",
      "[CV] max_features=0.75, max_samples=0.7, n_estimators=60 .............\n",
      "[CV]  max_features=0.75, max_samples=0.7, n_estimators=60, total= 2.5min\n",
      "[CV] max_features=0.75, max_samples=0.7, n_estimators=60 .............\n",
      "[CV]  max_features=0.75, max_samples=0.7, n_estimators=60, total= 2.5min\n",
      "[CV] max_features=0.75, max_samples=0.7, n_estimators=70 .............\n",
      "[CV]  max_features=0.75, max_samples=0.7, n_estimators=70, total= 2.9min\n",
      "[CV] max_features=0.75, max_samples=0.7, n_estimators=70 .............\n",
      "[CV]  max_features=0.75, max_samples=0.7, n_estimators=70, total= 2.9min\n",
      "[CV] max_features=0.75, max_samples=0.7, n_estimators=70 .............\n",
      "[CV]  max_features=0.75, max_samples=0.7, n_estimators=70, total= 2.9min\n",
      "[CV] max_features=0.75, max_samples=0.7, n_estimators=70 .............\n",
      "[CV]  max_features=0.75, max_samples=0.7, n_estimators=70, total= 2.9min\n",
      "[CV] max_features=0.75, max_samples=0.7, n_estimators=70 .............\n",
      "[CV]  max_features=0.75, max_samples=0.7, n_estimators=70, total= 2.9min\n",
      "[CV] max_features=0.75, max_samples=0.8, n_estimators=30 .............\n",
      "[CV]  max_features=0.75, max_samples=0.8, n_estimators=30, total= 1.3min\n",
      "[CV] max_features=0.75, max_samples=0.8, n_estimators=30 .............\n",
      "[CV]  max_features=0.75, max_samples=0.8, n_estimators=30, total= 1.3min\n",
      "[CV] max_features=0.75, max_samples=0.8, n_estimators=30 .............\n",
      "[CV]  max_features=0.75, max_samples=0.8, n_estimators=30, total= 1.3min\n",
      "[CV] max_features=0.75, max_samples=0.8, n_estimators=30 .............\n",
      "[CV]  max_features=0.75, max_samples=0.8, n_estimators=30, total= 1.3min\n",
      "[CV] max_features=0.75, max_samples=0.8, n_estimators=30 .............\n",
      "[CV]  max_features=0.75, max_samples=0.8, n_estimators=30, total= 1.3min\n",
      "[CV] max_features=0.75, max_samples=0.8, n_estimators=40 .............\n",
      "[CV]  max_features=0.75, max_samples=0.8, n_estimators=40, total= 1.7min\n",
      "[CV] max_features=0.75, max_samples=0.8, n_estimators=40 .............\n",
      "[CV]  max_features=0.75, max_samples=0.8, n_estimators=40, total= 1.7min\n",
      "[CV] max_features=0.75, max_samples=0.8, n_estimators=40 .............\n",
      "[CV]  max_features=0.75, max_samples=0.8, n_estimators=40, total= 1.7min\n",
      "[CV] max_features=0.75, max_samples=0.8, n_estimators=40 .............\n",
      "[CV]  max_features=0.75, max_samples=0.8, n_estimators=40, total= 1.7min\n",
      "[CV] max_features=0.75, max_samples=0.8, n_estimators=40 .............\n",
      "[CV]  max_features=0.75, max_samples=0.8, n_estimators=40, total= 1.7min\n",
      "[CV] max_features=0.75, max_samples=0.8, n_estimators=50 .............\n",
      "[CV]  max_features=0.75, max_samples=0.8, n_estimators=50, total= 2.1min\n",
      "[CV] max_features=0.75, max_samples=0.8, n_estimators=50 .............\n",
      "[CV]  max_features=0.75, max_samples=0.8, n_estimators=50, total= 2.1min\n",
      "[CV] max_features=0.75, max_samples=0.8, n_estimators=50 .............\n",
      "[CV]  max_features=0.75, max_samples=0.8, n_estimators=50, total= 2.1min\n",
      "[CV] max_features=0.75, max_samples=0.8, n_estimators=50 .............\n",
      "[CV]  max_features=0.75, max_samples=0.8, n_estimators=50, total= 2.1min\n",
      "[CV] max_features=0.75, max_samples=0.8, n_estimators=50 .............\n",
      "[CV]  max_features=0.75, max_samples=0.8, n_estimators=50, total= 2.1min\n",
      "[CV] max_features=0.75, max_samples=0.8, n_estimators=60 .............\n",
      "[CV]  max_features=0.75, max_samples=0.8, n_estimators=60, total= 2.5min\n",
      "[CV] max_features=0.75, max_samples=0.8, n_estimators=60 .............\n",
      "[CV]  max_features=0.75, max_samples=0.8, n_estimators=60, total= 2.5min\n",
      "[CV] max_features=0.75, max_samples=0.8, n_estimators=60 .............\n",
      "[CV]  max_features=0.75, max_samples=0.8, n_estimators=60, total= 2.5min\n",
      "[CV] max_features=0.75, max_samples=0.8, n_estimators=60 .............\n",
      "[CV]  max_features=0.75, max_samples=0.8, n_estimators=60, total= 2.5min\n",
      "[CV] max_features=0.75, max_samples=0.8, n_estimators=60 .............\n",
      "[CV]  max_features=0.75, max_samples=0.8, n_estimators=60, total= 2.6min\n",
      "[CV] max_features=0.75, max_samples=0.8, n_estimators=70 .............\n",
      "[CV]  max_features=0.75, max_samples=0.8, n_estimators=70, total= 3.0min\n",
      "[CV] max_features=0.75, max_samples=0.8, n_estimators=70 .............\n",
      "[CV]  max_features=0.75, max_samples=0.8, n_estimators=70, total= 2.9min\n",
      "[CV] max_features=0.75, max_samples=0.8, n_estimators=70 .............\n",
      "[CV]  max_features=0.75, max_samples=0.8, n_estimators=70, total= 2.9min\n",
      "[CV] max_features=0.75, max_samples=0.8, n_estimators=70 .............\n",
      "[CV]  max_features=0.75, max_samples=0.8, n_estimators=70, total= 2.9min\n",
      "[CV] max_features=0.75, max_samples=0.8, n_estimators=70 .............\n",
      "[CV]  max_features=0.75, max_samples=0.8, n_estimators=70, total= 3.0min\n",
      "[CV] max_features=0.8, max_samples=0.6, n_estimators=30 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.6, n_estimators=30, total= 1.3min\n",
      "[CV] max_features=0.8, max_samples=0.6, n_estimators=30 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.6, n_estimators=30, total= 1.2min\n",
      "[CV] max_features=0.8, max_samples=0.6, n_estimators=30 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.6, n_estimators=30, total= 1.3min\n",
      "[CV] max_features=0.8, max_samples=0.6, n_estimators=30 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.6, n_estimators=30, total= 1.3min\n",
      "[CV] max_features=0.8, max_samples=0.6, n_estimators=30 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.6, n_estimators=30, total= 1.3min\n",
      "[CV] max_features=0.8, max_samples=0.6, n_estimators=40 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.6, n_estimators=40, total= 1.7min\n",
      "[CV] max_features=0.8, max_samples=0.6, n_estimators=40 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.6, n_estimators=40, total= 1.7min\n",
      "[CV] max_features=0.8, max_samples=0.6, n_estimators=40 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.6, n_estimators=40, total= 1.7min\n",
      "[CV] max_features=0.8, max_samples=0.6, n_estimators=40 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.6, n_estimators=40, total= 1.7min\n",
      "[CV] max_features=0.8, max_samples=0.6, n_estimators=40 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.6, n_estimators=40, total= 1.7min\n",
      "[CV] max_features=0.8, max_samples=0.6, n_estimators=50 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.6, n_estimators=50, total= 2.1min\n",
      "[CV] max_features=0.8, max_samples=0.6, n_estimators=50 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.6, n_estimators=50, total= 2.1min\n",
      "[CV] max_features=0.8, max_samples=0.6, n_estimators=50 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.6, n_estimators=50, total= 2.1min\n",
      "[CV] max_features=0.8, max_samples=0.6, n_estimators=50 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.6, n_estimators=50, total= 2.1min\n",
      "[CV] max_features=0.8, max_samples=0.6, n_estimators=50 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.6, n_estimators=50, total= 2.1min\n",
      "[CV] max_features=0.8, max_samples=0.6, n_estimators=60 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.6, n_estimators=60, total= 2.5min\n",
      "[CV] max_features=0.8, max_samples=0.6, n_estimators=60 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.6, n_estimators=60, total= 2.5min\n",
      "[CV] max_features=0.8, max_samples=0.6, n_estimators=60 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.6, n_estimators=60, total= 2.5min\n",
      "[CV] max_features=0.8, max_samples=0.6, n_estimators=60 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.6, n_estimators=60, total= 2.5min\n",
      "[CV] max_features=0.8, max_samples=0.6, n_estimators=60 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.6, n_estimators=60, total= 2.5min\n",
      "[CV] max_features=0.8, max_samples=0.6, n_estimators=70 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.6, n_estimators=70, total= 3.0min\n",
      "[CV] max_features=0.8, max_samples=0.6, n_estimators=70 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.6, n_estimators=70, total= 2.9min\n",
      "[CV] max_features=0.8, max_samples=0.6, n_estimators=70 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.6, n_estimators=70, total= 2.9min\n",
      "[CV] max_features=0.8, max_samples=0.6, n_estimators=70 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.6, n_estimators=70, total= 2.9min\n",
      "[CV] max_features=0.8, max_samples=0.6, n_estimators=70 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.6, n_estimators=70, total= 2.9min\n",
      "[CV] max_features=0.8, max_samples=0.7, n_estimators=30 ..............\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  max_features=0.8, max_samples=0.7, n_estimators=30, total= 1.3min\n",
      "[CV] max_features=0.8, max_samples=0.7, n_estimators=30 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.7, n_estimators=30, total= 1.3min\n",
      "[CV] max_features=0.8, max_samples=0.7, n_estimators=30 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.7, n_estimators=30, total= 1.3min\n",
      "[CV] max_features=0.8, max_samples=0.7, n_estimators=30 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.7, n_estimators=30, total= 1.3min\n",
      "[CV] max_features=0.8, max_samples=0.7, n_estimators=30 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.7, n_estimators=30, total= 1.3min\n",
      "[CV] max_features=0.8, max_samples=0.7, n_estimators=40 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.7, n_estimators=40, total= 1.7min\n",
      "[CV] max_features=0.8, max_samples=0.7, n_estimators=40 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.7, n_estimators=40, total= 1.7min\n",
      "[CV] max_features=0.8, max_samples=0.7, n_estimators=40 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.7, n_estimators=40, total= 1.7min\n",
      "[CV] max_features=0.8, max_samples=0.7, n_estimators=40 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.7, n_estimators=40, total= 1.7min\n",
      "[CV] max_features=0.8, max_samples=0.7, n_estimators=40 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.7, n_estimators=40, total= 1.7min\n",
      "[CV] max_features=0.8, max_samples=0.7, n_estimators=50 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.7, n_estimators=50, total= 2.1min\n",
      "[CV] max_features=0.8, max_samples=0.7, n_estimators=50 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.7, n_estimators=50, total= 2.1min\n",
      "[CV] max_features=0.8, max_samples=0.7, n_estimators=50 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.7, n_estimators=50, total= 2.1min\n",
      "[CV] max_features=0.8, max_samples=0.7, n_estimators=50 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.7, n_estimators=50, total= 2.1min\n",
      "[CV] max_features=0.8, max_samples=0.7, n_estimators=50 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.7, n_estimators=50, total= 2.1min\n",
      "[CV] max_features=0.8, max_samples=0.7, n_estimators=60 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.7, n_estimators=60, total= 2.5min\n",
      "[CV] max_features=0.8, max_samples=0.7, n_estimators=60 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.7, n_estimators=60, total= 2.5min\n",
      "[CV] max_features=0.8, max_samples=0.7, n_estimators=60 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.7, n_estimators=60, total= 2.5min\n",
      "[CV] max_features=0.8, max_samples=0.7, n_estimators=60 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.7, n_estimators=60, total= 2.5min\n",
      "[CV] max_features=0.8, max_samples=0.7, n_estimators=60 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.7, n_estimators=60, total= 2.5min\n",
      "[CV] max_features=0.8, max_samples=0.7, n_estimators=70 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.7, n_estimators=70, total= 2.9min\n",
      "[CV] max_features=0.8, max_samples=0.7, n_estimators=70 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.7, n_estimators=70, total= 2.9min\n",
      "[CV] max_features=0.8, max_samples=0.7, n_estimators=70 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.7, n_estimators=70, total= 2.9min\n",
      "[CV] max_features=0.8, max_samples=0.7, n_estimators=70 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.7, n_estimators=70, total= 3.0min\n",
      "[CV] max_features=0.8, max_samples=0.7, n_estimators=70 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.7, n_estimators=70, total= 2.9min\n",
      "[CV] max_features=0.8, max_samples=0.8, n_estimators=30 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.8, n_estimators=30, total= 1.3min\n",
      "[CV] max_features=0.8, max_samples=0.8, n_estimators=30 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.8, n_estimators=30, total= 1.3min\n",
      "[CV] max_features=0.8, max_samples=0.8, n_estimators=30 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.8, n_estimators=30, total= 1.3min\n",
      "[CV] max_features=0.8, max_samples=0.8, n_estimators=30 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.8, n_estimators=30, total= 1.3min\n",
      "[CV] max_features=0.8, max_samples=0.8, n_estimators=30 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.8, n_estimators=30, total= 1.3min\n",
      "[CV] max_features=0.8, max_samples=0.8, n_estimators=40 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.8, n_estimators=40, total= 1.7min\n",
      "[CV] max_features=0.8, max_samples=0.8, n_estimators=40 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.8, n_estimators=40, total= 1.7min\n",
      "[CV] max_features=0.8, max_samples=0.8, n_estimators=40 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.8, n_estimators=40, total= 1.7min\n",
      "[CV] max_features=0.8, max_samples=0.8, n_estimators=40 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.8, n_estimators=40, total= 1.7min\n",
      "[CV] max_features=0.8, max_samples=0.8, n_estimators=40 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.8, n_estimators=40, total= 1.7min\n",
      "[CV] max_features=0.8, max_samples=0.8, n_estimators=50 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.8, n_estimators=50, total= 2.1min\n",
      "[CV] max_features=0.8, max_samples=0.8, n_estimators=50 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.8, n_estimators=50, total= 2.1min\n",
      "[CV] max_features=0.8, max_samples=0.8, n_estimators=50 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.8, n_estimators=50, total= 2.1min\n",
      "[CV] max_features=0.8, max_samples=0.8, n_estimators=50 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.8, n_estimators=50, total= 2.1min\n",
      "[CV] max_features=0.8, max_samples=0.8, n_estimators=50 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.8, n_estimators=50, total= 2.1min\n",
      "[CV] max_features=0.8, max_samples=0.8, n_estimators=60 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.8, n_estimators=60, total= 2.5min\n",
      "[CV] max_features=0.8, max_samples=0.8, n_estimators=60 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.8, n_estimators=60, total= 2.5min\n",
      "[CV] max_features=0.8, max_samples=0.8, n_estimators=60 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.8, n_estimators=60, total= 2.5min\n",
      "[CV] max_features=0.8, max_samples=0.8, n_estimators=60 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.8, n_estimators=60, total= 2.5min\n",
      "[CV] max_features=0.8, max_samples=0.8, n_estimators=60 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.8, n_estimators=60, total= 2.5min\n",
      "[CV] max_features=0.8, max_samples=0.8, n_estimators=70 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.8, n_estimators=70, total= 2.9min\n",
      "[CV] max_features=0.8, max_samples=0.8, n_estimators=70 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.8, n_estimators=70, total= 2.9min\n",
      "[CV] max_features=0.8, max_samples=0.8, n_estimators=70 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.8, n_estimators=70, total= 3.0min\n",
      "[CV] max_features=0.8, max_samples=0.8, n_estimators=70 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.8, n_estimators=70, total= 2.9min\n",
      "[CV] max_features=0.8, max_samples=0.8, n_estimators=70 ..............\n",
      "[CV]  max_features=0.8, max_samples=0.8, n_estimators=70, total= 2.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 225 out of 225 | elapsed: 509.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=BaggingClassifier(base_estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.5, gamma=0.2, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=8, min_child_weight=2, missing=None,\n",
       "       n_estimators=345, n_jobs=-1, nthread=None,\n",
       "       ..._estimators=50, n_jobs=-1, oob_score=False,\n",
       "         random_state=None, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'max_features': [0.7, 0.75, 0.8], 'max_samples': [0.6, 0.7, 0.8], 'n_estimators': [30, 40, 50, 60, 70]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=2)"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_xgb_bagger.fit(x_train_base, y_train_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_features': 0.75, 'max_samples': 0.8, 'n_estimators': 40}\n",
      "0.772503097893139\n"
     ]
    }
   ],
   "source": [
    "print gs_xgb_bagger.best_params_\n",
    "print gs_xgb_bagger.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB Modeling\n",
    "\n",
    "With our tuned parameters, we'll now actually create, fit, train, and store predictions for the 3 XGBClassifier model variations described above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.68 s, sys: 3.77 ms, total: 2.68 s\n",
      "Wall time: 3.21 s\n",
      "CPU times: user 2.68 s, sys: 7.58 ms, total: 2.69 s\n",
      "Wall time: 3.22 s\n",
      "CPU times: user 2.72 s, sys: 11.7 ms, total: 2.73 s\n",
      "Wall time: 2.88 s\n",
      "CPU times: user 2.99 s, sys: 11.8 ms, total: 3 s\n",
      "Wall time: 3.16 s\n",
      "CPU times: user 2.92 s, sys: 7.83 ms, total: 2.93 s\n",
      "Wall time: 3.06 s\n"
     ]
    }
   ],
   "source": [
    "xgb_raw = get_tuned_xgb_copy(\"raw\")\n",
    "xgb_raw = train_and_save_base_learner_preds(xgb_raw, folds, x_train_raw, y_train_raw, test_raw, \"xgboost_raw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation score: 0.7679407487061665 +/- 0.0036097387764845133\n",
      "Raw scores: [0.76847903 0.76623869 0.76193105 0.7712841  0.77177087]\n"
     ]
    }
   ],
   "source": [
    "# There seems to be a parallelization issue w/ XGBClassifier when trying to obtain a CV score, thus we use only 1 core\n",
    "xgb_raw_cv = get_cross_val_score(xgb_raw, x_train_raw, y_train_raw, n_splits, run_parallel=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.27 s, sys: 1.46 s, total: 7.73 s\n",
      "Wall time: 1.94 s\n",
      "CPU times: user 5.98 s, sys: 1.41 s, total: 7.39 s\n",
      "Wall time: 1.87 s\n",
      "CPU times: user 6.12 s, sys: 1.51 s, total: 7.63 s\n",
      "Wall time: 1.98 s\n",
      "CPU times: user 6.13 s, sys: 1.55 s, total: 7.69 s\n",
      "Wall time: 2.05 s\n",
      "CPU times: user 6.08 s, sys: 1.49 s, total: 7.57 s\n",
      "Wall time: 1.94 s\n"
     ]
    }
   ],
   "source": [
    "xgb_base = get_tuned_xgb_copy(\"base\")\n",
    "xgb_base = train_and_save_base_learner_preds(xgb_base, folds, x_train_base, y_train_base, test_base, \"xgboost_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation score: 0.758965265001 +/- 0.0044137786577\n",
      "Raw scores: [ 0.76202306  0.75019668  0.76073913  0.76056439  0.76130306]\n"
     ]
    }
   ],
   "source": [
    "xgb_base_cv = get_cross_val_score(xgb_base, x_train_base, y_train_base, n_splits, run_parallel=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.09 s, sys: 1.56 s, total: 9.65 s\n",
      "Wall time: 2.27 s\n",
      "CPU times: user 7.81 s, sys: 1.47 s, total: 9.28 s\n",
      "Wall time: 2.2 s\n",
      "CPU times: user 8.01 s, sys: 1.47 s, total: 9.47 s\n",
      "Wall time: 2.16 s\n",
      "CPU times: user 8.02 s, sys: 1.48 s, total: 9.5 s\n",
      "Wall time: 2.18 s\n",
      "CPU times: user 8.09 s, sys: 1.51 s, total: 9.59 s\n",
      "Wall time: 2.19 s\n"
     ]
    }
   ],
   "source": [
    "xgb_poly = get_tuned_xgb_copy(\"poly\")\n",
    "xgb_poly = train_and_save_base_learner_preds(xgb_poly, folds, x_train_poly, y_train_poly, test_poly, \"xgboost_poly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation score: 0.745601533629 +/- 0.00395136757867\n",
      "Raw scores: [ 0.74112726  0.7418853   0.74615411  0.74670364  0.75213736]\n"
     ]
    }
   ],
   "source": [
    "xgb_poly_cv = get_cross_val_score(xgb_poly, x_train_poly, y_train_poly, n_splits, run_parallel=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Bagged (Using Base Fitted XGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 40s, sys: 237 ms, total: 1min 40s\n",
      "Wall time: 1min 44s\n",
      "CPU times: user 1min 38s, sys: 170 ms, total: 1min 38s\n",
      "Wall time: 1min 41s\n",
      "CPU times: user 1min 35s, sys: 236 ms, total: 1min 35s\n",
      "Wall time: 1min 38s\n",
      "CPU times: user 1min 36s, sys: 260 ms, total: 1min 36s\n",
      "Wall time: 1min 39s\n",
      "CPU times: user 1min 35s, sys: 229 ms, total: 1min 36s\n",
      "Wall time: 1min 40s\n"
     ]
    }
   ],
   "source": [
    "# Bagged classifier\n",
    "xgb_bag = BaggingClassifier(base_estimator=get_tuned_xgb_copy(\"base\"), **xgb_bag_params)\n",
    "xgb_bag = train_and_save_base_learner_preds(xgb_bag, folds, x_train_base, y_train_base, test_base, \"xgboost_bag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation score: 0.7680347140060597 +/- 0.006487042101997774\n",
      "Raw scores: [0.7719898  0.76970894 0.75715998 0.76518267 0.77613217]\n"
     ]
    }
   ],
   "source": [
    "xgb_bag_cv = get_cross_val_score(xgb_bag, x_train_base, y_train_base, n_splits, run_parallel=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.65 s, sys: 3.81 ms, total: 1.65 s\n",
      "Wall time: 1.91 s\n",
      "CPU times: user 1.61 s, sys: 3.86 ms, total: 1.61 s\n",
      "Wall time: 1.71 s\n",
      "CPU times: user 1.63 s, sys: 0 ns, total: 1.63 s\n",
      "Wall time: 1.89 s\n",
      "CPU times: user 1.63 s, sys: 15.6 ms, total: 1.64 s\n",
      "Wall time: 1.9 s\n",
      "CPU times: user 1.6 s, sys: 3.93 ms, total: 1.61 s\n",
      "Wall time: 1.7 s\n"
     ]
    }
   ],
   "source": [
    "xgb_reduced = get_tuned_xgb_copy(\"reduced\")\n",
    "xgb_reduced = train_and_save_base_learner_preds(xgb_reduced, folds, x_train_reduced, y_train_reduced, test_reduced, \"xgboost_reduced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation score: 0.7592580101765478 +/- 0.00403111282038657\n",
      "Raw scores: [0.75909812 0.76317025 0.75419874 0.75546917 0.76435377]\n"
     ]
    }
   ],
   "source": [
    "xgb_reduced_cv = get_cross_val_score(xgb_reduced, x_train_reduced, y_train_reduced, n_splits, run_parallel=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='entropy',\n",
       "           max_depth=6, max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=150, n_jobs=-1, oob_score=False, random_state=None,\n",
       "           verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'n_estimators': [150, 200, 250, 300, 350], 'max_depth': [6, 8, 10, 12]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "et_param_grid = {\n",
    "    \"max_depth\": range(6, 12 + 1, 2),\n",
    "    \"n_estimators\": range(150, 350 + 1, 50)\n",
    "}\n",
    "\n",
    "et = ExtraTreesClassifier(max_depth=6, n_estimators=150, n_jobs=-1, criterion=\"entropy\")\n",
    "gs_et = GridSearchCV(estimator=et, param_grid=et_param_grid, cv=n_splits, scoring=\"roc_auc\")\n",
    "gs_et.fit(x_train_base, y_train_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 250, 'max_depth': 12}\n",
      "0.657812396697\n"
     ]
    }
   ],
   "source": [
    "print gs_et.best_params_\n",
    "print gs_et.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='entropy',\n",
       "           max_depth=12, max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           n_estimators=250, n_jobs=-1, oob_score=False, random_state=None,\n",
       "           verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'max_depth': [12, 14, 16, 18, 20]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step two\n",
    "et_param_grid_2 = {\n",
    "    \"max_depth\": range(12, 20 + 1, 2)\n",
    "}\n",
    "\n",
    "et_2 = ExtraTreesClassifier(max_depth=12, n_estimators=250, n_jobs=-1, criterion=\"entropy\")\n",
    "gs_et_2 = GridSearchCV(estimator=et_2, param_grid=et_param_grid_2, cv=n_splits, scoring=\"roc_auc\")\n",
    "gs_et_2.fit(x_train_base, y_train_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 250, 'max_depth': 12}\n",
      "0.657812396697\n"
     ]
    }
   ],
   "source": [
    "print gs_et.best_params_\n",
    "print gs_et.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation score: 0.658994376998 +/- 0.0162024899885\n",
      "Raw scores: [ 0.66693004  0.65553248  0.67156773  0.62885771  0.67208392]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.66693004,  0.65553248,  0.67156773,  0.62885771,  0.67208392])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_cross_val_score(ExtraTreesClassifier(max_depth=12, n_estimators=250, n_jobs=-1, criterion=\"entropy\"), x_train_base, y_train_base, n_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.03 s, sys: 132 ms, total: 2.16 s\n",
      "Wall time: 925 ms\n",
      "CPU times: user 2.13 s, sys: 127 ms, total: 2.26 s\n",
      "Wall time: 948 ms\n",
      "CPU times: user 2.33 s, sys: 120 ms, total: 2.45 s\n",
      "Wall time: 1.08 s\n",
      "CPU times: user 2.18 s, sys: 121 ms, total: 2.31 s\n",
      "Wall time: 970 ms\n",
      "CPU times: user 2.1 s, sys: 110 ms, total: 2.21 s\n",
      "Wall time: 935 ms\n"
     ]
    }
   ],
   "source": [
    "et_base = ExtraTreesClassifier(max_depth=12, n_estimators=250, n_jobs=-1, criterion=\"entropy\")\n",
    "et_base = train_and_save_base_learner_preds(et_base, folds, x_train_base, y_train_base, test_base, \"extra_trees_base\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaboostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ada_params = {\n",
    "    \"n_estimators\": 410,\n",
    "    \"learning_rate\": 1.7,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  15 out of  15 | elapsed:  1.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=1.7, n_estimators=410, random_state=None),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_estimators': [409], 'learning_rate': [1.675, 1.7, 1.725]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_param_grid = {\n",
    "    \"learning_rate\": [1.675, 1.7, 1.725],\n",
    "    \"n_estimators\": range(409, 410, 411)\n",
    "}\n",
    "\n",
    "ada = AdaBoostClassifier(**ada_params)\n",
    "gs_ada = GridSearchCV(estimator=ada, param_grid=ada_param_grid, cv=n_splits, scoring=\"roc_auc\", verbose=1)\n",
    "gs_ada.fit(x_train_base, y_train_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 400, 'learning_rate': 1.6}\n",
      "0.7048120649813508\n"
     ]
    }
   ],
   "source": [
    "print gs_ada.best_params_\n",
    "print gs_ada.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 413, 'learning_rate': 1.65}\n",
      "0.7064952811706677\n"
     ]
    }
   ],
   "source": [
    "print gs_ada.best_params_\n",
    "print gs_ada.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 410, 'learning_rate': 1.7}\n",
      "0.7101570612471971\n"
     ]
    }
   ],
   "source": [
    "print gs_ada.best_params_\n",
    "print gs_ada.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.5 s, sys: 16 ms, total: 3.51 s\n",
      "Wall time: 4.21 s\n",
      "CPU times: user 3.47 s, sys: 36 s, total: 3.47 s\n",
      "Wall time: 4 s\n",
      "CPU times: user 3.51 s, sys: 4.02 ms, total: 3.52 s\n",
      "Wall time: 3.6 s\n",
      "CPU times: user 3.47 s, sys: 68 s, total: 3.47 s\n",
      "Wall time: 3.51 s\n",
      "CPU times: user 3.49 s, sys: 15 s, total: 3.49 s\n",
      "Wall time: 3.83 s\n"
     ]
    }
   ],
   "source": [
    "ada_tuned = AdaBoostClassifier(**ada_params)\n",
    "ada_tuned = train_and_save_base_learner_preds(ada_tuned, folds, x_train_base, y_train_base, test_base, \"adaboost_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation score: 0.70863909472035 +/- 0.009432939045787084\n",
      "Raw scores: [0.72384353 0.70028701 0.69732999 0.70911501 0.71261994]\n"
     ]
    }
   ],
   "source": [
    "ada_tuned_cv = get_cross_val_score(ada_tuned, x_train_base, y_train_base, n_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNeighborsClassifier\n",
    "\n",
    "We'll train instances of KNeighbors with **n_neighbors** set to $2^n$ for **n = [1, 10]**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'n_neighbors'=2:  Cross validation score: 0.5734347750430698 +/- 0.02150554781143965\n",
      "Raw scores: [0.56259454 0.59927742 0.59888489 0.54767778 0.55873925]\n",
      "'n_neighbors'=4:  Cross validation score: 0.5904991367209932 +/- 0.021707633361062555\n",
      "Raw scores: [0.61750827 0.59411804 0.60925007 0.56118483 0.57043447]\n",
      "'n_neighbors'=8:  Cross validation score: 0.6106239221540269 +/- 0.028374392432192527\n",
      "Raw scores: [0.65312922 0.60882293 0.62842129 0.5716876  0.59105856]\n",
      "'n_neighbors'=16:  Cross validation score: 0.6245492482128034 +/- 0.012956113845272987\n",
      "Raw scores: [0.62794604 0.6354268  0.63109468 0.59914151 0.62913721]\n",
      "'n_neighbors'=32:  Cross validation score: 0.6354634757976712 +/- 0.016732919044860677\n",
      "Raw scores: [0.64259775 0.63234569 0.64453252 0.60471873 0.65312269]\n",
      "'n_neighbors'=64:  Cross validation score: 0.6266970227584763 +/- 0.026045333714564176\n",
      "Raw scores: [0.64346299 0.59740765 0.64831594 0.59261885 0.65167967]\n",
      "'n_neighbors'=128:  Cross validation score: 0.6278942299909309 +/- 0.0251870821371429\n",
      "Raw scores: [0.64371286 0.59585022 0.63367943 0.60305662 0.66317202]\n",
      "'n_neighbors'=256:  Cross validation score: 0.6245031895595641 +/- 0.02145195699074404\n",
      "Raw scores: [0.64017423 0.6006044  0.62072528 0.60406875 0.65694328]\n",
      "'n_neighbors'=512:  Cross validation score: 0.6103723855103647 +/- 0.02768702718157424\n",
      "Raw scores: [0.63900088 0.5820131  0.61331291 0.57563732 0.64189772]\n",
      "'n_neighbors'=1024:  Cross validation score: 0.6015178207623336 +/- 0.022206987825907614\n",
      "Raw scores: [0.62095236 0.57190201 0.61168963 0.57799078 0.62505433]\n"
     ]
    }
   ],
   "source": [
    "knn_models = dict()\n",
    "\n",
    "for n in range(1, 10 + 1):\n",
    "    knn_i = KNeighborsClassifier(n_neighbors=2**n, n_jobs=-1)\n",
    "    knn_i = train_and_save_base_learner_preds(knn_i, \n",
    "                                              folds, \n",
    "                                              x_train_base, \n",
    "                                              y_train_base, \n",
    "                                              test_base, \n",
    "                                              \"knn_{}\".format(2**n), \n",
    "                                              timeit=False)\n",
    "    knn_models[\"knn_{}\".format(2**n)] = knn_i\n",
    "    print (\"'n_neighbors'={}: \".format(2**n)),\n",
    "    get_cross_val_score(knn_i, x_train_base, y_train_base, n_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Choosing optimal base learners\n",
    "\n",
    "We'll first see how each base learner performs by itself, then display the pearson correlation matrix against each base learner's predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Process for parameters used for each base learner is documented in \"layer_1_models.ipynb\".\n",
    "rfc = RandomForestClassifier(criterion='entropy', max_depth=10, n_estimators=1000, n_jobs=-1)\n",
    "lr = LogisticRegression(C=100, tol=1e-05, solver=\"liblinear\")\n",
    "et = ExtraTreesClassifier(max_depth=12, n_estimators=250, n_jobs=-1, criterion=\"entropy\")\n",
    "ada_base = AdaBoostClassifier(n_estimators=410, learning_rate=1.7)\n",
    "xgb_raw = get_tuned_xgb_copy(\"raw\")\n",
    "xgb_base = get_tuned_xgb_copy(\"base\")\n",
    "xgb_reduced = get_tuned_xgb_copy(\"reduced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_learners = {\n",
    "    \"rfc\": rfc,\n",
    "    \"lr\": lr,\n",
    "    \"et\": et,\n",
    "    \"ada\": ada_base,\n",
    "    \"xgb_raw\": xgb_raw,\n",
    "    \"xgb_base\": xgb_base,\n",
    "    \"xgb_reduced\": xgb_reduced\n",
    "}\n",
    "\n",
    "base_learners.update(knn_models)\n",
    "\n",
    "all_preds = pd.DataFrame(np.zeros((test_base.shape[0], len(base_learners))), columns=list(base_learners.keys()))\n",
    "\n",
    "for name, model in base_learners.items():\n",
    "    model.fit(x_train_base, y_train_base)\n",
    "    all_preds[name] = model.predict_proba(test_base)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAokAAAJMCAYAAACW8jwmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa45414f110>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_preds = all_preds.reindex_axis(sorted(all_preds.columns.values), axis=1)\n",
    "\n",
    "ax = corrmat(all_preds.corr())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excluding the correlation values of different XGB / KNN instances, we can see that a majority of the base learners aren't highly correlated, so an ensemble including **all** of these base learners will likely outperform any of the base learner's lone predictions, through combining each base learner's respective predictive \n",
    "strengths."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
