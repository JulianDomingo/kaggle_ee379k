{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "Julian Domingo - jad5348\n",
    "\n",
    "This file contains my process for training my base learners and meta learner to predict the probability values for the target value **Y**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computation / Data Analysis stuff\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import skew, probplot, norm\n",
    "from scipy.special import boxcox1p\n",
    "\n",
    "# Modeling stuff\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import (RandomizedSearchCV, \n",
    "                                     GridSearchCV, \n",
    "                                     StratifiedKFold,\n",
    "                                     cross_val_score)\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import (RandomForestClassifier, \n",
    "                              AdaBoostClassifier, \n",
    "                              GradientBoostingClassifier, \n",
    "                              ExtraTreesClassifier)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.cross_validation import train_test_split, KFold\n",
    "\n",
    "# Plotting stuff\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "\n",
    "# Plotting visuals stuff\n",
    "%matplotlib inline\n",
    "mpl.style.use('ggplot')\n",
    "sns.set_style('white')\n",
    "pylab.rcParams['figure.figsize'] = 12,8\n",
    "\n",
    "# ignore warnings (i.e. deprecation warnings)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids = pd.read_csv(\"./data/raw/test.csv\")[[\"id\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(filename):\n",
    "    train = pd.read_csv(\"./data/refined/train/train_{}.csv\".format(filename))\n",
    "    test = pd.read_csv(\"./data/refined/test/test_{}.csv\".format(filename))\n",
    "    \n",
    "    x_train = train.drop([\"Y\"], axis = 1)\n",
    "    y_train = train[\"Y\"]\n",
    "    \n",
    "    return train, test, x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_base, test_base, x_train_base, y_train_base = get_data(\"base\")\n",
    "train_log, test_log, x_train_log, y_train_log = get_data(\"log\")\n",
    "train_scaled, test_scaled, x_train_scaled, y_train_scaled = get_data(\"scaled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cross_val_score(model, x_train, y_train, n_folds):\n",
    "    cv = cross_val_score(model, x_train, y_train, cv = n_folds, scoring = 'roc_auc', n_jobs = -1)\n",
    "    print(\"Cross validation score: {} +/- {}\\nRaw scores: {}\".format(str(np.mean(cv)), str(np.std(cv)), str(cv)))\n",
    "    return cv\n",
    "\n",
    "def train_and_save_base_learner_preds(model, folds, x_train, y_train, test, pred_filename):\n",
    "    # Train model on the folds defined\n",
    "    result = train(model, folds, x_train, y_train, test)\n",
    "        \n",
    "    train_preds_csv = pd.DataFrame(columns=[\"Y\"], index=x_train.index, data = result[\"train_preds\"])\n",
    "    train_preds_csv.to_csv(\"./predictions/train/train_{}.csv\".format(pred_filename))\n",
    "    \n",
    "    test_preds_csv = pd.DataFrame(columns=[\"Y\"], index=test.index, data=result[\"test_preds\"])\n",
    "    test_preds_csv.to_csv(\"./predictions/test/test_{}.csv\".format(pred_filename))\n",
    "    \n",
    "    return result[\"model\"]\n",
    "                          \n",
    "\n",
    "def train(model, folds, x, y, test):\n",
    "    \"\"\" Trains the model through (stratified) CV. \n",
    "    \n",
    "    'train_preds' is the combination of all predictions from each holdout.\n",
    "    'test_preds' is the final predictions computed through the mean of each test prediction.\n",
    "    \n",
    "    \"\"\"\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    test = np.array(test)\n",
    "        \n",
    "    train_preds = np.zeros(x.shape[0])\n",
    "    test_preds = np.zeros(test.shape[0])\n",
    "    test_preds_iter = np.zeros((test.shape[0], len(folds)))\n",
    "    \n",
    "    for i, (train_indices, test_indices) in enumerate(folds):\n",
    "        x_train = x[train_indices]\n",
    "        x_holdout = x[test_indices]\n",
    "        y_train = y[train_indices]\n",
    "        \n",
    "        %time model.fit(x_train, y_train)\n",
    "        \n",
    "        train_preds[test_indices] = model.predict_proba(x_holdout)[:,1]\n",
    "        test_preds_iter[:,i] = model.predict_proba(test)[:,1]\n",
    "        \n",
    "    test_preds[:] = test_preds_iter.mean(1)\n",
    "        \n",
    "    return {'model': model, 'train_preds': train_preds ,'test_preds': test_preds}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain fold indices for base learner training.\n",
    "n_splits = 5\n",
    "folds = list(StratifiedKFold(n_splits, random_state=seed).split(x_train_base, y_train_base))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Learners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier\n",
    "\n",
    "Tuning parameters\n",
    "    * n_estimators (online): \"n_estimators is not really worth optimizing. The more estimators you give it, the better it will do. 500 or 1000 is usually sufficient.\"\n",
    "    * criterion (class): Constantine mentioned entropy is the preferred criterion for Random Forests.\n",
    "    * max_features (code): used GridSearchCV, sci-kit learn docs showed [1, 3, 10] as good contenders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=1000, n_jobs=-1, oob_score=False,\n",
       "            random_state=None, verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'max_features': [1, 3, 10]}, pre_dispatch='2*n_jobs',\n",
       "       refit=True, return_train_score=True, scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_param_grid = {\n",
    "    'max_features': [1, 3, 10]\n",
    "}\n",
    "\n",
    "rfc = RandomForestClassifier(criterion='entropy', max_depth=10, n_estimators=1000, n_jobs=-1)\n",
    "\n",
    "gs_rfc = GridSearchCV(estimator=rfc, param_grid=rfc_param_grid, cv=n_splits, scoring=\"roc_auc\")\n",
    "gs_rfc.fit(x_train_base, y_train_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_features': 10}\n",
      "0.750506293137\n"
     ]
    }
   ],
   "source": [
    "# So, we'll use 10 to be our max_features value.\n",
    "print gs_rfc.best_params_\n",
    "print gs_rfc.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 44 s, sys: 417 ms, total: 44.4 s\n",
      "Wall time: 7.78 s\n",
      "CPU times: user 43.9 s, sys: 383 ms, total: 44.3 s\n",
      "Wall time: 7.75 s\n",
      "CPU times: user 43.5 s, sys: 353 ms, total: 43.8 s\n",
      "Wall time: 7.84 s\n",
      "CPU times: user 43.7 s, sys: 359 ms, total: 44 s\n",
      "Wall time: 7.64 s\n",
      "CPU times: user 43.3 s, sys: 354 ms, total: 43.7 s\n",
      "Wall time: 7.77 s\n",
      "Cross validation score: 0.74792660538 +/- 0.0159539543648\n",
      "Raw scores: [ 0.75121725  0.76470151  0.72537649  0.73385839  0.76447939]\n"
     ]
    }
   ],
   "source": [
    "# Train with our optimized parameters.\n",
    "rfc = RandomForestClassifier(criterion='entropy', max_depth=10, max_features=10, n_estimators=1000, n_jobs=-1)\n",
    "rfc = train_and_save_base_learner_preds(rfc, folds, x_train_base, y_train_base, test_base, \"random_forest_base\")\n",
    "rf_cv = get_cross_val_score(rfc, x_train_base, y_train_base, n_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.9683427 ,  0.84006011,  0.932847  , ...,  0.8995378 ,\n",
       "        0.97463642,  0.96310475])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.fit(x_train_base, y_train_base)\n",
    "probs = rfc.predict_proba(test_base)[:,1]\n",
    "print probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\"id\": test_ids.id, \"Y\": probs})\n",
    "submission.to_csv(\"./submissions/random_forest_lone.csv\", index=False, columns=[\"id\", \"Y\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what features RandomForestClassifier deemed most important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.Series(index=x_train_base.columns, data=rfc.feature_importances_).sort_values().plot(kind='barh', title='Variable Importances')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16383, 19)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_base.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F10</th>\n",
       "      <th>F11</th>\n",
       "      <th>F12</th>\n",
       "      <th>F13</th>\n",
       "      <th>F15</th>\n",
       "      <th>F16</th>\n",
       "      <th>F17</th>\n",
       "      <th>F18</th>\n",
       "      <th>F19</th>\n",
       "      <th>F20</th>\n",
       "      <th>F21</th>\n",
       "      <th>F22</th>\n",
       "      <th>F23</th>\n",
       "      <th>F24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16384</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>17000</td>\n",
       "      <td>143022</td>\n",
       "      <td>1</td>\n",
       "      <td>140341</td>\n",
       "      <td>1</td>\n",
       "      <td>122020</td>\n",
       "      <td>135753</td>\n",
       "      <td>1</td>\n",
       "      <td>128168</td>\n",
       "      <td>121276</td>\n",
       "      <td>1</td>\n",
       "      <td>122084</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>127696</td>\n",
       "      <td>1</td>\n",
       "      <td>36129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16385</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>18000</td>\n",
       "      <td>315517</td>\n",
       "      <td>1</td>\n",
       "      <td>138050</td>\n",
       "      <td>1</td>\n",
       "      <td>121506</td>\n",
       "      <td>55012</td>\n",
       "      <td>1</td>\n",
       "      <td>121648</td>\n",
       "      <td>120763</td>\n",
       "      <td>1</td>\n",
       "      <td>119703</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>127441</td>\n",
       "      <td>1</td>\n",
       "      <td>90582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16386</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>1000</td>\n",
       "      <td>142929</td>\n",
       "      <td>1</td>\n",
       "      <td>137960</td>\n",
       "      <td>1</td>\n",
       "      <td>121709</td>\n",
       "      <td>23834</td>\n",
       "      <td>1</td>\n",
       "      <td>314350</td>\n",
       "      <td>120965</td>\n",
       "      <td>1</td>\n",
       "      <td>119703</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>127029</td>\n",
       "      <td>1</td>\n",
       "      <td>46088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16387</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>2000</td>\n",
       "      <td>130186</td>\n",
       "      <td>1</td>\n",
       "      <td>128090</td>\n",
       "      <td>1</td>\n",
       "      <td>120286</td>\n",
       "      <td>92412</td>\n",
       "      <td>1</td>\n",
       "      <td>140144</td>\n",
       "      <td>180952</td>\n",
       "      <td>1</td>\n",
       "      <td>118961</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>127973</td>\n",
       "      <td>1</td>\n",
       "      <td>83138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16388</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>2000</td>\n",
       "      <td>132071</td>\n",
       "      <td>1</td>\n",
       "      <td>128051</td>\n",
       "      <td>1</td>\n",
       "      <td>138055</td>\n",
       "      <td>8513</td>\n",
       "      <td>1</td>\n",
       "      <td>121642</td>\n",
       "      <td>136961</td>\n",
       "      <td>1</td>\n",
       "      <td>118832</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>126927</td>\n",
       "      <td>1</td>\n",
       "      <td>92381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  F3  F4     F6      F7  F8     F10  F11     F12     F13  F15     F16  \\\n",
       "0  16384   0  33  17000  143022   1  140341    1  122020  135753    1  128168   \n",
       "1  16385   0  38  18000  315517   1  138050    1  121506   55012    1  121648   \n",
       "2  16386   1  27   1000  142929   1  137960    1  121709   23834    1  314350   \n",
       "3  16387   0  33   2000  130186   1  128090    1  120286   92412    1  140144   \n",
       "4  16388   0  40   2000  132071   1  128051    1  138055    8513    1  121642   \n",
       "\n",
       "      F17  F18     F19  F20  F21     F22  F23    F24  \n",
       "0  121276    1  122084    1    1  127696    1  36129  \n",
       "1  120763    1  119703    1    2  127441    1  90582  \n",
       "2  120965    1  119703    1    1  127029    1  46088  \n",
       "3  180952    1  118961    1    1  127973    1  83138  \n",
       "4  136961    1  118832    1    1  126927    1  92381  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_base.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Y</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F10</th>\n",
       "      <th>F11</th>\n",
       "      <th>F12</th>\n",
       "      <th>...</th>\n",
       "      <th>F15</th>\n",
       "      <th>F16</th>\n",
       "      <th>F17</th>\n",
       "      <th>F18</th>\n",
       "      <th>F19</th>\n",
       "      <th>F20</th>\n",
       "      <th>F21</th>\n",
       "      <th>F22</th>\n",
       "      <th>F23</th>\n",
       "      <th>F24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>1000</td>\n",
       "      <td>32020</td>\n",
       "      <td>1</td>\n",
       "      <td>127959</td>\n",
       "      <td>1</td>\n",
       "      <td>120193</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>119757</td>\n",
       "      <td>119100</td>\n",
       "      <td>1</td>\n",
       "      <td>118830</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>126461</td>\n",
       "      <td>1</td>\n",
       "      <td>46871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1000</td>\n",
       "      <td>130630</td>\n",
       "      <td>1</td>\n",
       "      <td>128342</td>\n",
       "      <td>2</td>\n",
       "      <td>122242</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>138110</td>\n",
       "      <td>121149</td>\n",
       "      <td>1</td>\n",
       "      <td>118832</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>130296</td>\n",
       "      <td>1</td>\n",
       "      <td>42386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>1000</td>\n",
       "      <td>303218</td>\n",
       "      <td>2</td>\n",
       "      <td>128299</td>\n",
       "      <td>1</td>\n",
       "      <td>120221</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>119777</td>\n",
       "      <td>119126</td>\n",
       "      <td>1</td>\n",
       "      <td>118832</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>127063</td>\n",
       "      <td>1</td>\n",
       "      <td>23968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>2000</td>\n",
       "      <td>19024</td>\n",
       "      <td>1</td>\n",
       "      <td>127968</td>\n",
       "      <td>1</td>\n",
       "      <td>124605</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>270637</td>\n",
       "      <td>123511</td>\n",
       "      <td>1</td>\n",
       "      <td>118832</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15274</td>\n",
       "      <td>1</td>\n",
       "      <td>27555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1000</td>\n",
       "      <td>303218</td>\n",
       "      <td>1</td>\n",
       "      <td>128299</td>\n",
       "      <td>1</td>\n",
       "      <td>120635</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>119777</td>\n",
       "      <td>119542</td>\n",
       "      <td>1</td>\n",
       "      <td>118832</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>133491</td>\n",
       "      <td>1</td>\n",
       "      <td>50260</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  Y  F3  F4    F6      F7  F8     F10  F11     F12  ...    F15     F16  \\\n",
       "0   1  1   0  38  1000   32020   1  127959    1  120193  ...      1  119757   \n",
       "1   2  1   0  41  1000  130630   1  128342    2  122242  ...      1  138110   \n",
       "2   3  1   0  50  1000  303218   2  128299    1  120221  ...      1  119777   \n",
       "3   4  1   0  45  2000   19024   1  127968    1  124605  ...      2  270637   \n",
       "4   5  1   0  41  1000  303218   1  128299    1  120635  ...      1  119777   \n",
       "\n",
       "      F17  F18     F19  F20  F21     F22  F23    F24  \n",
       "0  119100    1  118830    1    1  126461    1  46871  \n",
       "1  121149    1  118832    1    1  130296    1  42386  \n",
       "2  119126    1  118832    1    2  127063    1  23968  \n",
       "3  123511    1  118832    1    1   15274    1  27555  \n",
       "4  119542    1  118832    1    1  133491    1  50260  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_base.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def stack_model(model, train, test, y, new_feature):\n",
    "#     model.fit(train, y)\n",
    "#     train[new_feature] = pd.DataFrame(model.predict(train))\n",
    "#     test[new_feature] = pd.DataFrame(model.predict(test))\n",
    "    \n",
    "#     return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def get_out_of_folds_preds(k, model, x_train, x_test, y_train):\n",
    "#     \"\"\" Returns the out of folds predictions of the model passed. \"\"\"\n",
    "#     len_train = x_train.shape[0]\n",
    "#     len_test = x_test.shape[0]\n",
    "#     kf = KFold(len_train, n_folds = k, random_state = 1337)\n",
    "    \n",
    "#     oof_train = np.zeros((len_train,))\n",
    "#     oof_test = np.zeros((len_test,))\n",
    "#     oof_test_kf = np.empty((k, len_test))\n",
    "    \n",
    "#     for i, (train_indices, test_indices) in enumerate(kf):\n",
    "#         model.fit(x_train[train_indices], y_train[train_indices])\n",
    "        \n",
    "#         oof_train[test_indices] = model.predict(x_train[test_indices])\n",
    "#         oof_test_kf[i, :] = model.predict(x_test)\n",
    "\n",
    "#     oof_test[:] = oof_test_kf.mean(axis = 0)\n",
    "    \n",
    "#     return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def get_base_learners():\n",
    "#     # Parameters for each base model.\n",
    "#     rf_params = {\n",
    "#         'n_jobs': -1, # Number of cores used in training == all cores\n",
    "#         'n_estimators': 10, # Number of classification trees in model\n",
    "#         'warm_start': True,\n",
    "#         'max_depth': 3, # Max depth of the tree. WARNING - don't set too high, otherwise may overfit\n",
    "#         'min_samples_leaf': 2, # The minimum number of samples required to be at a leaf node \n",
    "#         'max_features' : 'sqrt', # The number of features to consider when looking for the best split\n",
    "#         'verbose': 0,\n",
    "#         'random_state': seed\n",
    "#         # TODO: tune hyperparameters\n",
    "#     }\n",
    "\n",
    "#     xgb_params = {\n",
    "#         # TODO: tune hyperparameters\n",
    "#     }\n",
    "\n",
    "#     et_params = {\n",
    "#         # TODO: tune hyperparameters\n",
    "#     }\n",
    "\n",
    "#     ada_params = {\n",
    "#         # TODO: tune hyperparameters\n",
    "#     }\n",
    "\n",
    "#     gb_params = {\n",
    "#         # TODO: tune hyperparameters\n",
    "#         'n_estimators': 100,\n",
    "#         'random_state': seed\n",
    "#     }\n",
    "\n",
    "#     svc_params = {\n",
    "#         # TODO: tune hyperparameters\n",
    "#         'C': 100 # Penalty parameter of error term\n",
    "#     }\n",
    "\n",
    "#     lr_params = {\n",
    "#         # TODO: tune hyperparameters\n",
    "#         'C': 100, # Regularization strength\n",
    "#         'random_state': seed\n",
    "#     }\n",
    "\n",
    "#     mlp_params = {\n",
    "#         # TODO: tune hyperparameters\n",
    "#         'hidden_layer_sizes': (80, 10),\n",
    "#         'early_stopping': False,\n",
    "#         'random_state': seed\n",
    "#     }\n",
    "    \n",
    "#     knn_params = {\n",
    "#         # TODO: tune hyperparameters\n",
    "#         'n_neighbors': 3\n",
    "#     }\n",
    "\n",
    "#     nb = GaussianNB()\n",
    "#     knn = KNeighborsClassifier(**knn_params)\n",
    "#     rf = RandomForestClassifier(**rf_params)\n",
    "#     xgb = XGBClassifier(**xgb_params)\n",
    "#     et = ExtraTreesClassifier(**et_params)\n",
    "#     lr = LogisticRegression(**lr_params)\n",
    "#     ada = AdaBoostClassifier(**ada_params)\n",
    "#     gb = GradientBoostingClassifier(**gb_params)\n",
    "#     svc = SVC(**svc_params)\n",
    "    \n",
    "#     return {'rf': rf,\n",
    "#             'et': et,\n",
    "#             'lr': lr,\n",
    "#             'ada': ada,\n",
    "#             'svc': svc,\n",
    "#             'nb': nb,\n",
    "#             'gb': gb,\n",
    "#             'knn': knn,\n",
    "#             'xgb': xgb}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# num_folds = 5\n",
    "\n",
    "# x_train_vals = x_train.values\n",
    "# x_test_vals = x_test.values\n",
    "# y_vals = y.ravel()\n",
    "\n",
    "# rf_train, rf_test = get_out_of_folds_preds(num_folds, rf, x_train_vals, x_test_vals, y_vals)\n",
    "# xgb_train, xgb_test = get_out_of_folds_preds(num_folds, xgb, x_train_vals, x_test_vals, y_vals)\n",
    "# ada_train, ada_test = get_out_of_folds_preds(num_folds, ada, x_train_vals, x_test_vals, y_vals)\n",
    "# gb_train, gb_test = get_out_of_folds_preds(num_folds, gb, x_train_vals, x_test_vals, y_vals)\n",
    "# svc_train, svc_test = get_out_of_folds_preds(num_folds, svc, x_train_vals, x_test_vals, y_vals)\n",
    "# et_train, et_test = get_out_of_folds_preds(num_folds, et, x_train_vals, x_test_vals, y_vals)\n",
    "\n",
    "# TODO: include Logistic Regressor\n",
    "# lr_train, lr_test = get_out_of_folds_preds(num_folds, lr, x_train_vals, x_test_vals, y_vals)\n",
    "    \n",
    "# Feature importances for ensemble models.\n",
    "# rf_importance = rf.fit(x_train.values, y.ravel()).feature_importances_\n",
    "# xgb_importance = xgb.fit(x_train.values, y.ravel()).feature_importances_\n",
    "# ada_importance = ada.fit(x_train.values, y.ravel()).feature_importances_\n",
    "# gb_importance = gb.fit(x_train.values, y.ravel()).feature_importances_\n",
    "# et_importance = et.fit(x_train.values, y.ravel()).feature_importances_\n",
    "\n",
    "# print (\"Random Forest Classifier feature importances:\\n{}\".format(rf_importance))\n",
    "# print (\"XGBoost Classifier feature importances:\\n{}\".format(xgb_importance))\n",
    "# print (\"AdaBoost Classifier feature importances:\\n{}\".format(ada_importance))\n",
    "# print (\"Gradient Boosting Classifier feature importances:\\n{}\".format(gb_importance))\n",
    "# print (\"Extra Trees Classifier feature importances:\\n{}\".format(et_importance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Train the base learners.\n",
    "# for (model_name, model) in base_learners.items():\n",
    "#     x_train, x_test = stack_model(model, x_train, x_test, y, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Feed the base learner predictions into the meta learner, and predict with meta learner.\n",
    "# meta_learner = XGBClassifier()\n",
    "# meta_learner.fit(x_train, y)\n",
    "# predictions = meta_learner.predict(x_test)\n",
    "# submission = pd.DataFrame({\"id\": test.id, \"Y\": predictions})\n",
    "# submission.to_csv('./results.csv', index = False, columns = [\"id\", \"Y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
