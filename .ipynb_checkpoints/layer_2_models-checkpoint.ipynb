{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking\n",
    "\n",
    "Julian Domingo - jad5348"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[MLENS] backend: threading\n"
     ]
    }
   ],
   "source": [
    "# Data analysis \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Modeling stuff\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from mlens.ensemble import SuperLearner\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import (RandomForestClassifier, \n",
    "                              AdaBoostClassifier,\n",
    "                              ExtraTreesClassifier,\n",
    "                              BaggingClassifier)\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "\n",
    "# Computation / numerical\n",
    "from scipy.stats import uniform, randint, hmean\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from mlens.preprocessing import Subset\n",
    "from mlens.metrics import make_scorer\n",
    "from mlens.model_selection import Evaluator\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For reproducibility\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Constants\n",
    "n_splits = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_ids = pd.read_csv(\"./data/raw/test.csv\")[[\"id\"]]\n",
    "y_train = pd.read_csv(\"./data/raw/train.csv\")[\"Y\"].ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_preds(preds, preds_filename):\n",
    "    submission = pd.DataFrame({\"id\": test_ids.id, \"Y\": preds})\n",
    "    submission.to_csv(\"./submissions/stacking_{}.csv\".format(preds_filename), index=False, columns=[\"id\", \"Y\"])\n",
    "    \n",
    "\n",
    "def get_cross_val_score(model, x_train, y_train, n_folds, run_parallel=True):\n",
    "    if run_parallel:\n",
    "        cv = cross_val_score(model, x_train, y_train, cv = n_folds, scoring = \"roc_auc\", n_jobs = -1)\n",
    "    else:\n",
    "        cv = cross_val_score(model, x_train, y_train, cv = n_folds, scoring = \"roc_auc\")\n",
    "\n",
    "    print(\"Cross validation score: {} +/- {}\\nRaw scores: {}\".format(str(np.mean(cv)), str(np.std(cv)), str(cv)))\n",
    "    return cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stacking Class\n",
    "\n",
    "Stacking works well for small to medium-sized data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Stacker(object):\n",
    "    def __init__(self, base_learners, meta_learners, y_train, test_ids):\n",
    "        self.base_learners = base_learners\n",
    "        self.meta_learners = meta_learners\n",
    "        self.y_train = y_train\n",
    "        self.test_ids = test_ids\n",
    "    \n",
    "    \n",
    "    def get_indiv_meta_preds(self, meta):\n",
    "        \"\"\" Retrieves the predictions of the model 'meta'. \"\"\"\n",
    "        if self.meta_features_train is None or self.meta_features_test is None:\n",
    "            raise ValueError(\"Invoke 'get_meta_features' before predicting.\")\n",
    "            \n",
    "        meta.fit(self.meta_features_train, self.y_train)\n",
    "        meta_preds = meta.predict_proba(self.meta_features_test)[:,1]\n",
    "        return meta_preds\n",
    "        \n",
    "        \n",
    "    def get_meta_features(self, mlens=False):\n",
    "        \"\"\" Retrieves all meta features for the train & test data from the base learners specified. \"\"\"\n",
    "        self.meta_features_train = np.zeros((len(self.y_train), len(self.base_learners)))\n",
    "        self.meta_features_test = np.zeros((len(self.test_ids), len(self.base_learners)))\n",
    "        \n",
    "        for i, base in enumerate(self.base_learners):\n",
    "            print (\"Gathering meta feature from '{}'...\".format(base))\n",
    "            \n",
    "            if mlens:\n",
    "                self.meta_features_train[:, i] = pd.read_csv(\"./meta_features/mlens/train/train_{}.csv\".format(base), \\\n",
    "                                                             index_col=0).as_matrix().ravel()\n",
    "                self.meta_features_test[:, i] = pd.read_csv(\"./meta_features/mlens/test/test_{}.csv\".format(base), \\\n",
    "                                                             index_col=0).as_matrix().ravel()\n",
    "            else:\n",
    "                self.meta_features_train[:, i] = pd.read_csv(\"./meta_features/train/train_{}.csv\".format(base), \\\n",
    "                                                             index_col=0).as_matrix().ravel()\n",
    "                self.meta_features_test[:, i] = pd.read_csv(\"./meta_features/test/test_{}.csv\".format(base), \\\n",
    "                                                            index_col=0).as_matrix().ravel()\n",
    "            \n",
    "        return self.meta_features_train.copy(), self.meta_features_test.copy()\n",
    "    \n",
    "    \n",
    "    def fit_meta_learners_and_predict(self):\n",
    "        \"\"\" Generates predictions using all meta features generated from the base learners for each meta learner. \"\"\"\n",
    "        if self.meta_features_train is None or self.meta_features_test is None:\n",
    "            raise ValueError(\"get_meta_features() should be called before generate_out_of_folds_preds.\")\n",
    "        \n",
    "        self.meta_learner_preds = np.zeros((len(self.test_ids), len(self.meta_learners)))\n",
    "        \n",
    "        for i, meta in enumerate(self.meta_learners):\n",
    "            meta.fit(self.meta_features_train, self.y_train)\n",
    "            self.meta_learner_preds[:, i] =  meta.predict_proba(self.meta_features_test)[:,1]\n",
    "            \n",
    "    \n",
    "    def get_df_meta_learner_preds(self):\n",
    "        if self.meta_learner_preds is None:\n",
    "            raise ValueError(\"No predictions were found. Invoke 'fit_meta_learners_and_predict' first.\")\n",
    "        \n",
    "        if self.base_learners is None:\n",
    "            raise ValueError(\"No base learners were specified. Construct an instance with base learners.\")\n",
    "        \n",
    "        return pd.DataFrame(self.meta_learner_preds, columns=self.base_learners)\n",
    "    \n",
    "    \n",
    "    def get_final_preds(self, mean=\"average\"):\n",
    "        if mean == \"average\":\n",
    "            return np.mean(self.meta_learner_preds, axis=1)\n",
    "        elif mean == \"harmonic\":\n",
    "            return hmean(self.meta_learner_preds, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta Learner(s) Parameter Tuning & Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble 1\n",
    "**Base Learners: **\n",
    "    * RF Raw\n",
    "    * RF Log\n",
    "    * RF Poly\n",
    "    * XGB Raw\n",
    "    * XGB Base\n",
    "    * XGB Poly\n",
    "    * LR Log\n",
    "    * Ada Base\n",
    "   \n",
    "**Meta Learners: **\n",
    "    * RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_learners_v1 = [\n",
    "    \"random_forest_raw\",\n",
    "    \"random_forest_log\",\n",
    "    \"random_forest_poly\",\n",
    "    \"xgboost_raw\",\n",
    "    \"xgboost_base\",\n",
    "    \"xgboost_poly\",\n",
    "    \"logistic_regression_log\",\n",
    "    \"adaboost_base\"\n",
    "]\n",
    "\n",
    "rf_meta_v1 = RandomForestClassifier(n_jobs=-1)\n",
    "\n",
    "meta_learners_v1 = [rf_meta_v1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gathering meta feature from 'random_forest_raw'...\n",
      "Gathering meta feature from 'random_forest_log'...\n",
      "Gathering meta feature from 'random_forest_poly'...\n",
      "Gathering meta feature from 'xgboost_raw'...\n",
      "Gathering meta feature from 'xgboost_base'...\n",
      "Gathering meta feature from 'xgboost_poly'...\n",
      "Gathering meta feature from 'logistic_regression_log'...\n",
      "Gathering meta feature from 'adaboost_base'...\n"
     ]
    }
   ],
   "source": [
    "stacker_v1 = Stacker(base_learners_v1, meta_learners_v1, y_train, test_ids)\n",
    "meta_features_train_v1, meta_features_test_v1 = stacker_v1.get_meta_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=-1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'max_features': [5, 6, 7], 'n_estimators': [300, 400, 500, 600, 700, 800, 900, 1000], 'max_depth': [5, 6, 7, 8, 9, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Warning: this block takes a long time to execute.\n",
    "rf_meta_v1_param_grid = {\n",
    "    \"max_features\": range(5, 7 + 1),\n",
    "    \"max_depth\": range(5, 10 + 1),\n",
    "    \"n_estimators\": range(300, 1000 + 1, 100) \n",
    "}\n",
    "\n",
    "gs_rf_v1 = GridSearchCV(estimator=rf_meta_v1, param_grid=rf_meta_v1_param_grid, cv=n_splits, scoring=\"roc_auc\", n_jobs=-1)\n",
    "gs_rf_v1.fit(meta_features_train_v1, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_features': 6, 'n_estimators': 300, 'max_depth': 6}\n",
      "0.772539082175\n"
     ]
    }
   ],
   "source": [
    "print gs_rf_v1.best_params_\n",
    "print gs_rf_v1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation score: 0.771359868469 +/- 0.00723717612684\n",
      "Raw scores: [ 0.76715711  0.77956341  0.75947714  0.77377431  0.77682737]\n",
      "[ 0.76715711  0.77956341  0.75947714  0.77377431  0.77682737]\n"
     ]
    }
   ],
   "source": [
    "print get_cross_val_score(RandomForestClassifier(n_jobs=-1, n_estimators=300, max_depth=6, max_features=6), meta_features_train_v1, y_train, n_folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.97136003  0.67447269  0.94252603 ...,  0.88289829  0.98178302\n",
      "  0.96819782]\n"
     ]
    }
   ],
   "source": [
    "# Get predictions w/ tuned params\n",
    "meta_preds_v1 = stacker_v1.get_indiv_meta_preds(RandomForestClassifier(n_jobs=-1, n_estimators=300, max_features=6, max_depth=6))\n",
    "print meta_preds_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.   0.7  0.9 ...,  1.   1.   1. ]\n"
     ]
    }
   ],
   "source": [
    "# Get predictions w/o tuned params\n",
    "meta_preds_v1_untuned = stacker_v1.get_indiv_meta_preds(RandomForestClassifier(n_jobs=-1))\n",
    "print meta_preds_v1_untuned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen by the predictions without tuned parameters, tuning of the meta model makes a tremendous difference on the prediction set obtained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Ensemble 2\n",
    "**Base Learners: **\n",
    "    * RF Raw\n",
    "    * RF Log\n",
    "    * RF Poly\n",
    "    * XGB Raw\n",
    "    * XGB Base\n",
    "    * XGB Poly\n",
    "    * LR Log\n",
    "    * Ada Base\n",
    "    * KNN_{2, 4, 8, 16, 32, 64, 128, 256, 512, 1024}\n",
    "   \n",
    "**Meta Learners: **\n",
    "    * RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gathering meta feature from 'random_forest_raw'...\n",
      "Gathering meta feature from 'random_forest_log'...\n",
      "Gathering meta feature from 'random_forest_poly'...\n",
      "Gathering meta feature from 'xgboost_raw'...\n",
      "Gathering meta feature from 'xgboost_base'...\n",
      "Gathering meta feature from 'xgboost_poly'...\n",
      "Gathering meta feature from 'logistic_regression_log'...\n",
      "Gathering meta feature from 'adaboost_base'...\n",
      "Gathering meta feature from 'knn_2'...\n",
      "Gathering meta feature from 'knn_4'...\n",
      "Gathering meta feature from 'knn_8'...\n",
      "Gathering meta feature from 'knn_16'...\n",
      "Gathering meta feature from 'knn_32'...\n",
      "Gathering meta feature from 'knn_64'...\n",
      "Gathering meta feature from 'knn_128'...\n",
      "Gathering meta feature from 'knn_256'...\n",
      "Gathering meta feature from 'knn_512'...\n",
      "Gathering meta feature from 'knn_1024'...\n"
     ]
    }
   ],
   "source": [
    "base_learners_v2 = [\n",
    "    \"random_forest_raw\",\n",
    "    \"random_forest_log\",\n",
    "    \"random_forest_poly\",\n",
    "    \"xgboost_raw\",\n",
    "    \"xgboost_base\",\n",
    "    \"xgboost_poly\",\n",
    "    \"logistic_regression_log\",\n",
    "    \"adaboost_base\",\n",
    "    \"knn_2\",\n",
    "    \"knn_4\",\n",
    "    \"knn_8\",\n",
    "    \"knn_16\",\n",
    "    \"knn_32\",\n",
    "    \"knn_64\",\n",
    "    \"knn_128\",\n",
    "    \"knn_256\",\n",
    "    \"knn_512\",\n",
    "    \"knn_1024\"\n",
    "]\n",
    "\n",
    "rf_meta_v2 = RandomForestClassifier(n_jobs=-1)\n",
    "meta_learners_v2 = [rf_meta_v2]\n",
    "\n",
    "stacker_v2 = Stacker(base_learners_v2, meta_learners_v2, y_train, test_ids)\n",
    "meta_features_train_v2, meta_features_test_v2 = stacker_v2.get_meta_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=-1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'max_features': [5, 6, 7], 'n_estimators': [300, 400, 500, 600, 700, 800, 900, 1000], 'max_depth': [5, 6, 7, 8, 9, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Warning: this block takes a long time to execute.\n",
    "rf_meta_v2_param_grid = {\n",
    "    \"max_features\": range(5, 7 + 1),\n",
    "    \"max_depth\": range(5, 10 + 1),\n",
    "    \"n_estimators\": range(300, 1000 + 1, 100) \n",
    "}\n",
    "\n",
    "gs_rf_v2 = GridSearchCV(estimator=rf_meta_v2, param_grid=rf_meta_v2_param_grid, cv=n_splits, scoring=\"roc_auc\", n_jobs=-1)\n",
    "gs_rf_v2.fit(meta_features_train_v2, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_features': 5, 'n_estimators': 300, 'max_depth': 9}\n",
      "0.773074767924\n"
     ]
    }
   ],
   "source": [
    "print gs_rf_v2.best_params_\n",
    "print gs_rf_v2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation score: 0.769897637451 +/- 0.00448583181217\n",
      "Raw scores: [ 0.76837689  0.77614972  0.77087385  0.76246286  0.77162487]\n",
      "[ 0.76837689  0.77614972  0.77087385  0.76246286  0.77162487]\n"
     ]
    }
   ],
   "source": [
    "print get_cross_val_score(RandomForestClassifier(n_jobs=-1, n_estimators=300, max_depth=9, max_features=5), meta_features_train_v2, y_train, n_folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.97460188  0.66699757  0.95640802 ...,  0.91079086  0.98644606\n",
      "  0.97122791]\n"
     ]
    }
   ],
   "source": [
    "# Get predictions w/ tuned params\n",
    "meta_preds_v2_tuned = stacker_v2.get_indiv_meta_preds(RandomForestClassifier(n_jobs=-1, n_estimators=300, max_depth=9, max_features=5))\n",
    "print meta_preds_v2_tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_preds(meta_preds_v2_tuned, \"_\".join(base_learners_v2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble 3\n",
    "**Base Learners: **\n",
    "    * RF Raw\n",
    "    * RF Log\n",
    "    * RF Poly\n",
    "    * XGB Raw\n",
    "    * XGB Base\n",
    "    * XGB Reduced\n",
    "    * XGB Poly\n",
    "    * LR Log\n",
    "    * Ada Base\n",
    "    * Bagged XGB (50 runs)\n",
    "    * Extra Trees Base\n",
    "    \n",
    "**Meta Learners: **\n",
    "    * RF\n",
    "    * XGB\n",
    "    \n",
    "**Final Predictions**: harmonic mean of meta learner predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gathering meta feature from 'random_forest_raw'...\n",
      "Gathering meta feature from 'random_forest_log'...\n",
      "Gathering meta feature from 'random_forest_poly'...\n",
      "Gathering meta feature from 'xgboost_reduced'...\n",
      "Gathering meta feature from 'xgboost_raw'...\n",
      "Gathering meta feature from 'xgboost_base'...\n",
      "Gathering meta feature from 'xgboost_poly'...\n",
      "Gathering meta feature from 'xgboost_bag'...\n",
      "Gathering meta feature from 'logistic_regression_log'...\n",
      "Gathering meta feature from 'adaboost_base'...\n",
      "Gathering meta feature from 'extra_trees_base'...\n"
     ]
    }
   ],
   "source": [
    "base_learners_v3 = [\n",
    "    \"random_forest_raw\",\n",
    "    \"random_forest_log\",\n",
    "    \"random_forest_poly\",\n",
    "    \"xgboost_reduced\",\n",
    "    \"xgboost_raw\",\n",
    "    \"xgboost_base\",\n",
    "    \"xgboost_poly\",\n",
    "    \"xgboost_bag\",\n",
    "    \"logistic_regression_log\",\n",
    "    \"adaboost_base\",\n",
    "    \"extra_trees_base\"\n",
    "]\n",
    "\n",
    "rf_meta_v3 = RandomForestClassifier(n_jobs=-1, max_features=2, n_estimators=300, max_depth=8, random_state=seed)\n",
    "meta_learners_v3 = [rf_meta_v3]\n",
    "\n",
    "stacker_v3 = Stacker(base_learners_v3, meta_learners_v3, y_train, test_ids)\n",
    "meta_features_train_v3, meta_features_test_v3 = stacker_v3.get_meta_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 99 candidates, totalling 495 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-342-7d684007a907>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mgs_rf_v3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrf_meta_v3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrf_v3_param_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"roc_auc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mgs_rf_v3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta_features_train_v3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/julian/anaconda2/lib/python2.7/site-packages/sklearn/model_selection/_search.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 639\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/julian/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/julian/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/julian/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/julian/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.pyc\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/julian/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/julian/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/julian/anaconda2/lib/python2.7/site-packages/sklearn/model_selection/_validation.pyc\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/julian/anaconda2/lib/python2.7/site-packages/sklearn/ensemble/forest.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    326\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[0;32m--> 328\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/julian/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/julian/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/julian/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/julian/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.pyc\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/julian/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/_parallel_backends.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/julian/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/julian/anaconda2/lib/python2.7/site-packages/sklearn/ensemble/forest.pyc\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight)\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'balanced'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/julian/anaconda2/lib/python2.7/site-packages/sklearn/tree/tree.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    788\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 790\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    791\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/julian/anaconda2/lib/python2.7/site-packages/sklearn/tree/tree.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    360\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Warning: this block takes a long time to execute.\n",
    "rf_v3_param_grid = {\n",
    "    \"max_features\": range(3, 5 + 1),\n",
    "    \"max_depth\": range(8, 10 + 1),\n",
    "    \"n_estimators\": range(250, 350 + 1, 10) \n",
    "}\n",
    "\n",
    "gs_rf_v3 = GridSearchCV(estimator=rf_meta_v3, param_grid=rf_v3_param_grid, cv=n_splits, scoring=\"roc_auc\", n_jobs=-1, verbose=1)\n",
    "gs_rf_v3.fit(meta_features_train_v3, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_features': 2, 'n_estimators': 300, 'max_depth': 8}\n",
      "0.776661015238\n"
     ]
    }
   ],
   "source": [
    "print gs_rf_v3.best_params_\n",
    "print gs_rf_v3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_features': 5, 'n_estimators': 310, 'max_depth': 9}\n",
      "0.7771661899370343\n"
     ]
    }
   ],
   "source": [
    "# After first iteration\n",
    "print gs_rf_v3.best_params_\n",
    "print gs_rf_v3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adding xgbreduced\n",
    "print gs_rf_v3.best_params_\n",
    "print gs_rf_v3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation score: 0.7758377713611871 +/- 0.00887867046923868\n",
      "Raw scores: [0.77596569 0.78868348 0.76137561 0.77351094 0.77965313]\n",
      "[0.77596569 0.78868348 0.76137561 0.77351094 0.77965313]\n"
     ]
    }
   ],
   "source": [
    "print get_cross_val_score(RandomForestClassifier(n_jobs=-1, n_estimators=300, max_depth=8, max_features=2, random_state=seed),\n",
    "                          meta_features_train_v3,\n",
    "                          y_train,\n",
    "                          n_folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "print get_cross_val_score(RandomForestClassifier(n_jobs=-1, n_estimators=310, max_depth=9, max_features=5, random_state=seed),\n",
    "                          meta_features_train_v3,\n",
    "                          y_train,\n",
    "                          n_folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.97333875 0.64369521 0.93752947 ... 0.90418185 0.982669   0.96400992]\n"
     ]
    }
   ],
   "source": [
    "meta_preds_v3_tuned = stacker_v3.get_indiv_meta_preds(RandomForestClassifier(n_jobs=-1,\n",
    "                                                                             n_estimators=300,\n",
    "                                                                             max_depth=8,\n",
    "                                                                             max_features=2, random_state=seed))\n",
    "print meta_preds_v3_tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_preds(meta_preds_v3_tuned, \"rf_only_meta_{}\".format(\"_\".join(base_learners_v3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGB Meta Learner Parameter Tuning\n",
    "\n",
    "Note that the \"final_params\" dictionary is iteratively updated as more parameters are tuned. The initial values are the same listed in the lauyer_1_models jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Change the \"after first iteration\" block when adding new metafeatures\n",
    "final_xgb_v3_params = {\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"n_estimators\": 39,\n",
    "    \"max_depth\": 4,\n",
    "    \"min_child_weight\": 0,\n",
    "    \"gamma\": 0.175,\n",
    "    \"subsample\": 0.65,\n",
    "    \"colsample_bytree\": 0.5,\n",
    "    \"objective\": 'binary:logistic', # Used for classifier XGB\n",
    "    \"scale_pos_weight\": 1,\n",
    "    \"seed\": seed\n",
    "}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    2.0s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   12.5s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:   13.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.5, gamma=0.185, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=4, min_child_weight=0, missing=None,\n",
       "       n_estimators=39, n_jobs=1, nthread=None,\n",
       "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=42, silent=True,\n",
       "       subsample=0.65),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'n_estimators': [30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_meta_v3 = XGBClassifier(**final_xgb_v3_params)\n",
    "\n",
    "# Warning: this block takes a long time to execute.\n",
    "xgb_v3_n_est = {\n",
    "    \"n_estimators\": range(30, 70)\n",
    "}\n",
    "\n",
    "gs_xgb_v3_n_est = GridSearchCV(estimator=xgb_meta_v3, param_grid=xgb_v3_n_est, cv=n_splits, scoring=\"roc_auc\", n_jobs=-1, verbose=1)\n",
    "gs_xgb_v3_n_est.fit(meta_features_train_v3, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 56}\n",
      "0.7743626942129123\n"
     ]
    }
   ],
   "source": [
    "# With no KNNs\n",
    "print gs_xgb_v3_n_est.best_params_\n",
    "print gs_xgb_v3_n_est.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 39}\n",
      "0.7790001418640146\n"
     ]
    }
   ],
   "source": [
    "# After first iteration \n",
    "print gs_xgb_v3_n_est.best_params_\n",
    "print gs_xgb_v3_n_est.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 42}\n",
      "0.7783016226867695\n"
     ]
    }
   ],
   "source": [
    "# Corrected from first iteration\n",
    "print gs_xgb_v3_n_est.best_params_\n",
    "print gs_xgb_v3_n_est.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 42}\n",
      "0.778939645637447\n"
     ]
    }
   ],
   "source": [
    "# After second iteration. Converged to final value.\n",
    "print gs_xgb_v3_n_est.best_params_\n",
    "print gs_xgb_v3_n_est.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 39}\n",
      "0.778119416007\n"
     ]
    }
   ],
   "source": [
    "# After second iteration\n",
    "print gs_xgb_v3_n_est.best_params_\n",
    "print gs_xgb_v3_n_est.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_base_params = {\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"n_estimators\": 1000,\n",
    "    \"max_depth\": 5,\n",
    "    \"min_child_weight\": 1,\n",
    "    \"gamma\": 0,\n",
    "    \"subsample\": 0.8,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"objective\": 'binary:logistic', # Used for classifier XGB\n",
    "    \"scale_pos_weight\": 1,\n",
    "    \"seed\": seed\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 35 candidates, totalling 175 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 175 out of 175 | elapsed:    8.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.5, gamma=0.185, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=4, min_child_weight=0, missing=None,\n",
       "       n_estimators=39, n_jobs=1, nthread=None,\n",
       "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=42, silent=True,\n",
       "       subsample=0.65),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'max_depth': [1, 2, 3, 4, 5], 'min_child_weight': [0, 1, 2, 3, 4, 5, 6]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_v3_md_mcw = {\n",
    "    \"max_depth\": range(1, 6),\n",
    "    \"min_child_weight\": range(0, 6 + 1)\n",
    "}\n",
    "\n",
    "gs_xgb_v3_md_mcw = GridSearchCV(estimator=XGBClassifier(**final_xgb_v3_params), \n",
    "                                                       param_grid=xgb_v3_md_mcw, \n",
    "                                                       cv=n_splits, \n",
    "                                                       scoring=\"roc_auc\", \n",
    "                                                       n_jobs=-1, \n",
    "                                                       verbose=1)\n",
    "gs_xgb_v3_md_mcw.fit(meta_features_train_v3, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 3, 'min_child_weight': 0}\n",
      "0.77683418973155\n"
     ]
    }
   ],
   "source": [
    "# Run 1\n",
    "print gs_xgb_v3_md_mcw.best_params_\n",
    "print gs_xgb_v3_md_mcw.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 3, 'min_child_weight': 2}\n",
      "0.778939645637447\n"
     ]
    }
   ],
   "source": [
    "# After first iteration\n",
    "print gs_xgb_v3_md_mcw.best_params_\n",
    "print gs_xgb_v3_md_mcw.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 4, 'min_child_weight': 0}\n",
      "0.778119416007\n"
     ]
    }
   ],
   "source": [
    "# After second iteration\n",
    "print gs_xgb_v3_md_mcw.best_params_\n",
    "print gs_xgb_v3_md_mcw.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  25 out of  25 | elapsed:    1.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.5, gamma=0.175, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=4, min_child_weight=0, missing=None,\n",
       "       n_estimators=39, n_jobs=1, nthread=None,\n",
       "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=42, silent=True,\n",
       "       subsample=0.65),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'gamma': [0.17, 0.175, 0.18, 0.185, 0.19]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_v3_gamma = {\n",
    "#     \"gamma\": [0.185, 0.186, 0.187, 0.188, 0.189, 0.19, 0.191, 0.192, 0.193, 0.194, 0.195]\n",
    "    \"gamma\": [0.17, 0.175, 0.18, 0.185, 0.19]\n",
    "}\n",
    "\n",
    "gs_xgb_v3_gamma = GridSearchCV(estimator=XGBClassifier(**final_xgb_v3_params), \n",
    "                                                       param_grid=xgb_v3_gamma, \n",
    "                                                       cv=n_splits, \n",
    "                                                       scoring=\"roc_auc\", \n",
    "                                                       n_jobs=-1, \n",
    "                                                       verbose=1)\n",
    "gs_xgb_v3_gamma.fit(meta_features_train_v3, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gamma': 0.2}\n",
      "0.7768581661860074\n"
     ]
    }
   ],
   "source": [
    "# Run 1\n",
    "print gs_xgb_v3_gamma.best_params_\n",
    "print gs_xgb_v3_gamma.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gamma': 0.19}\n",
      "0.7768581661860074\n"
     ]
    }
   ],
   "source": [
    "# Run 2\n",
    "print gs_xgb_v3_gamma.best_params_\n",
    "print gs_xgb_v3_gamma.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gamma': 0.185}\n",
      "0.778939645637447\n"
     ]
    }
   ],
   "source": [
    "# After first iteration\n",
    "print gs_xgb_v3_gamma.best_params_\n",
    "print gs_xgb_v3_gamma.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gamma': 0.175}\n",
      "0.778119416007\n"
     ]
    }
   ],
   "source": [
    "# After second iteration\n",
    "print gs_xgb_v3_gamma.best_params_\n",
    "print gs_xgb_v3_gamma.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    3.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.5, gamma=0.175, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=4, min_child_weight=0, missing=None,\n",
       "       n_estimators=39, n_jobs=1, nthread=None,\n",
       "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=42, silent=True,\n",
       "       subsample=0.65),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'subsample': [0.645, 0.65, 0.655], 'colsample_bytree': [0.5, 0.55, 0.6]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_v3_ss_cb = {\n",
    "#     \"subsample\": [0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8],\n",
    "#     \"colsample_bytree\": [0.3, 0.35, 0.4, 0.45, 0.5, 0.55, 0.6, 0.65, 0.7, 0.75, 0.8]\n",
    "    \"subsample\": [0.645, 0.65, 0.655],\n",
    "    \"colsample_bytree\": [0.5, 0.55, 0.6]\n",
    "}\n",
    "\n",
    "gs_xgb_v3_ss_cb = GridSearchCV(estimator=XGBClassifier(**final_xgb_v3_params), \n",
    "                                                       param_grid=xgb_v3_ss_cb, \n",
    "                                                       cv=n_splits, \n",
    "                                                       scoring=\"roc_auc\", \n",
    "                                                       n_jobs=-1, \n",
    "                                                       verbose=1)\n",
    "gs_xgb_v3_ss_cb.fit(meta_features_train_v3, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subsample': 0.65, 'colsample_bytree': 0.5}\n",
      "0.7779686180633612\n"
     ]
    }
   ],
   "source": [
    "# Run 1\n",
    "print gs_xgb_v3_ss_cb.best_params_\n",
    "print gs_xgb_v3_ss_cb.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subsample': 0.65, 'colsample_bytree': 0.5}\n",
      "0.778939645637447\n"
     ]
    }
   ],
   "source": [
    "# After first iteration\n",
    "print gs_xgb_v3_ss_cb.best_params_\n",
    "print gs_xgb_v3_ss_cb.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subsample': 0.65, 'colsample_bytree': 0.5}\n",
      "0.778119416007\n"
     ]
    }
   ],
   "source": [
    "# After second iteration\n",
    "print gs_xgb_v3_ss_cb.best_params_\n",
    "print gs_xgb_v3_ss_cb.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gathering meta feature from 'random_forest_raw'...\n",
      "Gathering meta feature from 'random_forest_log'...\n",
      "Gathering meta feature from 'random_forest_poly'...\n",
      "Gathering meta feature from 'xgboost_reduced'...\n",
      "Gathering meta feature from 'xgboost_raw'...\n",
      "Gathering meta feature from 'xgboost_base'...\n",
      "Gathering meta feature from 'xgboost_poly'...\n",
      "Gathering meta feature from 'xgboost_bag'...\n",
      "Gathering meta feature from 'logistic_regression_log'...\n",
      "Gathering meta feature from 'adaboost_base'...\n",
      "Gathering meta feature from 'extra_trees_base'...\n"
     ]
    }
   ],
   "source": [
    "# Make fresh Stacker instance\n",
    "base_learners_v3_final = [\n",
    "    \"random_forest_raw\",\n",
    "    \"random_forest_log\",\n",
    "    \"random_forest_poly\",\n",
    "    \"xgboost_reduced\",\n",
    "    \"xgboost_raw\",\n",
    "    \"xgboost_base\",\n",
    "    \"xgboost_poly\",\n",
    "    \"xgboost_bag\",\n",
    "    \"logistic_regression_log\",\n",
    "    \"adaboost_base\",\n",
    "    \"extra_trees_base\"\n",
    "]\n",
    "\n",
    "rf_final_v3 = RandomForestClassifier(n_estimators=300, max_depth=8, max_features=2, random_state=seed)\n",
    "xgb_final_v3 = XGBClassifier(**final_xgb_v3_params)\n",
    "\n",
    "meta_learners_v3_final = [rf_final_v3, xgb_final_v3]\n",
    "\n",
    "stacker_v3_final = Stacker(base_learners_v3_final, meta_learners_v3_final, y_train, test_ids)\n",
    "train_final_v3, test_final_v3 = stacker_v3_final.get_meta_features()\n",
    "stacker_v3_final.fit_meta_learners_and_predict()\n",
    "stacker_v3_final_preds = stacker_v3_final.get_final_preds(mean=\"harmonic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.96800797  0.67794841  0.93948099 ...,  0.9077512   0.97617163\n",
      "  0.95550081]\n"
     ]
    }
   ],
   "source": [
    "print stacker_v3_final_preds\n",
    "save_preds(stacker_v3_final_preds, \"{}_v2\".format(\"_\".join(base_learners_v3_final)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensemble 3b (added reduced xgb / svc with base data)\n",
    "\n",
    "**Base Learners: **\n",
    "    * RF Raw\n",
    "    * RF Log\n",
    "    * RF Poly\n",
    "    * XGB Reduced\n",
    "    * XGB Raw\n",
    "    * XGB Base\n",
    "    * XGB Poly\n",
    "    * LR Log\n",
    "    * Ada Base\n",
    "    * Bagged XGB (50 runs)\n",
    "    * Extra Trees Base\n",
    "    * SVC Base\n",
    "    \n",
    "**Meta Learners: **\n",
    "    * RF\n",
    "    * XGB\n",
    "    \n",
    "**Final Predictions**: harmonic mean of meta learner predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gathering meta feature from 'random_forest_raw'...\n",
      "Gathering meta feature from 'random_forest_log'...\n",
      "Gathering meta feature from 'random_forest_poly'...\n",
      "Gathering meta feature from 'xgboost_reduced'...\n",
      "Gathering meta feature from 'xgboost_raw'...\n",
      "Gathering meta feature from 'xgboost_base'...\n",
      "Gathering meta feature from 'xgboost_poly'...\n",
      "Gathering meta feature from 'xgboost_bag'...\n",
      "Gathering meta feature from 'logistic_regression_log'...\n",
      "Gathering meta feature from 'adaboost_base'...\n",
      "Gathering meta feature from 'extra_trees_base'...\n",
      "Gathering meta feature from 'svc_base'...\n"
     ]
    }
   ],
   "source": [
    "base_learners_v3 = [\n",
    "    \"random_forest_raw\",\n",
    "    \"random_forest_log\",\n",
    "    \"random_forest_poly\",\n",
    "    \"xgboost_reduced\",\n",
    "    \"xgboost_raw\",\n",
    "    \"xgboost_base\",\n",
    "    \"xgboost_poly\",\n",
    "    \"xgboost_bag\",\n",
    "    \"logistic_regression_log\",\n",
    "    \"adaboost_base\",\n",
    "    \"extra_trees_base\",\n",
    "    \"svc_base\"\n",
    "]\n",
    "\n",
    "rf_meta_v3 = RandomForestClassifier(n_jobs=-1, max_features=2, n_estimators=300, max_depth=8, random_state=seed)\n",
    "meta_learners_v3 = [rf_meta_v3]\n",
    "\n",
    "stacker_v3 = Stacker(base_learners_v3, meta_learners_v3, y_train, test_ids)\n",
    "meta_features_train_v3, meta_features_test_v3 = stacker_v3.get_meta_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_v3_b = {\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"n_estimators\": 42,\n",
    "    \"max_depth\": 3,\n",
    "    \"min_child_weight\": 2,\n",
    "    \"gamma\": 0.19,\n",
    "    \"subsample\": 0.65,\n",
    "    \"colsample_bytree\": 0.5,\n",
    "    \"objective\": 'binary:logistic', # Used for classifier XGB\n",
    "    \"scale_pos_weight\": 1,\n",
    "    \"seed\": seed\n",
    "}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.8s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   11.2s\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:   12.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.5, gamma=0.19, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=3, min_child_weight=2, missing=None,\n",
       "       n_estimators=42, n_jobs=1, nthread=None,\n",
       "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=42, silent=True,\n",
       "       subsample=0.65),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'n_estimators': [30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_meta_v3 = XGBClassifier(**xgb_v3_b)\n",
    "\n",
    "# Warning: this block takes a long time to execute.\n",
    "xgb_v3_n_est = {\n",
    "    \"n_estimators\": range(30, 70)\n",
    "}\n",
    "\n",
    "gs_xgb_v3_n_est = GridSearchCV(estimator=xgb_meta_v3, param_grid=xgb_v3_n_est, cv=n_splits, scoring=\"roc_auc\", n_jobs=-1, verbose=1)\n",
    "gs_xgb_v3_n_est.fit(meta_features_train_v3, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 53}\n",
      "0.7752741875519101\n"
     ]
    }
   ],
   "source": [
    "print gs_xgb_v3_n_est.best_params_\n",
    "print gs_xgb_v3_n_est.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 30}\n",
      "0.775114727204\n"
     ]
    }
   ],
   "source": [
    "# With all 3b models\n",
    "print gs_xgb_v3_n_est.best_params_\n",
    "print gs_xgb_v3_n_est.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 45}\n",
      "0.775986645495\n"
     ]
    }
   ],
   "source": [
    "print gs_xgb_v3_n_est.best_params_\n",
    "print gs_xgb_v3_n_est.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_v3_md_mcw = {\n",
    "    \"max_depth\": range(1, 6),\n",
    "    \"min_child_weight\": range(0, 6 + 1)\n",
    "}\n",
    "\n",
    "gs_xgb_v3_md_mcw = GridSearchCV(estimator=XGBClassifier(**xgb_v3_b), \n",
    "                                                       param_grid=xgb_v3_md_mcw, \n",
    "                                                       cv=n_splits, \n",
    "                                                       scoring=\"roc_auc\", \n",
    "                                                       n_jobs=-1, \n",
    "                                                       verbose=1)\n",
    "gs_xgb_v3_md_mcw.fit(meta_features_train_v3, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML-ensemble Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_meta_mlens_v1 = RandomForestClassifier(n_jobs=-1, n_estimators=300, max_depth=6)\n",
    "\n",
    "mlens_base_learners = [\n",
    "    RandomForestClassifier(criterion='entropy', max_depth=10, n_estimators=1000, n_jobs=-1),\n",
    "    LogisticRegression(C=100, tol=1e-05, solver=\"liblinear\"),\n",
    "    AdaBoostClassifier(n_estimators=395, learning_rate=1.55),\n",
    "    XGBClassifier(learning_rate=0.1,\n",
    "                    n_estimators=345,\n",
    "                    max_depth=8,\n",
    "                    min_child_weight=2,\n",
    "                    gamma=0.2,\n",
    "                    subsample=0.6,\n",
    "                    colsample_bytree=0.5,\n",
    "                    objective=\"binary:logistic\",\n",
    "                    n_jobs=-1,\n",
    "                    scale_pos_weight=1,\n",
    "                    seed=seed)\n",
    "]\n",
    "\n",
    "ensemble_v1 = SuperLearner(random_state=seed, scorer=roc_auc_score)\n",
    "ensemble_v1.add(mlens_base_learners, proba=True)\n",
    "ensemble_v1.add_meta(rf_meta_mlens_v1, proba=True)\n",
    "mlens_v1_preds = ensemble_v1.fit(meta_features_train_v1, y_train).predict_proba(meta_features_test_v1)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.9640277   0.70394427  0.95102447 ...,  0.89943802  0.98440754\n",
      "  0.95957553]\n"
     ]
    }
   ],
   "source": [
    "print mlens_v1_preds\n",
    "save_preds(mlens_v1_preds, \"mlens_v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_meta_mlens_v2 = RandomForestClassifier(n_jobs=-1, n_estimators=300, max_depth=9, max_features=5)\n",
    "\n",
    "mlens_base_learners = [\n",
    "    RandomForestClassifier(criterion='entropy', max_depth=10, n_estimators=1000, n_jobs=-1),\n",
    "    LogisticRegression(C=100, tol=1e-05, solver=\"liblinear\"),\n",
    "    ExtraTreesClassifier(max_depth=12, n_estimators=250, n_jobs=-1, criterion=\"entropy\"),\n",
    "    AdaBoostClassifier(n_estimators=395, learning_rate=1.55),\n",
    "    XGBClassifier(learning_rate=0.1,\n",
    "                    n_estimators=345,\n",
    "                    max_depth=8,\n",
    "                    min_child_weight=2,\n",
    "                    gamma=0.2,\n",
    "                    subsample=0.6,\n",
    "                    colsample_bytree=0.5,\n",
    "                    objective=\"binary:logistic\",\n",
    "                    n_jobs=-1,\n",
    "                    scale_pos_weight=1,\n",
    "                    seed=seed),\n",
    "    KNeighborsClassifier(n_jobs=-1, n_neighbors=2),\n",
    "    KNeighborsClassifier(n_jobs=-1, n_neighbors=4),\n",
    "    KNeighborsClassifier(n_jobs=-1, n_neighbors=8),\n",
    "    KNeighborsClassifier(n_jobs=-1, n_neighbors=16),\n",
    "    KNeighborsClassifier(n_jobs=-1, n_neighbors=32),\n",
    "    KNeighborsClassifier(n_jobs=-1, n_neighbors=64),\n",
    "    KNeighborsClassifier(n_jobs=-1, n_neighbors=128),\n",
    "    KNeighborsClassifier(n_jobs=-1, n_neighbors=256),\n",
    "    KNeighborsClassifier(n_jobs=-1, n_neighbors=512),\n",
    "    KNeighborsClassifier(n_jobs=-1, n_neighbors=1024)\n",
    "]\n",
    "\n",
    "ensemble_v2 = SuperLearner(random_state=seed, scorer=roc_auc_score)\n",
    "ensemble_v2.add(mlens_base_learners, proba=True)\n",
    "ensemble_v2.add_meta(rf_meta_mlens_v2, proba=True)\n",
    "mlens_v2_preds = ensemble_v2.fit(meta_features_train_v2, y_train).predict_proba(meta_features_test_v2)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.97149235  0.76364833  0.96501911 ...,  0.92276353  0.98632556\n",
      "  0.96678698]\n"
     ]
    }
   ],
   "source": [
    "print mlens_v2_preds\n",
    "save_preds(mlens_v2_preds, \"mlens_v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After looking at the LB scores, it seems adding KNeighborsClassifier models don't improve the stacking ensemble."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#     \"random_forest_raw\",\n",
    "#     \"random_forest_log\",\n",
    "#     \"random_forest_poly\",\n",
    "#     \"xgboost_reduced\",\n",
    "#     \"xgboost_raw\",\n",
    "#     \"xgboost_base\",\n",
    "#     \"xgboost_poly\",\n",
    "#     \"xgboost_bag\",\n",
    "#     \"logistic_regression_log\",\n",
    "#     \"adaboost_base\",\n",
    "#     \"extra_trees_base\"\n",
    "\n",
    "# Base learners\n",
    "rfc = RandomForestClassifier(criterion='entropy', max_depth=10, n_estimators=1000, n_jobs=-1)\n",
    "lr = LogisticRegression(C=100, tol=1e-05, solver=\"liblinear\")\n",
    "et = ExtraTreesClassifier(max_depth=12, n_estimators=250, n_jobs=-1, criterion=\"entropy\")\n",
    "ada = AdaBoostClassifier(n_estimators=395, learning_rate=1.55)\n",
    "xgb_base = XGBClassifier(learning_rate=0.1,\n",
    "                    n_estimators=311,\n",
    "                    max_depth=8,\n",
    "                    min_child_weight=2,\n",
    "                    gamma=0.2,\n",
    "                    subsample=0.6,\n",
    "                    colsample_bytree=0.5,\n",
    "                    objective=\"binary:logistic\",\n",
    "                    n_jobs=-1,\n",
    "                    seed=seed)\n",
    "xgb_reduced = XGBClassifier(learning_rate=0.1,\n",
    "                    n_estimators=223,\n",
    "                    max_depth=7,\n",
    "                    min_child_weight=1,\n",
    "                    gamma=0,\n",
    "                    subsample=0.8,\n",
    "                    colsample_bytree=0.75,\n",
    "                    objective=\"binary:logistic\",\n",
    "                    n_jobs=-1,\n",
    "                    seed=seed)\n",
    "xgb_raw = XGBClassifier(learning_rate=0.05,\n",
    "                    n_estimators=308,\n",
    "                    max_depth=9,\n",
    "                    min_child_weight=1,\n",
    "                    gamma=0,\n",
    "                    subsample=0.75,\n",
    "                    colsample_bytree=0.35,\n",
    "                    objective=\"binary:logistic\",\n",
    "                    n_jobs=-1,\n",
    "                    seed=seed)\n",
    "xgb_bag = BaggingClassifier(base_estimator=xgb_base,\n",
    "                            n_estimators=40, \n",
    "                            max_samples=0.8, \n",
    "                            max_features=0.75, \n",
    "                            bootstrap_features=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/julian/anaconda2/lib/python2.7/site-packages/sklearn/externals/joblib/parallel.py:540: UserWarning: Multiprocessing backed parallel loops cannot be nested below threads, setting n_jobs=1\n",
      "  **self._backend_args)\n"
     ]
    }
   ],
   "source": [
    "rf_meta_mlens_v3 = RandomForestClassifier(n_jobs=-1, n_estimators=300, max_depth=8, max_features=2)\n",
    "xgb_meta_mlens_v3 = XGBClassifier(**final_xgb_v3_params)\n",
    "\n",
    "# TODO: Tune poly xgb\n",
    "mlens_base_learners_v3 = [rfc, lr, et, ada, xgb_raw, xgb_base, xgb_reduced, xgb_bag]\n",
    "\n",
    "ensemble_v3 = SuperLearner(random_state=seed, scorer=roc_auc_score)\n",
    "ensemble_v3.add(mlens_base_learners_v3, proba=True)\n",
    "# ensemble_v3.add_meta(rf_meta_mlens_v3, proba=True)\n",
    "ensemble_v3.add_meta(xgb_meta_mlens_v3, proba=True)\n",
    "mlens_v3_preds = ensemble_v3.fit(meta_features_train_v3, y_train).predict_proba(meta_features_test_v3)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.98159868  0.6663233   0.94211096 ...,  0.92641664  0.98821068\n",
      "  0.95964485]\n"
     ]
    }
   ],
   "source": [
    "print mlens_v3_preds\n",
    "save_preds(mlens_v3_preds, \"mlens_v3_xgb_meta_only\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9718517  0.7683457  0.9387753  ... 0.8941298  0.9785266  0.95327765]\n"
     ]
    }
   ],
   "source": [
    "print mlens_v3_preds\n",
    "save_preds(mlens_v3_preds, \"mlens_v3_xgb_meta_only_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print mlens_v3_preds\n",
    "save_preds(mlens_v3_preds, \"mlens_v3_xgb_meta_only_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We'll also generate predictions using the same ensemble, but with 1st layer metafeatures generated through mlen's SuperLearner class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gathering meta feature from 'random_forest_raw'...\n",
      "Gathering meta feature from 'random_forest_log'...\n",
      "Gathering meta feature from 'random_forest_poly'...\n",
      "Gathering meta feature from 'xgboost_raw'...\n",
      "Gathering meta feature from 'xgboost_base'...\n",
      "Gathering meta feature from 'xgboost_poly'...\n",
      "Gathering meta feature from 'xgboost_bag'...\n",
      "Gathering meta feature from 'logistic_regression_log'...\n",
      "Gathering meta feature from 'adaboost_base'...\n",
      "Gathering meta feature from 'extra_trees_base'...\n",
      "Gathering meta feature from 'knn_16'...\n",
      "Gathering meta feature from 'knn_32'...\n",
      "Gathering meta feature from 'knn_64'...\n",
      "Gathering meta feature from 'knn_128'...\n",
      "Gathering meta feature from 'knn_256'...\n"
     ]
    }
   ],
   "source": [
    "# Make fresh Stacker instance\n",
    "base_learners_v3_final_mlens = [\n",
    "    \"random_forest_raw\",\n",
    "    \"random_forest_log\",\n",
    "    \"random_forest_poly\",\n",
    "    \"xgboost_raw\",\n",
    "    \"xgboost_base\",\n",
    "    \"xgboost_poly\",\n",
    "    \"xgboost_bag\",\n",
    "    \"logistic_regression_log\",\n",
    "    \"adaboost_base\",\n",
    "    \"extra_trees_base\",\n",
    "    \"knn_16\",\n",
    "    \"knn_32\",\n",
    "    \"knn_64\",\n",
    "    \"knn_128\",\n",
    "    \"knn_256\"\n",
    "]\n",
    "\n",
    "stacker_v3_final_mlens = Stacker(base_learners_v3_final_mlens, None, y_train, test_ids)\n",
    "train_final_v3_mlens, test_final_v3_mlens = stacker_v3_final_mlens.get_meta_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initial xgb parameters\n",
    "xgb_mlens_params = {\n",
    "    \"learning_rate\": 0.09,\n",
    "    \"n_estimators\": 46,\n",
    "    \"max_depth\": 3,\n",
    "    \"min_child_weight\": 7,\n",
    "    \"gamma\": 0,\n",
    "    \"subsample\": 0.685,\n",
    "    \"colsample_bytree\": 0.68,\n",
    "    \"objective\": 'binary:logistic', # Used for classifier XGB\n",
    "    \"seed\": seed\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.734047+0.0127341\ttest-auc:0.722934+0.0145375\n",
      "[1]\ttrain-auc:0.759262+0.00557842\ttest-auc:0.745818+0.0298525\n",
      "[2]\ttrain-auc:0.766799+0.00872291\ttest-auc:0.75358+0.0225906\n",
      "[3]\ttrain-auc:0.770167+0.00725838\ttest-auc:0.755784+0.0251559\n",
      "[4]\ttrain-auc:0.774741+0.00806723\ttest-auc:0.760688+0.0232365\n",
      "[5]\ttrain-auc:0.77746+0.00531645\ttest-auc:0.762361+0.0252231\n",
      "[6]\ttrain-auc:0.778588+0.00519758\ttest-auc:0.764443+0.0247424\n",
      "[7]\ttrain-auc:0.780294+0.00529331\ttest-auc:0.76453+0.0266961\n",
      "[8]\ttrain-auc:0.780943+0.00465434\ttest-auc:0.765124+0.0261509\n",
      "[9]\ttrain-auc:0.782127+0.00548183\ttest-auc:0.76557+0.0257302\n",
      "[10]\ttrain-auc:0.78381+0.00452858\ttest-auc:0.766914+0.0252983\n",
      "[11]\ttrain-auc:0.78469+0.00497257\ttest-auc:0.768047+0.0256788\n",
      "[12]\ttrain-auc:0.785586+0.00441534\ttest-auc:0.768733+0.0234927\n",
      "[13]\ttrain-auc:0.786189+0.00470209\ttest-auc:0.769019+0.0227549\n",
      "[14]\ttrain-auc:0.788019+0.00507137\ttest-auc:0.768712+0.023922\n",
      "[15]\ttrain-auc:0.788817+0.00450152\ttest-auc:0.768992+0.0239482\n",
      "[16]\ttrain-auc:0.789639+0.00458896\ttest-auc:0.769497+0.0237361\n",
      "[17]\ttrain-auc:0.791057+0.00454988\ttest-auc:0.76934+0.0237771\n",
      "[18]\ttrain-auc:0.791947+0.00445384\ttest-auc:0.76965+0.0242878\n",
      "[19]\ttrain-auc:0.79321+0.00464369\ttest-auc:0.7693+0.0236525\n",
      "[20]\ttrain-auc:0.794269+0.00447376\ttest-auc:0.770046+0.0240863\n",
      "[21]\ttrain-auc:0.794671+0.00431485\ttest-auc:0.770348+0.0241604\n",
      "[22]\ttrain-auc:0.795867+0.00379736\ttest-auc:0.771462+0.0237229\n",
      "[23]\ttrain-auc:0.796548+0.00336997\ttest-auc:0.771316+0.023929\n",
      "[24]\ttrain-auc:0.797604+0.00349551\ttest-auc:0.770479+0.0244051\n",
      "[25]\ttrain-auc:0.798664+0.00374859\ttest-auc:0.771147+0.0246057\n",
      "[26]\ttrain-auc:0.79978+0.00388183\ttest-auc:0.772153+0.0244222\n",
      "[27]\ttrain-auc:0.80126+0.0057052\ttest-auc:0.771613+0.0247726\n",
      "[28]\ttrain-auc:0.802826+0.00575567\ttest-auc:0.771633+0.0250132\n",
      "[29]\ttrain-auc:0.804077+0.00539131\ttest-auc:0.771967+0.0250803\n",
      "[30]\ttrain-auc:0.804761+0.00504822\ttest-auc:0.772626+0.0241094\n",
      "[31]\ttrain-auc:0.80576+0.00442326\ttest-auc:0.773896+0.0243105\n",
      "[32]\ttrain-auc:0.806619+0.00425081\ttest-auc:0.773951+0.0242695\n",
      "[33]\ttrain-auc:0.807442+0.00426949\ttest-auc:0.774132+0.0245663\n",
      "[34]\ttrain-auc:0.808502+0.00436284\ttest-auc:0.775189+0.0241964\n",
      "[35]\ttrain-auc:0.809366+0.0041703\ttest-auc:0.774588+0.0238389\n",
      "[36]\ttrain-auc:0.809879+0.00398316\ttest-auc:0.774466+0.0236958\n",
      "[37]\ttrain-auc:0.811183+0.00410796\ttest-auc:0.774401+0.0235351\n",
      "[38]\ttrain-auc:0.812108+0.00340589\ttest-auc:0.774342+0.023051\n",
      "[39]\ttrain-auc:0.813167+0.00325429\ttest-auc:0.774451+0.0235561\n",
      "[40]\ttrain-auc:0.814413+0.00399799\ttest-auc:0.773342+0.0249021\n",
      "[41]\ttrain-auc:0.816142+0.00435716\ttest-auc:0.773728+0.0252824\n",
      "[42]\ttrain-auc:0.816739+0.00459812\ttest-auc:0.773962+0.0250588\n",
      "[43]\ttrain-auc:0.817223+0.00419883\ttest-auc:0.774165+0.02454\n",
      "[44]\ttrain-auc:0.817997+0.00460966\ttest-auc:0.774692+0.0248404\n",
      "[45]\ttrain-auc:0.819449+0.00482557\ttest-auc:0.774919+0.0248191\n",
      "[46]\ttrain-auc:0.820321+0.00496854\ttest-auc:0.775117+0.0248881\n",
      "[47]\ttrain-auc:0.821034+0.00480269\ttest-auc:0.775407+0.0241352\n",
      "[48]\ttrain-auc:0.822074+0.00446524\ttest-auc:0.775237+0.024025\n",
      "[49]\ttrain-auc:0.823209+0.00427415\ttest-auc:0.774751+0.0242761\n",
      "[50]\ttrain-auc:0.82421+0.0044044\ttest-auc:0.774753+0.0238711\n",
      "\n",
      "Model Report\n",
      "Accuracy : 0.946041628517\n",
      "AUC Score (Train): 0.815648709377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/julian/anaconda2/lib/python2.7/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAERCAYAAAB2CKBkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNV3CY44MAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe6c0755190>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train_final_v3_mlens = pd.DataFrame(train_final_v3_mlens, columns=[\"F{}\".format(x) for x in range(1, len(base_learners_v3_final_mlens) + 1)])\n",
    "model_fit(XGBClassifier(**xgb_mlens_params), df_train_final_v3_mlens, df_train_final_v3_mlens.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed:   35.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.68, gamma=0, learning_rate=0.09,\n",
       "       max_delta_step=0, max_depth=3, min_child_weight=7, missing=None,\n",
       "       n_estimators=46, n_jobs=1, nthread=None,\n",
       "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=42, silent=True,\n",
       "       subsample=0.685),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'n_estimators': [30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_mlens_v3 = XGBClassifier(**xgb_mlens_params)\n",
    "\n",
    "xgb_v3_n_est = {\n",
    "    \"n_estimators\": range(30, 60)\n",
    "}\n",
    "\n",
    "gs_xgb_v3_n_est = GridSearchCV(estimator=xgb_mlens_v3, param_grid=xgb_v3_n_est, cv=n_splits, scoring=\"roc_auc\", n_jobs=-1, verbose=1)\n",
    "gs_xgb_v3_n_est.fit(train_final_v3_mlens, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 51}\n",
      "0.773236996023751\n"
     ]
    }
   ],
   "source": [
    "# With all KNN base ests\n",
    "print gs_xgb_v3_n_est.best_params_\n",
    "print gs_xgb_v3_n_est.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 49}\n",
      "0.7770819737125232\n"
     ]
    }
   ],
   "source": [
    "# With n_neighbors = 16, 32, 64, 128, 256\n",
    "print gs_xgb_v3_n_est.best_params_\n",
    "print gs_xgb_v3_n_est.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 46}\n",
      "0.7780699505546435\n"
     ]
    }
   ],
   "source": [
    "# With n_neighbors = 16, 32, 64, 128, 256 (after 1st iteration of tuning)\n",
    "print gs_xgb_v3_n_est.best_params_\n",
    "print gs_xgb_v3_n_est.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 15 candidates, totalling 75 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  75 out of  75 | elapsed:   24.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.68, gamma=0, learning_rate=0.09,\n",
       "       max_delta_step=0, max_depth=3, min_child_weight=7, missing=None,\n",
       "       n_estimators=46, n_jobs=1, nthread=None,\n",
       "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=42, silent=True,\n",
       "       subsample=0.685),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'max_depth': [3, 4, 5], 'min_child_weight': [4, 5, 6, 7, 8]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_v3_md_mcw = {\n",
    "    \"max_depth\": range(3, 6),\n",
    "    \"min_child_weight\": range(4, 9)\n",
    "}\n",
    "\n",
    "gs_xgb_v3_md_mcw = GridSearchCV(estimator=XGBClassifier(**xgb_mlens_params), \n",
    "                                                       param_grid=xgb_v3_md_mcw, \n",
    "                                                       cv=n_splits, \n",
    "                                                       scoring=\"roc_auc\", \n",
    "                                                       n_jobs=-1, \n",
    "                                                       verbose=1)\n",
    "gs_xgb_v3_md_mcw.fit(train_final_v3_mlens, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 4, 'min_child_weight': 4}\n",
      "0.7773744691782225\n"
     ]
    }
   ],
   "source": [
    "print gs_xgb_v3_md_mcw.best_params_\n",
    "print gs_xgb_v3_md_mcw.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 3, 'min_child_weight': 7}\n",
      "0.7781278817683718\n"
     ]
    }
   ],
   "source": [
    "# With n_neighbors = 16, 32, 64, 128, 256 (after 1st iteration of tuning)\n",
    "print gs_xgb_v3_md_mcw.best_params_\n",
    "print gs_xgb_v3_md_mcw.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    8.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.68, gamma=0, learning_rate=0.09,\n",
       "       max_delta_step=0, max_depth=3, min_child_weight=7, missing=None,\n",
       "       n_estimators=46, n_jobs=1, nthread=None,\n",
       "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=42, silent=True,\n",
       "       subsample=0.685),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'gamma': [0, 0.001, 0.002, 0.003, 0.004, 0.005]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_v3_gamma = {\n",
    "    \"gamma\": [0, 0.001, 0.002, 0.003, 0.004, 0.005]\n",
    "}\n",
    "\n",
    "gs_xgb_v3_gamma = GridSearchCV(estimator=XGBClassifier(**xgb_mlens_params), \n",
    "                                                       param_grid=xgb_v3_gamma, \n",
    "                                                       cv=n_splits, \n",
    "                                                       scoring=\"roc_auc\", \n",
    "                                                       n_jobs=-1, \n",
    "                                                       verbose=1)\n",
    "gs_xgb_v3_gamma.fit(train_final_v3_mlens, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gamma': 0}\n",
      "0.7770819737125232\n"
     ]
    }
   ],
   "source": [
    "print gs_xgb_v3_gamma.best_params_\n",
    "print gs_xgb_v3_gamma.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gamma': 0}\n",
      "0.7781278817683718\n"
     ]
    }
   ],
   "source": [
    "# With n_neighbors = 16, 32, 64, 128, 256 (after 1st iteration of tuning)\n",
    "print gs_xgb_v3_gamma.best_params_\n",
    "print gs_xgb_v3_gamma.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 405 out of 405 | elapsed:  1.8min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.68, gamma=0, learning_rate=0.09,\n",
       "       max_delta_step=0, max_depth=3, min_child_weight=7, missing=None,\n",
       "       n_estimators=46, n_jobs=1, nthread=None,\n",
       "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=42, silent=True,\n",
       "       subsample=0.685),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'subsample': [0.68, 0.685, 0.69, 0.695, 0.7, 0.705, 0.71, 0.715, 0.72], 'colsample_bytree': [0.68, 0.685, 0.69, 0.695, 0.7, 0.705, 0.71, 0.715, 0.72]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_v3_ss_cb = {\n",
    "    \"subsample\": [0.68, 0.685, 0.69, 0.695, 0.7, 0.705, 0.71, 0.715, 0.72],\n",
    "    \"colsample_bytree\": [0.68, 0.685, 0.69, 0.695, 0.7, 0.705, 0.71, 0.715, 0.72]\n",
    "}\n",
    "\n",
    "gs_xgb_v3_ss_cb = GridSearchCV(estimator=XGBClassifier(**xgb_mlens_params), \n",
    "                                                       param_grid=xgb_v3_ss_cb, \n",
    "                                                       cv=n_splits, \n",
    "                                                       scoring=\"roc_auc\", \n",
    "                                                       n_jobs=-1, \n",
    "                                                       verbose=1)\n",
    "gs_xgb_v3_ss_cb.fit(train_final_v3_mlens, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subsample': 0.685, 'colsample_bytree': 0.68}\n",
      "0.7776488976761237\n"
     ]
    }
   ],
   "source": [
    "print gs_xgb_v3_ss_cb.best_params_\n",
    "print gs_xgb_v3_ss_cb.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subsample': 0.685, 'colsample_bytree': 0.68}\n",
      "0.7781278817683718\n"
     ]
    }
   ],
   "source": [
    "# With n_neighbors = 16, 32, 64, 128, 256 (after 1st iteration of tuning)\n",
    "print gs_xgb_v3_ss_cb.best_params_\n",
    "print gs_xgb_v3_ss_cb.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  40 out of  40 | elapsed:    9.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.68, gamma=0, learning_rate=0.09,\n",
       "       max_delta_step=0, max_depth=3, min_child_weight=7, missing=None,\n",
       "       n_estimators=46, n_jobs=1, nthread=None,\n",
       "       objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=42, silent=True,\n",
       "       subsample=0.685),\n",
       "       fit_params=None, iid=True, n_jobs=-1,\n",
       "       param_grid={'learning_rate': [0.085, 0.09, 0.095, 0.1, 0.105, 0.11, 0.115, 0.12]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_v3_learning_rate = {\n",
    "    \"learning_rate\": [0.085, 0.09, 0.095, 0.1, 0.105, 0.11, 0.115, 0.12]\n",
    "}\n",
    "\n",
    "gs_xgb_v3_learning_rate = GridSearchCV(estimator=XGBClassifier(**xgb_mlens_params), \n",
    "                                                       param_grid=xgb_v3_learning_rate, \n",
    "                                                       cv=n_splits, \n",
    "                                                       scoring=\"roc_auc\", \n",
    "                                                       n_jobs=-1, \n",
    "                                                       verbose=1)\n",
    "gs_xgb_v3_learning_rate.fit(train_final_v3_mlens, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.09}\n",
      "0.7777948582010761\n"
     ]
    }
   ],
   "source": [
    "print gs_xgb_v3_learning_rate.best_params_\n",
    "print gs_xgb_v3_learning_rate.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.09}\n",
      "0.7781278817683718\n"
     ]
    }
   ],
   "source": [
    "# With n_neighbors = 16, 32, 64, 128, 256 (after 1st iteration of tuning)\n",
    "print gs_xgb_v3_learning_rate.best_params_\n",
    "print gs_xgb_v3_learning_rate.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_meta_mlens_v3 = RandomForestClassifier(n_jobs=-1, n_estimators=300, max_depth=8, max_features=2)\n",
    "xgb_meta_mlens_v3 = XGBClassifier(**xgb_mlens_params)\n",
    "\n",
    "mlens_base_learners_v3 = [\n",
    "    RandomForestClassifier(criterion='entropy', max_depth=10, n_estimators=1000, n_jobs=-1),\n",
    "    LogisticRegression(C=100, tol=1e-05, solver=\"liblinear\"),\n",
    "    ExtraTreesClassifier(max_depth=12, n_estimators=250, n_jobs=-1, criterion=\"entropy\"),\n",
    "    AdaBoostClassifier(n_estimators=395, learning_rate=1.55),\n",
    "    XGBClassifier(learning_rate=0.1,\n",
    "                    n_estimators=345,\n",
    "                    max_depth=8,\n",
    "                    min_child_weight=2,\n",
    "                    gamma=0.2,\n",
    "                    subsample=0.6,\n",
    "                    colsample_bytree=0.5,\n",
    "                    objective=\"binary:logistic\",\n",
    "                    n_jobs=-1,\n",
    "                    scale_pos_weight=1,\n",
    "                    seed=seed),\n",
    "    BaggingClassifier(base_estimator=XGBClassifier(learning_rate=0.1,\n",
    "                                                    n_estimators=345,\n",
    "                                                    max_depth=8,\n",
    "                                                    min_child_weight=2,\n",
    "                                                    gamma=0.2,\n",
    "                                                    subsample=0.6,\n",
    "                                                    colsample_bytree=0.5,\n",
    "                                                    objective=\"binary:logistic\",\n",
    "                                                    n_jobs=-1,\n",
    "                                                    scale_pos_weight=1,\n",
    "                                                    seed=seed), \n",
    "                      n_estimators=50, max_samples=0.7, max_features=0.75, bootstrap_features=True)\n",
    "]\n",
    "\n",
    "ensemble_v3 = SuperLearner(random_state=seed, scorer=roc_auc_score)\n",
    "ensemble_v3.add(mlens_base_learners_v3, proba=True)\n",
    "# ensemble_v3.add_meta(rf_meta_mlens_v3, proba=True)\n",
    "ensemble_v3.add_meta(xgb_meta_mlens_v3, proba=True)\n",
    "mlens_v3_preds_knn = ensemble_v3.fit(meta_features_train_v3, y_train).predict_proba(meta_features_test_v3)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9761619  0.70373476 0.9570611  ... 0.93645567 0.98507524 0.9569393 ]\n"
     ]
    }
   ],
   "source": [
    "print mlens_v3_preds_knn\n",
    "save_preds(mlens_v3_preds_knn, \"mlens_v3_with_knn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9754563  0.68639696 0.949029   ... 0.92335254 0.9772997  0.9586274 ]\n"
     ]
    }
   ],
   "source": [
    "print mlens_v3_preds_knn\n",
    "save_preds(mlens_v3_preds_knn, \"mlens_v3_with_knn_16_32_64_128_256\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9707168  0.7537478  0.9387455  ... 0.9111801  0.97642946 0.95039713]\n"
     ]
    }
   ],
   "source": [
    "base_learners_v3 = [\n",
    "    \"random_forest_raw\",\n",
    "    \"xgboost_reduced\",\n",
    "    \"xgboost_raw\",\n",
    "    \"xgboost_base\",\n",
    "    \"xgboost_poly\",\n",
    "    \"xgboost_bag\",\n",
    "    \"logistic_regression_log\",\n",
    "    \"adaboost_base\",\n",
    "    \"extra_trees_base\"\n",
    "]\n",
    "\n",
    "print mlens_v3_preds_knn\n",
    "save_preds(mlens_v3_preds_knn, \"mlens_{}\".format(\"_\".join(base_learners_v3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
