{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking\n",
    "\n",
    "Julian Domingo - jad5348"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[MLENS] backend: threading\n"
     ]
    }
   ],
   "source": [
    "# Data analysis \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Modeling stuff\n",
    "from xgboost import XGBClassifier\n",
    "from mlens.ensemble import SuperLearner\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import (RandomForestClassifier, \n",
    "                              AdaBoostClassifier,\n",
    "                              ExtraTreesClassifier)\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "\n",
    "# For reproducibility\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Constants\n",
    "n_splits = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_ids = pd.read_csv(\"./data/raw/test.csv\")[[\"id\"]]\n",
    "y_train = pd.read_csv(\"./data/raw/train.csv\")[\"Y\"].ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_preds(preds, preds_filename):\n",
    "    submission = pd.DataFrame({\"id\": test_ids.id, \"Y\": preds})\n",
    "    submission.to_csv(\"./submissions/stacking_{}.csv\".format(preds_filename), index=False, columns=[\"id\", \"Y\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stacking Class\n",
    "\n",
    "Stacking works well for small to medium-sized data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Stacker(object):\n",
    "    def __init__(self, base_learners, meta_learners, y_train, test_ids):\n",
    "        self.base_learners = base_learners\n",
    "        self.meta_learners = meta_learners\n",
    "        self.y_train = y_train\n",
    "        self.test_ids = test_ids\n",
    "        \n",
    "        \n",
    "    def get_indiv_meta_preds(self, meta):\n",
    "        \"\"\" Retrieves the predictions of the model 'meta'. \"\"\"\n",
    "        if self.meta_features_train is None or self.meta_features_test is None:\n",
    "            raise ValueError(\"Invoke 'get_meta_features' before predicting.\")\n",
    "            \n",
    "        meta.fit(self.meta_features_train, self.y_train)\n",
    "        meta_preds = meta.predict_proba(self.meta_features_test)[:,1]\n",
    "        return meta_preds\n",
    "        \n",
    "        \n",
    "    def get_meta_features(self):\n",
    "        \"\"\" Retrieves all meta features for the train & test data from the base learners specified. \"\"\"\n",
    "        self.meta_features_train = np.zeros((len(self.y_train), len(self.base_learners)))\n",
    "        self.meta_features_test = np.zeros((len(self.test_ids), len(self.base_learners)))\n",
    "        \n",
    "        for i, base in enumerate(self.base_learners):\n",
    "            print (\"Gathering meta feature from '{}'...\".format(base))\n",
    "            self.meta_features_train[:, i] = pd.read_csv(\"./meta_features/train/train_{}.csv\".format(base), \\\n",
    "                                                         index_col=0).as_matrix().ravel()\n",
    "            self.meta_features_test[:, i] = pd.read_csv(\"./meta_features/test/test_{}.csv\".format(base), \\\n",
    "                                                        index_col=0).as_matrix().ravel()\n",
    "            \n",
    "        return self.meta_features_train.copy(), self.meta_features_test.copy()\n",
    "    \n",
    "    \n",
    "    def fit_meta_learners_and_predict(self):\n",
    "        \"\"\" Generates predictions using all meta features generated from the base learners for each meta learner. \"\"\"\n",
    "        if not self.meta_features_train or self.meta_features_test:\n",
    "            raise ValueError(\"get_meta_features() should be called before generate_out_of_folds_preds.\")\n",
    "        \n",
    "        self.meta_learner_preds = np.zeros(len(self.test_ids), len(self.meta_learners))\n",
    "        \n",
    "        for i, meta in enumerate(meta_learners):\n",
    "            meta.fit(self.meta_features_train, self.y_train)\n",
    "            self.meta_learner_preds[:, i] =  meta.predict_proba(self.meta_features_test)[:,1]\n",
    "            \n",
    "    \n",
    "    def get_df_meta_learner_preds(self):\n",
    "        if self.meta_learner_preds is None:\n",
    "            raise ValueError(\"No predictions were found. Invoke 'fit_meta_learners_and_predict' first.\")\n",
    "        \n",
    "        if self.base_learners is None:\n",
    "            raise ValueError(\"No base learners were specified. Construct an instance with base learners.\")\n",
    "        \n",
    "        return pd.DataFrame(self.meta_learner_preds, columns=self.base_learners)\n",
    "    \n",
    "    \n",
    "    def get_final_preds(self):\n",
    "        return np.mean(self.meta_learner_preds, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta Learner(s) Parameter Tuning & Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble 1\n",
    "**Base Learners: **\n",
    "    * RF Raw\n",
    "    * RF Log\n",
    "    * RF Poly\n",
    "    * XGB Raw\n",
    "    * XGB Base\n",
    "    * XGB Poly\n",
    "    * LR Log\n",
    "    * Ada Base\n",
    "   \n",
    "**Meta Learners: **\n",
    "    * RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_learners_v1 = [\n",
    "    \"random_forest_raw\",\n",
    "    \"random_forest_log\",\n",
    "    \"random_forest_poly\",\n",
    "    \"xgboost_raw\",\n",
    "    \"xgboost_base\",\n",
    "    \"xgboost_poly\",\n",
    "    \"logistic_regression_log\",\n",
    "    \"adaboost_base\"\n",
    "]\n",
    "\n",
    "rf_meta_v1 = RandomForestClassifier(n_jobs=-1)\n",
    "\n",
    "meta_learners_v1 = [rf_meta_v1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gathering meta feature from 'random_forest_raw'...\n",
      "Gathering meta feature from 'random_forest_log'...\n",
      "Gathering meta feature from 'random_forest_poly'...\n",
      "Gathering meta feature from 'xgboost_raw'...\n",
      "Gathering meta feature from 'xgboost_base'...\n",
      "Gathering meta feature from 'xgboost_poly'...\n",
      "Gathering meta feature from 'logistic_regression_log'...\n",
      "Gathering meta feature from 'adaboost_base'...\n"
     ]
    }
   ],
   "source": [
    "stacker_v1 = Stacker(base_learners_v1, meta_learners_v1, y_train, test_ids)\n",
    "meta_features_train_v1, meta_features_test_v1 = stacker_v1.get_meta_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=-1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'max_features': [5, 6, 7], 'n_estimators': [300, 400, 500, 600, 700, 800, 900, 1000], 'max_depth': [5, 6, 7, 8, 9, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Warning: this block takes a long time to execute.\n",
    "rf_meta_v1_param_grid = {\n",
    "    \"max_features\": range(5, 7 + 1),\n",
    "    \"max_depth\": range(5, 10 + 1),\n",
    "    \"n_estimators\": range(300, 1000 + 1, 100) \n",
    "}\n",
    "\n",
    "gs_rf_v1 = GridSearchCV(estimator=rf_meta_v1, param_grid=rf_meta_v1_param_grid, cv=n_splits, scoring=\"roc_auc\", n_jobs=-1)\n",
    "gs_rf_v1.fit(meta_features_train_v1, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_features': 6, 'n_estimators': 300, 'max_depth': 6}\n",
      "0.772539082175\n"
     ]
    }
   ],
   "source": [
    "print gs_rf_v1.best_params_\n",
    "print gs_rf_v1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.97136003  0.67447269  0.94252603 ...,  0.88289829  0.98178302\n",
      "  0.96819782]\n"
     ]
    }
   ],
   "source": [
    "# Get predictions w/ tuned params\n",
    "meta_preds_v1 = stacker_v1.get_indiv_meta_preds(RandomForestClassifier(n_jobs=-1, n_estimators=300, max_features=6, max_depth=6))\n",
    "print meta_preds_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_preds(meta_preds_rf_v1, \"_\".join(base_learners_v1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Ensemble 2\n",
    "**Base Learners: **\n",
    "    * RF Raw\n",
    "    * RF Log\n",
    "    * RF Poly\n",
    "    * XGB Raw\n",
    "    * XGB Base\n",
    "    * XGB Poly\n",
    "    * LR Log\n",
    "    * Ada Base\n",
    "    * KNN_{2, 4, 8, 16, 32, 64, 128, 256, 512, 1024}\n",
    "   \n",
    "**Meta Learners: **\n",
    "    * RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_learners_v2 = [\n",
    "    \"random_forest_raw\",\n",
    "    \"random_forest_log\",\n",
    "    \"random_forest_poly\",\n",
    "    \"xgboost_raw\",\n",
    "    \"xgboost_base\",\n",
    "    \"xgboost_poly\",\n",
    "    \"logistic_regression_log\",\n",
    "    \"adaboost_base\",\n",
    "    \"knn_2\",\n",
    "    \"knn_4\",\n",
    "    \"knn_8\",\n",
    "    \"knn_16\",\n",
    "    \"knn_32\",\n",
    "    \"knn_64\",\n",
    "    \"knn_128\",\n",
    "    \"knn_256\",\n",
    "    \"knn_512\",\n",
    "    \"knn_1024\"\n",
    "]\n",
    "\n",
    "rf_meta_v2 = RandomForestClassifier(n_jobs=-1)\n",
    "meta_learners_v2 = [rf_meta_v2]\n",
    "\n",
    "stacker_v2 = Stacker(base_learners_v2, meta_learners_v2, y_train, test_ids)\n",
    "meta_features_train_v2, meta_features_test_v2 = stacker_v2.get_meta_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Test different variety of base learners for stacking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML-ensemble Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# v1\n",
    "rf_meta_mlens_v1 = RandomForestClassifier(n_jobs=-1, n_estimators=300, max_depth=6)\n",
    "\n",
    "mlens_base_learners = [\n",
    "    RandomForestClassifier(criterion='entropy', max_depth=10, n_estimators=1000, n_jobs=-1),\n",
    "    LogisticRegression(C=100, tol=1e-05, solver=\"liblinear\"),\n",
    "    ExtraTreesClassifier(max_depth=12, n_estimators=250, n_jobs=-1, criterion=\"entropy\"),\n",
    "    AdaBoostClassifier(n_estimators=395, learning_rate=1.55),\n",
    "    XGBClassifier(learning_rate=0.1,\n",
    "                    n_estimators=345,\n",
    "                    max_depth=8,\n",
    "                    min_child_weight=2,\n",
    "                    gamma=0.2,\n",
    "                    subsample=0.6,\n",
    "                    colsample_bytree=0.5,\n",
    "                    objective=\"binary:logistic\",\n",
    "                    n_jobs=-1,\n",
    "                    scale_pos_weight=1,\n",
    "                    seed=seed)\n",
    "]\n",
    "\n",
    "ensemble = SuperLearner(random_state=seed, scorer=roc_auc_score)\n",
    "ensemble.add(mlens_base_learners, proba=True)\n",
    "ensemble.add_meta(rf_meta_mlens_v1, proba=True)\n",
    "mlens_v1_preds = ensemble.fit(meta_features_train_v1, y_train).predict_proba(meta_features_test_v1)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.96494621  0.70450526  0.95294267 ...,  0.89949614  0.9846648\n",
      "  0.96006691]\n"
     ]
    }
   ],
   "source": [
    "print mlens_v1_preds\n",
    "save_preds(mlens_v1_preds, \"mlens_v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
