{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking\n",
    "\n",
    "Julian Domingo - jad5348"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data analysis \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Modeling stuff\n",
    "from xgboost import XGBClassifier\n",
    "from mlens.ensemble import SuperLearner\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import (RandomForestClassifier, \n",
    "                              AdaBoostClassifier,\n",
    "                              ExtraTreesClassifier,\n",
    "                              BaggingClassifier)\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "\n",
    "# Computation / numerical\n",
    "from scipy.stats import uniform, randint\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from mlens.preprocessing import Subset\n",
    "from mlens.metrics import make_scorer\n",
    "from mlens.model_selection import Evaluator\n",
    "\n",
    "# For reproducibility\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Constants\n",
    "n_splits = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_ids = pd.read_csv(\"./data/raw/test.csv\")[[\"id\"]]\n",
    "y_train = pd.read_csv(\"./data/raw/train.csv\")[\"Y\"].ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_preds(preds, preds_filename):\n",
    "    submission = pd.DataFrame({\"id\": test_ids.id, \"Y\": preds})\n",
    "    submission.to_csv(\"./submissions/stacking_{}.csv\".format(preds_filename), index=False, columns=[\"id\", \"Y\"])\n",
    "    \n",
    "    \n",
    "def get_data(filename):\n",
    "    train = pd.read_csv(\"./data/refined/train/train_{}.csv\".format(filename))\n",
    "    test = pd.read_csv(\"./data/refined/test/test_{}.csv\".format(filename))\n",
    "    \n",
    "    x_train = train.drop([\"Y\"], axis = 1)\n",
    "    y_train = train[\"Y\"]\n",
    "    \n",
    "    return train, test, x_train, y_train\n",
    "\n",
    "\n",
    "def get_cross_val_score(model, x_train, y_train, n_folds, run_parallel=True):\n",
    "    if run_parallel:\n",
    "        cv = cross_val_score(model, x_train, y_train, cv = n_folds, scoring = \"roc_auc\", n_jobs = -1)\n",
    "    else:\n",
    "        cv = cross_val_score(model, x_train, y_train, cv = n_folds, scoring = \"roc_auc\")\n",
    "\n",
    "    print(\"Cross validation score: {} +/- {}\\nRaw scores: {}\".format(str(np.mean(cv)), str(np.std(cv)), str(cv)))\n",
    "    return cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_raw, test_raw, x_train_raw, y_train_raw = get_data(\"raw\")\n",
    "train_base, test_base, x_train_base, y_train_base = get_data(\"base\")\n",
    "train_log, test_log, x_train_log, y_train_log = get_data(\"log\")\n",
    "train_poly, test_poly, x_train_poly, y_train_poly = get_data(\"poly\")\n",
    "train_scaled, test_scaled, x_train_scaled, y_train_scaled = get_data(\"scaled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stacking Class\n",
    "\n",
    "Stacking works well for small to medium-sized data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Stacker(object):\n",
    "    def __init__(self, base_learners, meta_learners, y_train, test_ids):\n",
    "        self.base_learners = base_learners\n",
    "        self.meta_learners = meta_learners\n",
    "        self.y_train = y_train\n",
    "        self.test_ids = test_ids\n",
    "    \n",
    "    \n",
    "    def get_indiv_meta_preds(self, meta):\n",
    "        \"\"\" Retrieves the predictions of the model 'meta'. \"\"\"\n",
    "        if self.meta_features_train is None or self.meta_features_test is None:\n",
    "            raise ValueError(\"Invoke 'get_meta_features' before predicting.\")\n",
    "            \n",
    "        meta.fit(self.meta_features_train, self.y_train)\n",
    "        meta_preds = meta.predict_proba(self.meta_features_test)[:,1]\n",
    "        return meta_preds\n",
    "        \n",
    "        \n",
    "    def get_meta_features(self):\n",
    "        \"\"\" Retrieves all meta features for the train & test data from the base learners specified. \"\"\"\n",
    "        self.meta_features_train = np.zeros((len(self.y_train), len(self.base_learners)))\n",
    "        self.meta_features_test = np.zeros((len(self.test_ids), len(self.base_learners)))\n",
    "        \n",
    "        for i, base in enumerate(self.base_learners):\n",
    "            print (\"Gathering meta feature from '{}'...\".format(base))\n",
    "            self.meta_features_train[:, i] = pd.read_csv(\"./meta_features/train/train_{}.csv\".format(base), \\\n",
    "                                                         index_col=0).as_matrix().ravel()\n",
    "            self.meta_features_test[:, i] = pd.read_csv(\"./meta_features/test/test_{}.csv\".format(base), \\\n",
    "                                                        index_col=0).as_matrix().ravel()\n",
    "            \n",
    "        return self.meta_features_train.copy(), self.meta_features_test.copy()\n",
    "    \n",
    "    \n",
    "    def fit_meta_learners_and_predict(self):\n",
    "        \"\"\" Generates predictions using all meta features generated from the base learners for each meta learner. \"\"\"\n",
    "        if not self.meta_features_train or self.meta_features_test:\n",
    "            raise ValueError(\"get_meta_features() should be called before generate_out_of_folds_preds.\")\n",
    "        \n",
    "        self.meta_learner_preds = np.zeros(len(self.test_ids), len(self.meta_learners))\n",
    "        \n",
    "        for i, meta in enumerate(meta_learners):\n",
    "            meta.fit(self.meta_features_train, self.y_train)\n",
    "            self.meta_learner_preds[:, i] =  meta.predict_proba(self.meta_features_test)[:,1]\n",
    "            \n",
    "    \n",
    "    def get_df_meta_learner_preds(self):\n",
    "        if self.meta_learner_preds is None:\n",
    "            raise ValueError(\"No predictions were found. Invoke 'fit_meta_learners_and_predict' first.\")\n",
    "        \n",
    "        if self.base_learners is None:\n",
    "            raise ValueError(\"No base learners were specified. Construct an instance with base learners.\")\n",
    "        \n",
    "        return pd.DataFrame(self.meta_learner_preds, columns=self.base_learners)\n",
    "    \n",
    "    \n",
    "    def get_final_preds(self):\n",
    "        return np.mean(self.meta_learner_preds, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta Learner(s) Parameter Tuning & Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble 1\n",
    "**Base Learners: **\n",
    "    * RF Raw\n",
    "    * RF Log\n",
    "    * RF Poly\n",
    "    * XGB Raw\n",
    "    * XGB Base\n",
    "    * XGB Poly\n",
    "    * LR Log\n",
    "    * Ada Base\n",
    "   \n",
    "**Meta Learners: **\n",
    "    * RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_learners_v1 = [\n",
    "    \"random_forest_raw\",\n",
    "    \"random_forest_log\",\n",
    "    \"random_forest_poly\",\n",
    "    \"xgboost_raw\",\n",
    "    \"xgboost_base\",\n",
    "    \"xgboost_poly\",\n",
    "    \"logistic_regression_log\",\n",
    "    \"adaboost_base\"\n",
    "]\n",
    "\n",
    "rf_meta_v1 = RandomForestClassifier(n_jobs=-1)\n",
    "\n",
    "meta_learners_v1 = [rf_meta_v1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gathering meta feature from 'random_forest_raw'...\n",
      "Gathering meta feature from 'random_forest_log'...\n",
      "Gathering meta feature from 'random_forest_poly'...\n",
      "Gathering meta feature from 'xgboost_raw'...\n",
      "Gathering meta feature from 'xgboost_base'...\n",
      "Gathering meta feature from 'xgboost_poly'...\n",
      "Gathering meta feature from 'logistic_regression_log'...\n",
      "Gathering meta feature from 'adaboost_base'...\n"
     ]
    }
   ],
   "source": [
    "stacker_v1 = Stacker(base_learners_v1, meta_learners_v1, y_train, test_ids)\n",
    "meta_features_train_v1, meta_features_test_v1 = stacker_v1.get_meta_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=-1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'max_features': [5, 6, 7], 'n_estimators': [300, 400, 500, 600, 700, 800, 900, 1000], 'max_depth': [5, 6, 7, 8, 9, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Warning: this block takes a long time to execute.\n",
    "rf_meta_v1_param_grid = {\n",
    "    \"max_features\": range(5, 7 + 1),\n",
    "    \"max_depth\": range(5, 10 + 1),\n",
    "    \"n_estimators\": range(300, 1000 + 1, 100) \n",
    "}\n",
    "\n",
    "gs_rf_v1 = GridSearchCV(estimator=rf_meta_v1, param_grid=rf_meta_v1_param_grid, cv=n_splits, scoring=\"roc_auc\", n_jobs=-1)\n",
    "gs_rf_v1.fit(meta_features_train_v1, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_features': 6, 'n_estimators': 300, 'max_depth': 6}\n",
      "0.772539082175\n"
     ]
    }
   ],
   "source": [
    "print gs_rf_v1.best_params_\n",
    "print gs_rf_v1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation score: 0.771359868469 +/- 0.00723717612684\n",
      "Raw scores: [ 0.76715711  0.77956341  0.75947714  0.77377431  0.77682737]\n",
      "[ 0.76715711  0.77956341  0.75947714  0.77377431  0.77682737]\n"
     ]
    }
   ],
   "source": [
    "print get_cross_val_score(RandomForestClassifier(n_jobs=-1, n_estimators=300, max_depth=6, max_features=6), meta_features_train_v1, y_train, n_folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.97136003  0.67447269  0.94252603 ...,  0.88289829  0.98178302\n",
      "  0.96819782]\n"
     ]
    }
   ],
   "source": [
    "# Get predictions w/ tuned params\n",
    "meta_preds_v1 = stacker_v1.get_indiv_meta_preds(RandomForestClassifier(n_jobs=-1, n_estimators=300, max_features=6, max_depth=6))\n",
    "print meta_preds_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.   0.7  0.9 ...,  1.   1.   1. ]\n"
     ]
    }
   ],
   "source": [
    "# Get predictions w/o tuned params\n",
    "meta_preds_v1_untuned = stacker_v1.get_indiv_meta_preds(RandomForestClassifier(n_jobs=-1))\n",
    "print meta_preds_v1_untuned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen by the predictions without tuned parameters, tuning of the meta model makes a tremendous difference on the prediction set obtained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Ensemble 2\n",
    "**Base Learners: **\n",
    "    * RF Raw\n",
    "    * RF Log\n",
    "    * RF Poly\n",
    "    * XGB Raw\n",
    "    * XGB Base\n",
    "    * XGB Poly\n",
    "    * LR Log\n",
    "    * Ada Base\n",
    "    * KNN_{2, 4, 8, 16, 32, 64, 128, 256, 512, 1024}\n",
    "   \n",
    "**Meta Learners: **\n",
    "    * RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gathering meta feature from 'random_forest_raw'...\n",
      "Gathering meta feature from 'random_forest_log'...\n",
      "Gathering meta feature from 'random_forest_poly'...\n",
      "Gathering meta feature from 'xgboost_raw'...\n",
      "Gathering meta feature from 'xgboost_base'...\n",
      "Gathering meta feature from 'xgboost_poly'...\n",
      "Gathering meta feature from 'logistic_regression_log'...\n",
      "Gathering meta feature from 'adaboost_base'...\n",
      "Gathering meta feature from 'knn_2'...\n",
      "Gathering meta feature from 'knn_4'...\n",
      "Gathering meta feature from 'knn_8'...\n",
      "Gathering meta feature from 'knn_16'...\n",
      "Gathering meta feature from 'knn_32'...\n",
      "Gathering meta feature from 'knn_64'...\n",
      "Gathering meta feature from 'knn_128'...\n",
      "Gathering meta feature from 'knn_256'...\n",
      "Gathering meta feature from 'knn_512'...\n",
      "Gathering meta feature from 'knn_1024'...\n"
     ]
    }
   ],
   "source": [
    "base_learners_v2 = [\n",
    "    \"random_forest_raw\",\n",
    "    \"random_forest_log\",\n",
    "    \"random_forest_poly\",\n",
    "    \"xgboost_raw\",\n",
    "    \"xgboost_base\",\n",
    "    \"xgboost_poly\",\n",
    "    \"logistic_regression_log\",\n",
    "    \"adaboost_base\",\n",
    "    \"knn_2\",\n",
    "    \"knn_4\",\n",
    "    \"knn_8\",\n",
    "    \"knn_16\",\n",
    "    \"knn_32\",\n",
    "    \"knn_64\",\n",
    "    \"knn_128\",\n",
    "    \"knn_256\",\n",
    "    \"knn_512\",\n",
    "    \"knn_1024\"\n",
    "]\n",
    "\n",
    "rf_meta_v2 = RandomForestClassifier(n_jobs=-1)\n",
    "meta_learners_v2 = [rf_meta_v2]\n",
    "\n",
    "stacker_v2 = Stacker(base_learners_v2, meta_learners_v2, y_train, test_ids)\n",
    "meta_features_train_v2, meta_features_test_v2 = stacker_v2.get_meta_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=-1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid={'max_features': [5, 6, 7], 'n_estimators': [300, 400, 500, 600, 700, 800, 900, 1000], 'max_depth': [5, 6, 7, 8, 9, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Warning: this block takes a long time to execute.\n",
    "rf_meta_v2_param_grid = {\n",
    "    \"max_features\": range(5, 7 + 1),\n",
    "    \"max_depth\": range(5, 10 + 1),\n",
    "    \"n_estimators\": range(300, 1000 + 1, 100) \n",
    "}\n",
    "\n",
    "gs_rf_v2 = GridSearchCV(estimator=rf_meta_v2, param_grid=rf_meta_v2_param_grid, cv=n_splits, scoring=\"roc_auc\", n_jobs=-1)\n",
    "gs_rf_v2.fit(meta_features_train_v2, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_features': 5, 'n_estimators': 300, 'max_depth': 9}\n",
      "0.773074767924\n"
     ]
    }
   ],
   "source": [
    "print gs_rf_v2.best_params_\n",
    "print gs_rf_v2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation score: 0.769897637451 +/- 0.00448583181217\n",
      "Raw scores: [ 0.76837689  0.77614972  0.77087385  0.76246286  0.77162487]\n",
      "[ 0.76837689  0.77614972  0.77087385  0.76246286  0.77162487]\n"
     ]
    }
   ],
   "source": [
    "print get_cross_val_score(RandomForestClassifier(n_jobs=-1, n_estimators=300, max_depth=9, max_features=5), meta_features_train_v2, y_train, n_folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.97460188  0.66699757  0.95640802 ...,  0.91079086  0.98644606\n",
      "  0.97122791]\n"
     ]
    }
   ],
   "source": [
    "# Get predictions w/ tuned params\n",
    "meta_preds_v2_tuned = stacker_v2.get_indiv_meta_preds(RandomForestClassifier(n_jobs=-1, n_estimators=300, max_depth=9, max_features=5))\n",
    "print meta_preds_v2_tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_preds(meta_preds_v2_tuned, \"_\".join(base_learners_v2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble 3\n",
    "**Base Learners: **\n",
    "    * RF Raw\n",
    "    * RF Log\n",
    "    * RF Poly\n",
    "    * XGB Raw\n",
    "    * XGB Base\n",
    "    * XGB Poly\n",
    "    * LR Log\n",
    "    * Ada Base\n",
    "    * Bagged XGB (50 runs)\n",
    "    * Extra Trees Base\n",
    "    \n",
    "**Meta Learners: **\n",
    "    * RF\n",
    "    * XGB\n",
    "    \n",
    "**Final Predictions**: harmonic mean of meta learner predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gathering meta feature from 'random_forest_raw'...\n",
      "Gathering meta feature from 'random_forest_log'...\n",
      "Gathering meta feature from 'random_forest_poly'...\n",
      "Gathering meta feature from 'xgboost_raw'...\n",
      "Gathering meta feature from 'xgboost_base'...\n",
      "Gathering meta feature from 'xgboost_poly'...\n",
      "Gathering meta feature from 'xgboost_base'...\n",
      "Gathering meta feature from 'xgboost_bag'...\n",
      "Gathering meta feature from 'logistic_regression_log'...\n",
      "Gathering meta feature from 'adaboost_base'...\n",
      "Gathering meta feature from 'extra_trees_base'...\n"
     ]
    }
   ],
   "source": [
    "base_learners_v3 = [\n",
    "    \"random_forest_raw\",\n",
    "    \"random_forest_log\",\n",
    "    \"random_forest_poly\",\n",
    "    \"xgboost_raw\",\n",
    "    \"xgboost_base\",\n",
    "    \"xgboost_poly\",\n",
    "    \"xgboost_base\",\n",
    "    \"xgboost_bag\",\n",
    "    \"logistic_regression_log\",\n",
    "    \"adaboost_base\",\n",
    "    \"extra_trees_base\"\n",
    "]\n",
    "\n",
    "rf_meta_v3 = RandomForestClassifier(n_jobs=-1, random_state=seed)\n",
    "meta_learners_v3 = [rf_meta_v3]\n",
    "\n",
    "stacker_v3 = Stacker(base_learners_v3, meta_learners_v3, y_train, test_ids)\n",
    "meta_features_train_v3, meta_features_test_v3 = stacker_v3.get_meta_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Warning: this block takes a long time to execute.\n",
    "rf_v3_param_grid = {\n",
    "    \"max_features\": range(2, 10 + 1),\n",
    "    \"max_depth\": range(2, 10 + 1),\n",
    "    \"n_estimators\": range(300, 1000 + 1, 100) \n",
    "}\n",
    "\n",
    "gs_rf_v3 = GridSearchCV(estimator=rf_meta_v3, param_grid=rf_v3_param_grid, cv=n_splits, scoring=\"roc_auc\", n_jobs=-1, verbose=5)\n",
    "gs_rf_v3.fit(meta_features_train_v3, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print gs_rf_v3.best_params_\n",
    "print gs_rf_v3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print get_cross_val_score(RandomForestClassifier(n_jobs=-1, n_estimators=, max_depth=, max_features=),\n",
    "                          meta_features_train_v3,\n",
    "                          y_train,\n",
    "                          n_folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_preds_v3_tuned = stacker_v3.get_indiv_meta_preds(RandomForestClassifier(n_jobs=-1,\n",
    "                                                                             n_estimators=,\n",
    "                                                                             max_depth=,\n",
    "                                                                             max_features=))\n",
    "print meta_preds_v3_tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_preds(meta_preds_v3_tuned, \"_\".join(base_learners_v3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML-ensemble Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_meta_mlens_v1 = RandomForestClassifier(n_jobs=-1, n_estimators=300, max_depth=6)\n",
    "\n",
    "mlens_base_learners = [\n",
    "    RandomForestClassifier(criterion='entropy', max_depth=10, n_estimators=1000, n_jobs=-1),\n",
    "    LogisticRegression(C=100, tol=1e-05, solver=\"liblinear\"),\n",
    "    AdaBoostClassifier(n_estimators=395, learning_rate=1.55),\n",
    "    XGBClassifier(learning_rate=0.1,\n",
    "                    n_estimators=345,\n",
    "                    max_depth=8,\n",
    "                    min_child_weight=2,\n",
    "                    gamma=0.2,\n",
    "                    subsample=0.6,\n",
    "                    colsample_bytree=0.5,\n",
    "                    objective=\"binary:logistic\",\n",
    "                    n_jobs=-1,\n",
    "                    scale_pos_weight=1,\n",
    "                    seed=seed)\n",
    "]\n",
    "\n",
    "ensemble_v1 = SuperLearner(random_state=seed, scorer=roc_auc_score)\n",
    "ensemble_v1.add(mlens_base_learners, proba=True)\n",
    "ensemble_v1.add_meta(rf_meta_mlens_v1, proba=True)\n",
    "mlens_v1_preds = ensemble_v1.fit(meta_features_train_v1, y_train).predict_proba(meta_features_test_v1)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.9640277   0.70394427  0.95102447 ...,  0.89943802  0.98440754\n",
      "  0.95957553]\n"
     ]
    }
   ],
   "source": [
    "print mlens_v1_preds\n",
    "save_preds(mlens_v1_preds, \"mlens_v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_meta_mlens_v2 = RandomForestClassifier(n_jobs=-1, n_estimators=300, max_depth=9, max_features=5)\n",
    "\n",
    "mlens_base_learners = [\n",
    "    RandomForestClassifier(criterion='entropy', max_depth=10, n_estimators=1000, n_jobs=-1),\n",
    "    LogisticRegression(C=100, tol=1e-05, solver=\"liblinear\"),\n",
    "    ExtraTreesClassifier(max_depth=12, n_estimators=250, n_jobs=-1, criterion=\"entropy\"),\n",
    "    AdaBoostClassifier(n_estimators=395, learning_rate=1.55),\n",
    "    XGBClassifier(learning_rate=0.1,\n",
    "                    n_estimators=345,\n",
    "                    max_depth=8,\n",
    "                    min_child_weight=2,\n",
    "                    gamma=0.2,\n",
    "                    subsample=0.6,\n",
    "                    colsample_bytree=0.5,\n",
    "                    objective=\"binary:logistic\",\n",
    "                    n_jobs=-1,\n",
    "                    scale_pos_weight=1,\n",
    "                    seed=seed),\n",
    "    KNeighborsClassifier(n_jobs=-1, n_neighbors=2),\n",
    "    KNeighborsClassifier(n_jobs=-1, n_neighbors=4),\n",
    "    KNeighborsClassifier(n_jobs=-1, n_neighbors=8),\n",
    "    KNeighborsClassifier(n_jobs=-1, n_neighbors=16),\n",
    "    KNeighborsClassifier(n_jobs=-1, n_neighbors=32),\n",
    "    KNeighborsClassifier(n_jobs=-1, n_neighbors=64),\n",
    "    KNeighborsClassifier(n_jobs=-1, n_neighbors=128),\n",
    "    KNeighborsClassifier(n_jobs=-1, n_neighbors=256),\n",
    "    KNeighborsClassifier(n_jobs=-1, n_neighbors=512),\n",
    "    KNeighborsClassifier(n_jobs=-1, n_neighbors=1024)\n",
    "]\n",
    "\n",
    "ensemble_v2 = SuperLearner(random_state=seed, scorer=roc_auc_score)\n",
    "ensemble_v2.add(mlens_base_learners, proba=True)\n",
    "ensemble_v2.add_meta(rf_meta_mlens_v2, proba=True)\n",
    "mlens_v2_preds = ensemble_v2.fit(meta_features_train_v2, y_train).predict_proba(meta_features_test_v2)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.97149235  0.76364833  0.96501911 ...,  0.92276353  0.98632556\n",
      "  0.96678698]\n"
     ]
    }
   ],
   "source": [
    "print mlens_v2_preds\n",
    "save_preds(mlens_v2_preds, \"mlens_v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After looking at the LB scores, it seems adding KNeighborsClassifier models don't improve the stacking ensemble."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_meta_mlens_v3 = RandomForestClassifier(n_jobs=-1, n_estimators=300, max_depth=9, max_features=5)\n",
    "\n",
    "mlens_base_learners_v3 = [\n",
    "    RandomForestClassifier(criterion='entropy', max_depth=10, n_estimators=1000, n_jobs=-1),\n",
    "    LogisticRegression(C=100, tol=1e-05, solver=\"liblinear\"),\n",
    "    ExtraTreesClassifier(max_depth=12, n_estimators=250, n_jobs=-1, criterion=\"entropy\"),\n",
    "    AdaBoostClassifier(n_estimators=395, learning_rate=1.55),\n",
    "    XGBClassifier(learning_rate=0.1,\n",
    "                    n_estimators=345,\n",
    "                    max_depth=8,\n",
    "                    min_child_weight=2,\n",
    "                    gamma=0.2,\n",
    "                    subsample=0.6,\n",
    "                    colsample_bytree=0.5,\n",
    "                    objective=\"binary:logistic\",\n",
    "                    n_jobs=-1,\n",
    "                    scale_pos_weight=1,\n",
    "                    seed=seed),\n",
    "    BaggingClassifier(base_estimator=XGBClassifier(learning_rate=0.1,\n",
    "                                                    n_estimators=345,\n",
    "                                                    max_depth=8,\n",
    "                                                    min_child_weight=2,\n",
    "                                                    gamma=0.2,\n",
    "                                                    subsample=0.6,\n",
    "                                                    colsample_bytree=0.5,\n",
    "                                                    objective=\"binary:logistic\",\n",
    "                                                    n_jobs=-1,\n",
    "                                                    scale_pos_weight=1,\n",
    "                                                    seed=seed), \n",
    "                      n_estimators=50, max_samples=0.7, max_features=0.75, bootstrap_features=True)\n",
    "]\n",
    "\n",
    "ensemble_v3 = SuperLearner(random_state=seed, scorer=roc_auc_score)\n",
    "ensemble_v3.add(mlens_base_learners_v3, proba=True)\n",
    "ensemble_v3.add_meta(rf_meta_mlens_v3, proba=True)\n",
    "mlens_v3_preds = ensemble_v3.fit(meta_features_train_v3, y_train).predict_proba(meta_features_test_v3)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mlens_v3_preds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-6ee824814b8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0mmlens_v3_preds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'mlens_v3_preds' is not defined"
     ]
    }
   ],
   "source": [
    "print mlens_v3_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
