{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "Julian Domingo - jad5348\n",
    "\n",
    "This file contains my process for training my base learners and meta learner to predict the probability values for the target value **Y**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computation / Data Analysis stuff\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import skew, probplot, norm\n",
    "from scipy.special import boxcox1p\n",
    "\n",
    "# Modeling stuff\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import (RandomizedSearchCV, \n",
    "                                     GridSearchCV, \n",
    "                                     StratifiedKFold,\n",
    "                                     cross_val_score)\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import (RandomForestClassifier, \n",
    "                              AdaBoostClassifier, \n",
    "                              GradientBoostingClassifier, \n",
    "                              ExtraTreesClassifier)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.cross_validation import train_test_split, KFold\n",
    "\n",
    "# Plotting stuff\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pylab as pylab\n",
    "from pandas.tools.plotting import scatter_matrix\n",
    "\n",
    "# Plotting visuals stuff\n",
    "%matplotlib inline\n",
    "mpl.style.use('ggplot')\n",
    "sns.set_style('white')\n",
    "pylab.rcParams['figure.figsize'] = 12,8\n",
    "\n",
    "# ignore warnings (i.e. deprecation warnings)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids = pd.read_csv(\"./data/raw/test.csv\")[[\"id\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(filename):\n",
    "    train = pd.read_csv(\"./data/refined/train/train_{}.csv\".format(filename))\n",
    "    test = pd.read_csv(\"./data/refined/test/test_{}.csv\".format(filename))\n",
    "    \n",
    "    x_train = train.drop([\"Y\"], axis = 1)\n",
    "    y_train = train[\"Y\"]\n",
    "    \n",
    "    return train, test, x_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_base, test_base, x_train_base, y_train_base = get_data(\"base\")\n",
    "train_log, test_log, x_train_log, y_train_log = get_data(\"log\")\n",
    "train_scaled, test_scaled, x_train_scaled, y_train_scaled = get_data(\"scaled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cross_val_score(model, x_train, y_train, n_folds):\n",
    "    cv = cross_val_score(model, x_train, y_train, cv = n_folds, scoring = 'roc_auc', n_jobs = -1)\n",
    "    print(\"Cross validation score: {} +/- {}\\nRaw scores: {}\".format(str(np.mean(cv)), str(np.std(cv)), str(cv)))\n",
    "    return cv\n",
    "\n",
    "def train_and_save_base_learner_preds(model, folds, x_train, y_train, test, pred_filename):\n",
    "    # Train model on the folds defined\n",
    "    result = train(model, folds, x_train, y_train, test)\n",
    "        \n",
    "    train_preds_csv = pd.DataFrame(columns=[\"Y\"], index=x_train.index, data = result[\"train_preds\"])\n",
    "    train_preds_csv.to_csv(\"./predictions/train/train_{}.csv\".format(pred_filename))\n",
    "    \n",
    "    test_preds_csv = pd.DataFrame(columns=[\"Y\"], index=test.index, data=result[\"test_preds\"])\n",
    "    test_preds_csv.to_csv(\"./predictions/test/test_{}.csv\".format(pred_filename))\n",
    "    \n",
    "    return result[\"model\"]\n",
    "                          \n",
    "\n",
    "def train(model, folds, x, y, test):\n",
    "    \"\"\" Trains the model through (stratified) CV. \n",
    "    \n",
    "    'train_preds' is the combination of all predictions from each holdout.\n",
    "    'test_preds' is the final predictions computed through the mean of each test prediction.\n",
    "    \n",
    "    \"\"\"\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    test = np.array(test)\n",
    "        \n",
    "    train_preds = np.zeros(x.shape[0])\n",
    "    test_preds = np.zeros(test.shape[0])\n",
    "    test_preds_iter = np.zeros((test.shape[0], len(folds)))\n",
    "    \n",
    "    for i, (train_indices, test_indices) in enumerate(folds):\n",
    "        x_train = x[train_indices]\n",
    "        x_holdout = x[test_indices]\n",
    "        y_train = y[train_indices]\n",
    "        \n",
    "        %time model.fit(x_train, y_train)\n",
    "        \n",
    "        train_preds[test_indices] = model.predict_proba(x_holdout)[:,1]\n",
    "        test_preds_iter[:,i] = model.predict_proba(test)[:,1]\n",
    "        \n",
    "    test_preds[:] = test_preds_iter.mean(1)\n",
    "        \n",
    "    return {'model': model, 'train_preds': train_preds ,'test_preds': test_preds}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain fold indices for base learner training.\n",
    "n_splits = 5\n",
    "folds = list(StratifiedKFold(n_splits, random_state=seed).split(x_train_base, y_train_base))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Learners"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier\n",
    "\n",
    "Tuning parameters\n",
    "    * n_estimators (online): \"n_estimators is not really worth optimizing. The more estimators you give it, the better it will do. 500 or 1000 is usually sufficient.\"\n",
    "    * criterion (class): Constantine mentioned entropy is the preferred criterion for Random Forests.\n",
    "    * max_features (code): used GridSearchCV, sci-kit learn docs showed [1, 3, 10] as good contenders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=10, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=1000, n_jobs=-1, oob_score=False,\n",
       "            random_state=None, verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'max_features': [1, 3, 10]}, pre_dispatch='2*n_jobs',\n",
       "       refit=True, return_train_score=True, scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_param_grid = {\n",
    "    'max_features': [1, 3, 10]\n",
    "}\n",
    "\n",
    "rfc = RandomForestClassifier(criterion='entropy', max_depth=10, n_estimators=1000, n_jobs=-1)\n",
    "\n",
    "gs_rfc = GridSearchCV(estimator=rfc, param_grid=rfc_param_grid, cv=n_splits, scoring=\"roc_auc\")\n",
    "gs_rfc.fit(x_train_base, y_train_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_features': 10}\n",
      "0.750506293137\n"
     ]
    }
   ],
   "source": [
    "# So, we'll use 10 to be our max_features value.\n",
    "print gs_rfc.best_params_\n",
    "print gs_rfc.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 44 s, sys: 417 ms, total: 44.4 s\n",
      "Wall time: 7.78 s\n",
      "CPU times: user 43.9 s, sys: 383 ms, total: 44.3 s\n",
      "Wall time: 7.75 s\n",
      "CPU times: user 43.5 s, sys: 353 ms, total: 43.8 s\n",
      "Wall time: 7.84 s\n",
      "CPU times: user 43.7 s, sys: 359 ms, total: 44 s\n",
      "Wall time: 7.64 s\n",
      "CPU times: user 43.3 s, sys: 354 ms, total: 43.7 s\n",
      "Wall time: 7.77 s\n",
      "Cross validation score: 0.74792660538 +/- 0.0159539543648\n",
      "Raw scores: [ 0.75121725  0.76470151  0.72537649  0.73385839  0.76447939]\n"
     ]
    }
   ],
   "source": [
    "# Train with our optimized parameters.\n",
    "rfc = RandomForestClassifier(criterion='entropy', max_depth=10, max_features=10, n_estimators=1000, n_jobs=-1)\n",
    "rfc = train_and_save_base_learner_preds(rfc, folds, x_train_base, y_train_base, test_base, \"random_forest_base\")\n",
    "rf_cv = get_cross_val_score(rfc, x_train_base, y_train_base, n_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.9683427 ,  0.84006011,  0.932847  , ...,  0.8995378 ,\n",
       "        0.97463642,  0.96310475])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.fit(x_train_base, y_train_base)\n",
    "probs = rfc.predict_proba(test_base)[:,1]\n",
    "print probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\"id\": test_ids.id, \"Y\": probs})\n",
    "submission.to_csv(\"./submissions/random_forest_lone.csv\", index=False, columns=[\"id\", \"Y\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what features RandomForestClassifier deemed most important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x111c39510>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsQAAAHiCAYAAADvSNo1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niAEAAGC0/w/dPhru+ibUVQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x111c4d950>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(index=x_train_base.columns, data=rfc.feature_importances_).sort_values().plot(kind='barh', title='Variable Importances')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16383, 19)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_base.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F10</th>\n",
       "      <th>F11</th>\n",
       "      <th>F12</th>\n",
       "      <th>F13</th>\n",
       "      <th>F15</th>\n",
       "      <th>F16</th>\n",
       "      <th>F17</th>\n",
       "      <th>F18</th>\n",
       "      <th>F19</th>\n",
       "      <th>F20</th>\n",
       "      <th>F21</th>\n",
       "      <th>F22</th>\n",
       "      <th>F23</th>\n",
       "      <th>F24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16384</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>17000</td>\n",
       "      <td>143022</td>\n",
       "      <td>1</td>\n",
       "      <td>140341</td>\n",
       "      <td>1</td>\n",
       "      <td>122020</td>\n",
       "      <td>135753</td>\n",
       "      <td>1</td>\n",
       "      <td>128168</td>\n",
       "      <td>121276</td>\n",
       "      <td>1</td>\n",
       "      <td>122084</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>127696</td>\n",
       "      <td>1</td>\n",
       "      <td>36129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16385</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>18000</td>\n",
       "      <td>315517</td>\n",
       "      <td>1</td>\n",
       "      <td>138050</td>\n",
       "      <td>1</td>\n",
       "      <td>121506</td>\n",
       "      <td>55012</td>\n",
       "      <td>1</td>\n",
       "      <td>121648</td>\n",
       "      <td>120763</td>\n",
       "      <td>1</td>\n",
       "      <td>119703</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>127441</td>\n",
       "      <td>1</td>\n",
       "      <td>90582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16386</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>1000</td>\n",
       "      <td>142929</td>\n",
       "      <td>1</td>\n",
       "      <td>137960</td>\n",
       "      <td>1</td>\n",
       "      <td>121709</td>\n",
       "      <td>23834</td>\n",
       "      <td>1</td>\n",
       "      <td>314350</td>\n",
       "      <td>120965</td>\n",
       "      <td>1</td>\n",
       "      <td>119703</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>127029</td>\n",
       "      <td>1</td>\n",
       "      <td>46088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16387</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>2000</td>\n",
       "      <td>130186</td>\n",
       "      <td>1</td>\n",
       "      <td>128090</td>\n",
       "      <td>1</td>\n",
       "      <td>120286</td>\n",
       "      <td>92412</td>\n",
       "      <td>1</td>\n",
       "      <td>140144</td>\n",
       "      <td>180952</td>\n",
       "      <td>1</td>\n",
       "      <td>118961</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>127973</td>\n",
       "      <td>1</td>\n",
       "      <td>83138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16388</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>2000</td>\n",
       "      <td>132071</td>\n",
       "      <td>1</td>\n",
       "      <td>128051</td>\n",
       "      <td>1</td>\n",
       "      <td>138055</td>\n",
       "      <td>8513</td>\n",
       "      <td>1</td>\n",
       "      <td>121642</td>\n",
       "      <td>136961</td>\n",
       "      <td>1</td>\n",
       "      <td>118832</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>126927</td>\n",
       "      <td>1</td>\n",
       "      <td>92381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  F3  F4     F6      F7  F8     F10  F11     F12     F13  F15     F16  \\\n",
       "0  16384   0  33  17000  143022   1  140341    1  122020  135753    1  128168   \n",
       "1  16385   0  38  18000  315517   1  138050    1  121506   55012    1  121648   \n",
       "2  16386   1  27   1000  142929   1  137960    1  121709   23834    1  314350   \n",
       "3  16387   0  33   2000  130186   1  128090    1  120286   92412    1  140144   \n",
       "4  16388   0  40   2000  132071   1  128051    1  138055    8513    1  121642   \n",
       "\n",
       "      F17  F18     F19  F20  F21     F22  F23    F24  \n",
       "0  121276    1  122084    1    1  127696    1  36129  \n",
       "1  120763    1  119703    1    2  127441    1  90582  \n",
       "2  120965    1  119703    1    1  127029    1  46088  \n",
       "3  180952    1  118961    1    1  127973    1  83138  \n",
       "4  136961    1  118832    1    1  126927    1  92381  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_base.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Y</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>F10</th>\n",
       "      <th>F11</th>\n",
       "      <th>F12</th>\n",
       "      <th>...</th>\n",
       "      <th>F15</th>\n",
       "      <th>F16</th>\n",
       "      <th>F17</th>\n",
       "      <th>F18</th>\n",
       "      <th>F19</th>\n",
       "      <th>F20</th>\n",
       "      <th>F21</th>\n",
       "      <th>F22</th>\n",
       "      <th>F23</th>\n",
       "      <th>F24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>1000</td>\n",
       "      <td>32020</td>\n",
       "      <td>1</td>\n",
       "      <td>127959</td>\n",
       "      <td>1</td>\n",
       "      <td>120193</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>119757</td>\n",
       "      <td>119100</td>\n",
       "      <td>1</td>\n",
       "      <td>118830</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>126461</td>\n",
       "      <td>1</td>\n",
       "      <td>46871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1000</td>\n",
       "      <td>130630</td>\n",
       "      <td>1</td>\n",
       "      <td>128342</td>\n",
       "      <td>2</td>\n",
       "      <td>122242</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>138110</td>\n",
       "      <td>121149</td>\n",
       "      <td>1</td>\n",
       "      <td>118832</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>130296</td>\n",
       "      <td>1</td>\n",
       "      <td>42386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>1000</td>\n",
       "      <td>303218</td>\n",
       "      <td>2</td>\n",
       "      <td>128299</td>\n",
       "      <td>1</td>\n",
       "      <td>120221</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>119777</td>\n",
       "      <td>119126</td>\n",
       "      <td>1</td>\n",
       "      <td>118832</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>127063</td>\n",
       "      <td>1</td>\n",
       "      <td>23968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>2000</td>\n",
       "      <td>19024</td>\n",
       "      <td>1</td>\n",
       "      <td>127968</td>\n",
       "      <td>1</td>\n",
       "      <td>124605</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>270637</td>\n",
       "      <td>123511</td>\n",
       "      <td>1</td>\n",
       "      <td>118832</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15274</td>\n",
       "      <td>1</td>\n",
       "      <td>27555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>1000</td>\n",
       "      <td>303218</td>\n",
       "      <td>1</td>\n",
       "      <td>128299</td>\n",
       "      <td>1</td>\n",
       "      <td>120635</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>119777</td>\n",
       "      <td>119542</td>\n",
       "      <td>1</td>\n",
       "      <td>118832</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>133491</td>\n",
       "      <td>1</td>\n",
       "      <td>50260</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  Y  F3  F4    F6      F7  F8     F10  F11     F12  ...    F15     F16  \\\n",
       "0   1  1   0  38  1000   32020   1  127959    1  120193  ...      1  119757   \n",
       "1   2  1   0  41  1000  130630   1  128342    2  122242  ...      1  138110   \n",
       "2   3  1   0  50  1000  303218   2  128299    1  120221  ...      1  119777   \n",
       "3   4  1   0  45  2000   19024   1  127968    1  124605  ...      2  270637   \n",
       "4   5  1   0  41  1000  303218   1  128299    1  120635  ...      1  119777   \n",
       "\n",
       "      F17  F18     F19  F20  F21     F22  F23    F24  \n",
       "0  119100    1  118830    1    1  126461    1  46871  \n",
       "1  121149    1  118832    1    1  130296    1  42386  \n",
       "2  119126    1  118832    1    2  127063    1  23968  \n",
       "3  123511    1  118832    1    1   15274    1  27555  \n",
       "4  119542    1  118832    1    1  133491    1  50260  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_base.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def stack_model(model, train, test, y, new_feature):\n",
    "#     model.fit(train, y)\n",
    "#     train[new_feature] = pd.DataFrame(model.predict(train))\n",
    "#     test[new_feature] = pd.DataFrame(model.predict(test))\n",
    "    \n",
    "#     return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def get_out_of_folds_preds(k, model, x_train, x_test, y_train):\n",
    "#     \"\"\" Returns the out of folds predictions of the model passed. \"\"\"\n",
    "#     len_train = x_train.shape[0]\n",
    "#     len_test = x_test.shape[0]\n",
    "#     kf = KFold(len_train, n_folds = k, random_state = 1337)\n",
    "    \n",
    "#     oof_train = np.zeros((len_train,))\n",
    "#     oof_test = np.zeros((len_test,))\n",
    "#     oof_test_kf = np.empty((k, len_test))\n",
    "    \n",
    "#     for i, (train_indices, test_indices) in enumerate(kf):\n",
    "#         model.fit(x_train[train_indices], y_train[train_indices])\n",
    "        \n",
    "#         oof_train[test_indices] = model.predict(x_train[test_indices])\n",
    "#         oof_test_kf[i, :] = model.predict(x_test)\n",
    "\n",
    "#     oof_test[:] = oof_test_kf.mean(axis = 0)\n",
    "    \n",
    "#     return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def get_base_learners():\n",
    "#     # Parameters for each base model.\n",
    "#     rf_params = {\n",
    "#         'n_jobs': -1, # Number of cores used in training == all cores\n",
    "#         'n_estimators': 10, # Number of classification trees in model\n",
    "#         'warm_start': True,\n",
    "#         'max_depth': 3, # Max depth of the tree. WARNING - don't set too high, otherwise may overfit\n",
    "#         'min_samples_leaf': 2, # The minimum number of samples required to be at a leaf node \n",
    "#         'max_features' : 'sqrt', # The number of features to consider when looking for the best split\n",
    "#         'verbose': 0,\n",
    "#         'random_state': seed\n",
    "#         # TODO: tune hyperparameters\n",
    "#     }\n",
    "\n",
    "#     xgb_params = {\n",
    "#         # TODO: tune hyperparameters\n",
    "#     }\n",
    "\n",
    "#     et_params = {\n",
    "#         # TODO: tune hyperparameters\n",
    "#     }\n",
    "\n",
    "#     ada_params = {\n",
    "#         # TODO: tune hyperparameters\n",
    "#     }\n",
    "\n",
    "#     gb_params = {\n",
    "#         # TODO: tune hyperparameters\n",
    "#         'n_estimators': 100,\n",
    "#         'random_state': seed\n",
    "#     }\n",
    "\n",
    "#     svc_params = {\n",
    "#         # TODO: tune hyperparameters\n",
    "#         'C': 100 # Penalty parameter of error term\n",
    "#     }\n",
    "\n",
    "#     lr_params = {\n",
    "#         # TODO: tune hyperparameters\n",
    "#         'C': 100, # Regularization strength\n",
    "#         'random_state': seed\n",
    "#     }\n",
    "\n",
    "#     mlp_params = {\n",
    "#         # TODO: tune hyperparameters\n",
    "#         'hidden_layer_sizes': (80, 10),\n",
    "#         'early_stopping': False,\n",
    "#         'random_state': seed\n",
    "#     }\n",
    "    \n",
    "#     knn_params = {\n",
    "#         # TODO: tune hyperparameters\n",
    "#         'n_neighbors': 3\n",
    "#     }\n",
    "\n",
    "#     nb = GaussianNB()\n",
    "#     knn = KNeighborsClassifier(**knn_params)\n",
    "#     rf = RandomForestClassifier(**rf_params)\n",
    "#     xgb = XGBClassifier(**xgb_params)\n",
    "#     et = ExtraTreesClassifier(**et_params)\n",
    "#     lr = LogisticRegression(**lr_params)\n",
    "#     ada = AdaBoostClassifier(**ada_params)\n",
    "#     gb = GradientBoostingClassifier(**gb_params)\n",
    "#     svc = SVC(**svc_params)\n",
    "    \n",
    "#     return {'rf': rf,\n",
    "#             'et': et,\n",
    "#             'lr': lr,\n",
    "#             'ada': ada,\n",
    "#             'svc': svc,\n",
    "#             'nb': nb,\n",
    "#             'gb': gb,\n",
    "#             'knn': knn,\n",
    "#             'xgb': xgb}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# num_folds = 5\n",
    "\n",
    "# x_train_vals = x_train.values\n",
    "# x_test_vals = x_test.values\n",
    "# y_vals = y.ravel()\n",
    "\n",
    "# rf_train, rf_test = get_out_of_folds_preds(num_folds, rf, x_train_vals, x_test_vals, y_vals)\n",
    "# xgb_train, xgb_test = get_out_of_folds_preds(num_folds, xgb, x_train_vals, x_test_vals, y_vals)\n",
    "# ada_train, ada_test = get_out_of_folds_preds(num_folds, ada, x_train_vals, x_test_vals, y_vals)\n",
    "# gb_train, gb_test = get_out_of_folds_preds(num_folds, gb, x_train_vals, x_test_vals, y_vals)\n",
    "# svc_train, svc_test = get_out_of_folds_preds(num_folds, svc, x_train_vals, x_test_vals, y_vals)\n",
    "# et_train, et_test = get_out_of_folds_preds(num_folds, et, x_train_vals, x_test_vals, y_vals)\n",
    "\n",
    "# TODO: include Logistic Regressor\n",
    "# lr_train, lr_test = get_out_of_folds_preds(num_folds, lr, x_train_vals, x_test_vals, y_vals)\n",
    "    \n",
    "# Feature importances for ensemble models.\n",
    "# rf_importance = rf.fit(x_train.values, y.ravel()).feature_importances_\n",
    "# xgb_importance = xgb.fit(x_train.values, y.ravel()).feature_importances_\n",
    "# ada_importance = ada.fit(x_train.values, y.ravel()).feature_importances_\n",
    "# gb_importance = gb.fit(x_train.values, y.ravel()).feature_importances_\n",
    "# et_importance = et.fit(x_train.values, y.ravel()).feature_importances_\n",
    "\n",
    "# print (\"Random Forest Classifier feature importances:\\n{}\".format(rf_importance))\n",
    "# print (\"XGBoost Classifier feature importances:\\n{}\".format(xgb_importance))\n",
    "# print (\"AdaBoost Classifier feature importances:\\n{}\".format(ada_importance))\n",
    "# print (\"Gradient Boosting Classifier feature importances:\\n{}\".format(gb_importance))\n",
    "# print (\"Extra Trees Classifier feature importances:\\n{}\".format(et_importance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Train the base learners.\n",
    "# for (model_name, model) in base_learners.items():\n",
    "#     x_train, x_test = stack_model(model, x_train, x_test, y, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Feed the base learner predictions into the meta learner, and predict with meta learner.\n",
    "# meta_learner = XGBClassifier()\n",
    "# meta_learner.fit(x_train, y)\n",
    "# predictions = meta_learner.predict(x_test)\n",
    "# submission = pd.DataFrame({\"id\": test.id, \"Y\": predictions})\n",
    "# submission.to_csv('./results.csv', index = False, columns = [\"id\", \"Y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
